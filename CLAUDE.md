# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

PANDA_DATASETS is a collection of academic paper metadata scrapers for computer vision and machine learning conferences. Each conference has its own subdirectory with a standalone Python script that extracts paper information from official proceedings.

## Running the Scripts

```bash
# Run from the conference directory
cd ICCV25
python3 fetch_iccv2025.py

# Or with explicit interpreter
python3 ./ICCV25/fetch_iccv2025.py
```

Scripts are long-running (hours for 2000+ papers) due to rate limiting. They support resume via progress files.

## Architecture

### Script Pattern

Each conference scraper follows the same pattern:
- `fetch_<conference>.py` - Main scraper script
- `<conference>_papers.csv` - Output: paper metadata in CSV
- `<conference>_progress.json` - Checkpoint file for resume support
- `<conference>_fetch.log` - Execution log (redirect stdout)
- `papers_<conference>.md` - Markdown table of papers with code (generated by `csv_to_md.py`)

### Generating Markdown Tables

```bash
python3 csv_to_md.py ICCV25/iccv2025_papers.csv
# Output: ICCV25/papers_iccv25.md
```

Filters to include only papers where `code_url` exists or `code_available` is `yes`/`maybe`.

### Key Design Decisions

1. **No external dependencies**: Uses only Python stdlib (`urllib.request`, `re`, `json`, `pathlib`)
2. **Respectful crawling**: Rate-limited (0.8s delay), custom User-Agent, retry logic with backoff
3. **Resume support**: Progress checkpointed every 10 papers to JSON; script auto-resumes on restart
4. **Code detection**: Validates repository URLs against patterns to avoid false positives (docs, blog pages, etc.)

### Data Flow

1. Fetch main conference listing page
2. Extract paper titles and detail page URLs via regex
3. For each paper:
   - Fetch detail page
   - Extract: PDF URL, abstract, arXiv link
   - Search abstract for code repository URLs
   - If arXiv exists but no code found, also check arXiv page
4. Save to CSV with code availability status: `yes` (URL found), `maybe` (mentioned in abstract), `no`

## Adding New Conferences

Copy an existing script and modify:
- `BASE_URL` - Conference proceedings site
- `extract_papers()` - Regex pattern for paper listing format
- `process_paper()` - Extraction logic for paper details
- Output file paths

The URL validation (`is_valid_repo`) and code extraction (`extract_code_url`) functions are reusable across conferences.
