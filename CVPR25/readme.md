| title | code | about | language | stars | forks | watches | paper | pass^4 |
|-------|------|-------|----------|-------|-------|---------|-------|--------|
| Deterministic Image-to-Image Translation via Denoising Brownian Bridge Models with Dual Approximators | [code](https://github.com/bohan95/dual-app-bridge) |  | Python | 24 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Deterministic_Image-to-Image_Translation_via_Denoising_Brownian_Bridge_Models_with_Dual_CVPR_2025_paper.pdf) | |
| Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment | [code](https://github.com/OpenGVLab/TPO) | Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment | Jupyter Notebook | 64 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Task_Preference_Optimization_Improving_Multimodal_Large_Language_Models_with_Vision_CVPR_2025_paper.pdf) | |
| Cross-modal Causal Relation Alignment for Video Question Grounding | [code](https://github.com/WissingChen/CRA-GQA) | The official implementation of "Cross-modal Causal Relation Alignment for Video Question Grounding. (CVPR 2025 Highlight)" | Python | 41 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Cross-modal_Causal_Relation_Alignment_for_Video_Question_Grounding_CVPR_2025_paper.pdf) | |
| Learning to Detect Objects from  Multi-Agent LiDAR Scans without Manual Labels | [code](https://github.com/xmuqimingxia/DOtA) | Learning to Detect Objects from Multi-Agent LiDAR Scans without Manual Labels. (CVPR2025) | Python | 36 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Learning_to_Detect_Objects_from__Multi-Agent_LiDAR_Scans_without_CVPR_2025_paper.pdf) | |
| Multi-Layer Visual Feature Fusion in Multimodal LLMs: Methods; Analysis; and Best Practices | [code](https://github.com/EIT-NLP/Layer_Select_Fuse_for_MLLM) | [CVPR2025] Official implementation of the paper "Multi-Layer Visual Feature Fusion in Multimodal LLMs: Methods, Analysis, and Best Practices". (by Junyan Lin) | Python | 43 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Multi-Layer_Visual_Feature_Fusion_in_Multimodal_LLMs_Methods_Analysis_and_CVPR_2025_paper.pdf) | |
| APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian Based Reconstruction for Vision Transformers | [code](https://github.com/GoatWu/APHQ-ViT) | [CVPR 2025] APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian Based Reconstruction for Vision Transformers | Python | 34 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_APHQ-ViT_Post-Training_Quantization_with_Average_Perturbation_Hessian_Based_Reconstruction_for_CVPR_2025_paper.pdf) | |
| Omni-Scene: Omni-Gaussian Representation for Ego-Centric Sparse-View Scene Reconstruction | [code](https://github.com/WU-CVGL/Omni-Scene) | [CVPR2025] Omni-Scene: Omni-Gaussian Representation for Ego-Centric Sparse-View Scene Reconstruction | Python | 230 | 16 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_Omni-Scene_Omni-Gaussian_Representation_for_Ego-Centric_Sparse-View_Scene_Reconstruction_CVPR_2025_paper.pdf) | |
| Missing Target-Relevant Information Prediction with World Model for Accurate Zero-Shot Composed Image Retrieval | [code](https://github.com/Pter61/predicir) | CVPR 2025 |  | 13 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Missing_Target-Relevant_Information_Prediction_with_World_Model_for_Accurate_Zero-Shot_CVPR_2025_paper.pdf) | |
| Binarized Mamba-Transformer for Lightweight Quad Bayer HybridEVS Demosaicing | [code](https://github.com/Clausy9/BMTNet) | Code for CVPR 2025 paper "Binarized Mamba-Transformer for Lightweight Quad Bayer HybridEVS Demosaicing". | Python | 8 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Binarized_Mamba-Transformer_for_Lightweight_Quad_Bayer_HybridEVS_Demosaicing_CVPR_2025_paper.pdf) | |
| Interpretable Image Classification via Non-parametric Part Prototype Learning | [code](https://github.com/zijizhu/proto-non-param) | Official PyTorch implementation for the paper "Interpretable Image Classification via Non-parametric Part Prototype Learning" CVPR 2025. | Python | 23 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Interpretable_Image_Classification_via_Non-parametric_Part_Prototype_Learning_CVPR_2025_paper.pdf) | |
| SGC-Net: Stratified Granular Comparison Network for Open-Vocabulary HOI Detection | [code](https://github.com/Phil0212/SGC-Net) | CVPR-2025ï¼ˆSGC-Net: Stratified Granular Comparison Network for Open-Vocabulary HOI Detection.) | Python | 14 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_SGC-Net_Stratified_Granular_Comparison_Network_for_Open-Vocabulary_HOI_Detection_CVPR_2025_paper.pdf) | |
| FlashGS: Efficient 3D Gaussian Splatting for Large-scale and High-resolution Rendering | [code](https://github.com/InternLandMark/FlashGS) |  | C++ | 203 | 14 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_FlashGS_Efficient_3D_Gaussian_Splatting_for_Large-scale_and_High-resolution_Rendering_CVPR_2025_paper.pdf) | |
| Reloc3r: Large-Scale Training of Relative Camera Pose Regression for Generalizable; Fast; and Accurate Visual Localization | [code](https://github.com/ffrivera0/reloc3r) | [CVPR 2025] Relative camera pose estimation and visual localization with Reloc3r | Python | 275 | 24 | 12 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Reloc3r_Large-Scale_Training_of_Relative_Camera_Pose_Regression_for_Generalizable_CVPR_2025_paper.pdf) | |
| AI-Face: A Million-Scale Demographically Annotated AI-Generated Face Dataset and Fairness Benchmark | [code](https://github.com/Purdue-M2/AI-Face-FairnessBench) | We introduce AI-Face, the first million-scale AI-generated face dataset with demographic annotations, and conduct a comprehensive fairness benchmark. Our work has been accepted at CVPR 2025. | Python | 77 | 7 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_AI-Face_A_Million-Scale_Demographically_Annotated_AI-Generated_Face_Dataset_and_Fairness_CVPR_2025_paper.pdf) | |
| Inference-Scale Complexity in ANN-SNN Conversion for High-Performance and Low-Power Applications | [code](https://github.com/putshua/Inference-scale-ANN-SNN) | Code for paper "Inference-Scale Complexity in ANN-SNN Conversion for High-Performance and Low-Power Applications", CVPR 2025 | Jupyter Notebook | 8 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Bu_Inference-Scale_Complexity_in_ANN-SNN_Conversion_for_High-Performance_and_Low-Power_Applications_CVPR_2025_paper.pdf) | |
| TopNet: Transformer-Efficient Occupancy Prediction Network for Octree-Structured Point Cloud Geometry Compression | [code](https://github.com/xinjiewang1995/TopNet) | [CVPR 2025] This is the official PyTorch implementation of our paper "TopNet: Transformer-Efficient Occupancy Prediction Network for Octree-Structured Point Cloud Geometry Compression" | Python | 28 | 3 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TopNet_Transformer-Efficient_Occupancy_Prediction_Network_for_Octree-Structured_Point_Cloud_Geometry_CVPR_2025_paper.pdf) | |
| Self-Expansion of Pre-trained Models with Mixture of Adapters for Continual Learning | [code](https://github.com/huiyiwang01/SEMA-CL) |  | Python | 32 | 2 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Self-Expansion_of_Pre-trained_Models_with_Mixture_of_Adapters_for_Continual_CVPR_2025_paper.pdf) | |
| MambaOut: Do We Really Need Mamba for Vision? | [code](https://github.com/yuweihao/MambaOut) | MambaOut: Do We Really Need Mamba for Vision? (CVPR 2025) | Python | 2631 | 48 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_MambaOut_Do_We_Really_Need_Mamba_for_Vision_CVPR_2025_paper.pdf) | |
| Everything to the Synthetic: Diffusion-driven Test-time Adaptation via Synthetic-Domain Alignment | [code](https://github.com/SHI-Labs/Diffusion-Driven-Test-Time-Adaptation-via-Synthetic-Domain-Alignment) | Everything to the Synthetic: Diffusion-driven Test-time Adaptation via Synthetic-Domain Alignment, arXiv 2024 / CVPR 2025 | Python | 38 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Everything_to_the_Synthetic_Diffusion-driven_Test-time_Adaptation_via_Synthetic-Domain_Alignment_CVPR_2025_paper.pdf) | |
| Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation | [code](https://github.com/dengpeihua/GROTO) | [CVPR 2025] Official implementation of paper "Multi-Granularity Class Prototype Topology Distillation for Class-Incremental  Source-Free Unsupervised Domain Adaptation" | Python | 16 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Multi-Granularity_Class_Prototype_Topology_Distillation_for_Class-Incremental_Source-Free_Unsupervised_Domain_CVPR_2025_paper.pdf) | |
| DnLUT: Ultra-Efficient Color Image Denoising via Channel-Aware Lookup Tables | [code](https://github.com/Stephen0808/DnLUT) | [CVPR 2025] DnLUT: Ultra-Efficient Color Image Denoising via Channel-Aware Lookup Tables | Python | 72 | 8 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_DnLUT_Ultra-Efficient_Color_Image_Denoising_via_Channel-Aware_Lookup_Tables_CVPR_2025_paper.pdf) | |
| Curriculum Coarse-to-Fine Selection for High-IPC Dataset Distillation | [code](https://github.com/CYDaaa30/CCFS) | Curriculum Coarse-to-Fine Selection for High-IPC Dataset Dis | Python | 8 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Curriculum_Coarse-to-Fine_Selection_for_High-IPC_Dataset_Distillation_CVPR_2025_paper.pdf) | |
| SATA: Spatial Autocorrelation Token Analysis for Enhancing the Robustness of Vision Transformers | [code](https://github.com/nick-nikzad/SATA) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Nikzad_SATA_Spatial_Autocorrelation_Token_Analysis_for_Enhancing_the_Robustness_of_CVPR_2025_paper.pdf) | |
| HiLoTs: High-Low Temporal Sensitive Representation Learning for Semi-Supervised LiDAR Segmentation in Autonomous Driving | [code](https://github.com/rdlin118/HiLoTs) |  | Python | 13 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_HiLoTs_High-Low_Temporal_Sensitive_Representation_Learning_for_Semi-Supervised_LiDAR_Segmentation_CVPR_2025_paper.pdf) | |
| Spiking Transformer with Spatial-Temporal Attention | [code](https://github.com/Intelligent-Computing-Lab-Yale/STAtten) | PyTorch Implementation of Spiking Transformer with Spatial-Temporal Attention (CVPR 2025) | Python | 65 | 11 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Spiking_Transformer_with_Spatial-Temporal_Attention_CVPR_2025_paper.pdf) | |
| SymDPO: Boosting In-Context Learning of Large Multimodal Models with Symbol Demonstration Direct Preference Optimization | [code](https://github.com/APiaoG/SymDPO) | We have developed Symbol Demonstration Direct Preference Optimization (SymDPO) and validating its effectiveness across multiple benchmarks. | Python | 22 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_SymDPO_Boosting_In-Context_Learning_of_Large_Multimodal_Models_with_Symbol_CVPR_2025_paper.pdf) | |
| Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior | [code](https://github.com/ChnanChan/PSP-UAP) | Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior | Python | 13 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Data-free_Universal_Adversarial_Perturbation_with_Pseudo-semantic_Prior_CVPR_2025_paper.pdf) | |
| GIVEPose: Gradual Intra-class Variation Elimination for RGB-based Category-Level Object Pose Estimation | [code](https://github.com/ziqin-h/GIVEPose) | Offical Pytorch Implementation of CVPR2025 GIVEPose: Gradual Intra-class Variation Elimination for RGB-based Category-Level Object Pose Estimation | Python | 14 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_GIVEPose_Gradual_Intra-class_Variation_Elimination_for_RGB-based_Category-Level_Object_Pose_CVPR_2025_paper.pdf) | |
| Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention | [code](https://github.com/saadwazir/MCADS-Decoder) | Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention - Accepted in CVPR 2025 | Python | 39 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wazir_Rethinking_Decoder_Design_Improving_Biomarker_Segmentation_Using_Depth-to-Space_Restoration_and_CVPR_2025_paper.pdf) | |
| SynTab-LLaVA: Enhancing Multimodal Table Understanding with Decoupled Synthesis | [code](https://github.com/bang123-box/SynTab-LLaVA) | SynTab-LLaVA: Enhancing Multimodal Table Understanding with Decoupled Synthesis CVPR2025 | Python | 10 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_SynTab-LLaVA_Enhancing_Multimodal_Table_Understanding_with_Decoupled_Synthesis_CVPR_2025_paper.pdf) | |
| Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing | [code](https://github.com/taco-group/FaceLock) | Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing | Python | 50 | 3 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Edit_Away_and_My_Face_Will_not_Stay_Personal_Biometric_CVPR_2025_paper.pdf) | |
| DrVideo: Document Retrieval Based Long Video Understanding | [code](https://github.com/Upper9527/DrVideo) | Code of "DrVideo: Document Retrieval Based Long Video Understanding" | Python | 97 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_DrVideo_Document_Retrieval_Based_Long_Video_Understanding_CVPR_2025_paper.pdf) | |
| LSNet: See Large; Focus Small | [code](https://github.com/jameslahm/lsnet) | LSNet: See Large, Focus Small [CVPR 2025] | Python | 477 | 41 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LSNet_See_Large_Focus_Small_CVPR_2025_paper.pdf) | |
| DocLayLLM: An Efficient Multi-modal Extension of Large Language Models for Text-rich Document Understanding | [code](https://github.com/whlscut/DocLayLLM) | [CVPR 2025] DocLayLLM: An Efficient Multi-modal Extension of Large Language Models for Text-rich Document Understanding | Python | 22 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_DocLayLLM_An_Efficient_Multi-modal_Extension_of_Large_Language_Models_for_CVPR_2025_paper.pdf) | |
| DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in Multimodal Cycles | [code](https://github.com/showlab/DoraCycle) | [CVPR 2025] DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in Multimodal Cycles |  | 28 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DoraCycle_Domain-Oriented_Adaptation_of_Unified_Generative_Model_in_Multimodal_Cycles_CVPR_2025_paper.pdf) | |
| WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion | [code](https://github.com/wuyang98/weathergen) |  | Jupyter Notebook | 18 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_WeatherGen_A_Unified_Diverse_Weather_Generator_for_LiDAR_Point_Clouds_CVPR_2025_paper.pdf) | |
| MUST: The First Dataset and Unified Framework for Multispectral UAV Single Object Tracking | [code](https://github.com/q2479036243/MUST-Multispectral-UAV-Single-Object-Tracking) |  | Python | 56 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_MUST_The_First_Dataset_and_Unified_Framework_for_Multispectral_UAV_CVPR_2025_paper.pdf) | |
| Tightening Robustness Verification of MaxPool-based Neural Networks via Minimizing the Over-Approximation Zone | [code](https://github.com/xiaoyuanpigo/Ti-Lin-Hybrid-Lin) | (CVPR 2025)Tightening Robustness Verification of MaxPool-based Neural Networks via Minimizing the Over-Approximation Zone | Python | 1 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Tightening_Robustness_Verification_of_MaxPool-based_Neural_Networks_via_Minimizing_the_CVPR_2025_paper.pdf) | |
| Taste More; Taste Better: Diverse Data and Strong Model Boost Semi-Supervised Crowd Counting | [code](https://github.com/syhien/taste_more_taste_better) | Official implementation of CVPR'25 "Taste More, Taste Better: Diverse Data and Strong Model Boost Semi-Supervised Crowd Counting" | Python | 4 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Taste_More_Taste_Better_Diverse_Data_and_Strong_Model_Boost_CVPR_2025_paper.pdf) | |
| Latent Space Imaging | [code](http://github.com/vccimaging/latent-imaging) | [CVPR 2025] PyTorch code and models for the Latent Space Imaging method.  | Python | 11 | 2 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Souza_Latent_Space_Imaging_CVPR_2025_paper.pdf) | |
| Balanced Direction from Multifarious Choices: Arithmetic Meta-Learning for Domain Generalization | [code](https://github.com/zzwdx/ARITH) |  |  | 0 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Balanced_Direction_from_Multifarious_Choices_Arithmetic_Meta-Learning_for_Domain_Generalization_CVPR_2025_paper.pdf) | |
| Anatomical Consistency and Adaptive Prior-informed Transformation for Multi-contrast MR Image Synthesis via Diffusion Model | [code](https://github.com/yejees/APT) | The official code of APT | Python | 12 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shin_Anatomical_Consistency_and_Adaptive_Prior-informed_Transformation_for_Multi-contrast_MR_Image_CVPR_2025_paper.pdf) | |
| SeCap: Self-Calibrating and Adaptive Prompts for Cross-view Person Re-Identification in Aerial-Ground Networks | [code](https://github.com/wangshining681/SeCap-AGPReID) | SeCap: Self-Calibrating and Adaptive Prompts for Cross-view Person Re-Identification in Aerial-Ground Networks (CVPR'25) | Python | 19 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SeCap_Self-Calibrating_and_Adaptive_Prompts_for_Cross-view_Person_Re-Identification_in_CVPR_2025_paper.pdf) | |
| Aesthetic Post-Training Diffusion Models from Generic Preferences with Step-by-step Preference Optimization | [code](https://github.com/RockeyCoss/SPO) | [CVPR 2025] Aesthetic Post-Training Diffusion Models from Generic Preferences with Step-by-step Preference Optimization | Python | 261 | 11 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Aesthetic_Post-Training_Diffusion_Models_from_Generic_Preferences_with_Step-by-step_Preference_CVPR_2025_paper.pdf) | |
| Adversarial Diffusion Compression for Real-World Image Super-Resolution | [code](https://github.com/Guaishou74851/AdcSR) | (CVPR 2025) Adversarial Diffusion Compression for Real-World Image Super-Resolution [PyTorch] | Python | 243 | 14 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Adversarial_Diffusion_Compression_for_Real-World_Image_Super-Resolution_CVPR_2025_paper.pdf) | |
| Towards Universal AI-Generated Image Detection by Variational Information Bottleneck Network | [code](https://github.com/oceanzhf/VIBAIGCDetect) | Official implementation of CVPR2025 paper "Towards Universal AI-Generated Image Detection by Variational Information Bottleneck Network" | Python | 18 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Towards_Universal_AI-Generated_Image_Detection_by_Variational_Information_Bottleneck_Network_CVPR_2025_paper.pdf) | |
| FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding | [code](https://github.com/Moomin-Fin/Ano) |  |  | 5 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_FSBench_A_Figure_Skating_Benchmark_for_Advancing_Artistic_Sports_Understanding_CVPR_2025_paper.pdf) | |
| Towards Understanding How Knowledge Evolves in Large Vision-Language Models | [code](https://github.com/XIAO4579/Vlm-interpretability) | Official implementation for the paper"Towards Understanding How Knowledge Evolves in Large Vision-Language Models" | Python | 26 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Towards_Understanding_How_Knowledge_Evolves_in_Large_Vision-Language_Models_CVPR_2025_paper.pdf) | |
| A Unified; Resilient; and Explainable Adversarial Patch Detector | [code](https://github.com/tbvl22/Unified-resilient-and-Explainable-Adversarial-Patch-detector) |  |  | 4 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kumar_A_Unified_Resilient_and_Explainable_Adversarial_Patch_Detector_CVPR_2025_paper.pdf) | |
| Structured 3D Latents for Scalable and Versatile 3D Generation | [code](https://github.com/Microsoft/TRELLIS) | Official repo for paper "Structured 3D Latents for Scalable and Versatile 3D Generation" (CVPR'25 Spotlight). | Python | 11543 | 1073 | 135 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiang_Structured_3D_Latents_for_Scalable_and_Versatile_3D_Generation_CVPR_2025_paper.pdf) | |
| Noise Modeling in One Hour: Minimizing Preparation Efforts for Self-supervised Low-Light RAW Image Denoising | [code](https://github.com/SonyResearch/raw_image_denoising) | Noise Modeling in One Hour: Minimizing Preparation Efforts for Self-supervised Low-Light RAW Image Denoising | Python | 66 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Noise_Modeling_in_One_Hour_Minimizing_Preparation_Efforts_for_Self-supervised_CVPR_2025_paper.pdf) | |
| Fish-Vista: A Multi-Purpose Dataset for Understanding & Identification of Traits from Images | [code](https://github.com/Imageomics/Fish-Vista) | Fish-Vista: A Multi-Purpose Dataset for Understanding & Identification of Traits from Images | Jupyter Notebook | 6 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mehrab_Fish-Vista_A_Multi-Purpose_Dataset_for_Understanding__Identification_of_Traits_CVPR_2025_paper.pdf) | |
| High Dynamic Range Video Compression: A Large-Scale Benchmark Dataset and A Learned Bit-depth Scalable Compression Algorithm | [code](https://github.com/sdkinda/HDR-Learned-Video-Coding) | High Dynamic Range Video Compression: A Large-Scale Benchmark Dataset and A Learned Bit-depth Scalable Compression Algorithm |  | 11 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_High_Dynamic_Range_Video_Compression_A_Large-Scale_Benchmark_Dataset_and_CVPR_2025_paper.pdf) | |
| DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models | [code](https://github.com/vbdi/divprune) | [CVPR 2025] DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models | Python | 63 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Alvar_DivPrune_Diversity-based_Visual_Token_Pruning_for_Large_Multimodal_Models_CVPR_2025_paper.pdf) | |
| Training Data Provenance Verification: Did Your Model Use Synthetic Data from My Generative Model for Training? | [code](https://github.com/xieyc99/TrainProVe) | [CVPR 2025] Training Data Provenance Verification: Did Your Model Use Synthetic Data from My Generative Model for Training? | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Training_Data_Provenance_Verification_Did_Your_Model_Use_Synthetic_Data_CVPR_2025_paper.pdf) | |
| STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding | [code](https://github.com/zhoujiahuan1991/CVPR2025-STOP) |  | Python | 17 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_STOP_Integrated_Spatial-Temporal_Dynamic_Prompting_for_Video_Understanding_CVPR_2025_paper.pdf) | |
| Improving the Training of Data-Efficient GANs via Quality Aware Dynamic Discriminator Rejection Sampling | [code](https://github.com/zzhang05/QADDRS) |  | Python | 3 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Improving_the_Training_of_Data-Efficient_GANs_via_Quality_Aware_Dynamic_CVPR_2025_paper.pdf) | |
| PBR-NeRF: Inverse Rendering with Physics-Based Neural Fields | [code](https://github.com/s3anwu/pbrnerf) | We tackle the ill-posed inverse rendering problem with a NeRF model based on physical priors which jointly estimates scene materials, illumination, and geometry. | Python | 39 | 3 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_PBR-NeRF_Inverse_Rendering_with_Physics-Based_Neural_Fields_CVPR_2025_paper.pdf) | |
| No Pains; More Gains: Recycling Sub-Salient Patches for Efficient High-Resolution Image Recognition | [code](https://github.com/Qinrong-NKU/DBPS) |  | Python | 7 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_No_Pains_More_Gains_Recycling_Sub-Salient_Patches_for_Efficient_High-Resolution_CVPR_2025_paper.pdf) | |
| SphereUFormer: A U-Shaped Transformer for Spherical 360 Perception | [code](https://github.com/yanivbenny/sphere_uformer) |  | Python | 13 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Benny_SphereUFormer_A_U-Shaped_Transformer_for_Spherical_360_Perception_CVPR_2025_paper.pdf) | |
| Advancing Generalizable Tumor Segmentation with Anomaly-Aware Open-Vocabulary Attention Maps and Frozen Foundation Diffusion Models | [code](https://github.com/Yankai96/DiffuGTS) | Discover the repository for "Advancing Generalizable Tumor Segmentation with Anomaly-Aware Open-Vocabulary Attention Maps and Frozen Foundation Diffusion Models", a pioneering study that has been accepted for presentation at CVPR 2025. |  | 17 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Advancing_Generalizable_Tumor_Segmentation_with_Anomaly-Aware_Open-Vocabulary_Attention_Maps_and_CVPR_2025_paper.pdf) | |
| Open-Canopy: Towards Very High Resolution Forest Monitoring | [code](https://github.com/fajwel/Open-Canopy) | Canopy Height Estimation at very High Resolution | Python | 44 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fogel_Open-Canopy_Towards_Very_High_Resolution_Forest_Monitoring_CVPR_2025_paper.pdf) | |
| Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget | [code](https://github.com/SonyResearch/micro_diffusion) | Official repository for our work on micro-budget training of large-scale diffusion models. | Python | 1548 | 53 | 51 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sehwag_Stretching_Each_Dollar_Diffusion_Training_from_Scratch_on_a_Micro-Budget_CVPR_2025_paper.pdf) | |
| Physical Plausibility-aware Trajectory Prediction via Locomotion Embodiment | [code](https://github.com/ImIntheMiddle/EmLoco) | [CVPR2025] Official PyTorch implimentation for "Physical Plausibility-aware Trajectory Prediction via Locomotion Embodiment" | Python | 46 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Taketsugu_Physical_Plausibility-aware_Trajectory_Prediction_via_Locomotion_Embodiment_CVPR_2025_paper.pdf) | |
| OW-OVD: Unified Open World and Open Vocabulary Object Detection | [code](https://github.com/xxyzll/OW_OVD) | OW-OVD: Unified Open World and Open Vocabulary Object Detection (CVPR 2025) | Python | 22 | 3 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xi_OW-OVD_Unified_Open_World_and_Open_Vocabulary_Object_Detection_CVPR_2025_paper.pdf) | |
| Using Powerful Prior Knowledge of Diffusion Model in Deep Unfolding Networks for Image Compressive Sensing | [code](https://github.com/FengodChen/DMP-DUN-CVPR2025) | [CVPR2025] Using Powerful Prior Knowledge of Diffusion Model in Deep Unfolding Networks for Image Compressive Sensing | Python | 27 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_Using_Powerful_Prior_Knowledge_of_Diffusion_Model_in_Deep_Unfolding_CVPR_2025_paper.pdf) | |
| VASparse: Towards Efficient Visual Hallucination Mitigation via Visual-Aware Token Sparsification | [code](https://github.com/mengchuang123/VASparse-github) | [CVPR 2025] VASparse: Towards Efficient Visual Hallucination Mitigation via Visual-Aware Token Sparsification | Python | 49 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhuang_VASparse_Towards_Efficient_Visual_Hallucination_Mitigation_via_Visual-Aware_Token_Sparsification_CVPR_2025_paper.pdf) | |
| SPARC: Score Prompting and Adaptive Fusion for Zero-Shot Multi-Label Recognition in Vision-Language Models | [code](https://github.com/kjmillerCURIS/SPARC) | SPARC: Score Prompting and Adaptive Fusion for Zero-Shot Multi-Label Recognition in Vision-Language Models | Python | 4 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Miller_SPARC_Score_Prompting_and_Adaptive_Fusion_for_Zero-Shot_Multi-Label_Recognition_CVPR_2025_paper.pdf) | |
| FedMIA: An Effective Membership Inference Attack Exploiting "All for One" Principle in Federated Learning | [code](https://github.com/Liar-Mask/FedMIA) |  | Python | 14 | 10 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_FedMIA_An_Effective_Membership_Inference_Attack_Exploiting_All_for_One_CVPR_2025_paper.pdf) | |
| Prompt-CAM: Making Vision Transformers Interpretable for Fine-Grained Analysis | [code](https://github.com/Imageomics/Prompt_CAM) | This is an official implementation for PROMPT-CAM: A Simpler Interpretable Transformer for Fine-Grained Analysis (CVPR'25) | Jupyter Notebook | 65 | 3 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chowdhury_Prompt-CAM_Making_Vision_Transformers_Interpretable_for_Fine-Grained_Analysis_CVPR_2025_paper.pdf) | |
| DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework | [code](https://github.com/hmorimitsu/ptlflow/tree/main/ptlflow/models/dpflow) | PyTorch Lightning Optical Flow models, scripts, and pretrained weights. | Python | 477 | 53 | 11 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Morimitsu_DPFlow_Adaptive_Optical_Flow_Estimation_with_a_Dual-Pyramid_Framework_CVPR_2025_paper.pdf) | |
| DocSAM: Unified Document Image Segmentation via Query Decomposition and Heterogeneous Mixed Learning | [code](https://github.com/xhli-git/DocSAM) |  | Python | 30 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DocSAM_Unified_Document_Image_Segmentation_via_Query_Decomposition_and_Heterogeneous_CVPR_2025_paper.pdf) | |
| Self-Supervised Learning for Color Spike Camera Reconstruction | [code](https://github.com/csycdong/SSL-CSC) |  | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Self-Supervised_Learning_for_Color_Spike_Camera_Reconstruction_CVPR_2025_paper.pdf) | |
| Interactive Medical Image Analysis with Concept-based Similarity Reasoning | [code](https://github.com/tadeephuy/InteractCSR) | Official implementation of Interactive Medical Image Analysis with Concept-based Similarity Reasoning [CVPR2025] |  | 17 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huy_Interactive_Medical_Image_Analysis_with_Concept-based_Similarity_Reasoning_CVPR_2025_paper.pdf) | |
| Masking meets Supervision: A Strong Learning Alliance | [code](https://github.com/naver-ai/augsub) | [CVPR 2025] Official PyTorch implementation of MaskSub "Masking meets Supervision: A Strong Learning Alliance" | Python | 45 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Heo_Masking_meets_Supervision_A_Strong_Learning_Alliance_CVPR_2025_paper.pdf) | |
| Are Spatial-Temporal Graph Convolution Networks for Human Action Recognition Over-Parameterized? | [code](https://github.com/davelailai/Sparse-ST-GCN) |  | Python | 8 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Are_Spatial-Temporal_Graph_Convolution_Networks_for_Human_Action_Recognition_Over-Parameterized_CVPR_2025_paper.pdf) | |
| Towards Lossless Implicit Neural Representation via Bit Plane Decomposition | [code](https://github.com/WooKyoungHan/LosslessINR) | Official implementation of the CVPR'25 Paper "Towards Lossless Implicit Neural Representation via Bit Plane Decomposition" | JavaScript | 27 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Towards_Lossless_Implicit_Neural_Representation_via_Bit_Plane_Decomposition_CVPR_2025_paper.pdf) | |
| Unraveling Normal Anatomy via Fluid-Driven Anomaly Randomization | [code](https://github.com/peirong26/UNA) | [CVPR 2025] Unraveling Normal Anatomy via Fluid-Driven Anomaly Randomization | Python | 19 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Unraveling_Normal_Anatomy_via_Fluid-Driven_Anomaly_Randomization_CVPR_2025_paper.pdf) | |
| URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration | [code](https://github.com/FZU-N/URWKV) | [CVPR'2025] URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration | Python | 33 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_URWKV_Unified_RWKV_Model_with_Multi-state_Perspective_for_Low-light_Image_CVPR_2025_paper.pdf) | |
| OSDFace: One-Step Diffusion Model for Face Restoration | [code](https://github.com/jkwang28/OSDFace) | Official Repo for CVPR 2025 paper "OSDFace: One-Step Diffusion Model for Face Restoration" | Python | 242 | 11 | 24 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_OSDFace_One-Step_Diffusion_Model_for_Face_Restoration_CVPR_2025_paper.pdf) | |
| MMTL-UniAD: A Unified Framework for Multimodal and Multi-Task Learning in Assistive Driving Perception | [code](https://github.com/Wenzhuo-Liu/MMTL-UniAD) | MMTL-UniAD: A Unified Framework for Multimodal and Multi-Task Learning in Assistive Driving Perception | Python | 27 | 7 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MMTL-UniAD_A_Unified_Framework_for_Multimodal_and_Multi-Task_Learning_in_CVPR_2025_paper.pdf) | |
| Multimodal Autoregressive Pre-training of Large Vision Encoders | [code](https://github.com/apple/ml-aim) | This repository provides the code and model checkpoints for AIMv1 and AIMv2 research projects. | Python | 1393 | 68 | 26 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fini_Multimodal_Autoregressive_Pre-training_of_Large_Vision_Encoders_CVPR_2025_paper.pdf) | |
| Bridging the Vision-Brain Gap with an Uncertainty-Aware Blur Prior | [code](https://github.com/HaitaoWuTJU/Uncertainty-aware-Blur-Prior) | Uncertainty-aware Blur Prior on CVPR 2025 | Python | 66 | 7 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Bridging_the_Vision-Brain_Gap_with_an_Uncertainty-Aware_Blur_Prior_CVPR_2025_paper.pdf) | |
| Invisible Backdoor Attack against Self-supervised Learning | [code](https://github.com/Zhang-Henry/INACTIVE) | The official implementation of CVPR 2025 paper "Invisible Backdoor Attack against Self-supervised Learning" | Python | 17 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Invisible_Backdoor_Attack_against_Self-supervised_Learning_CVPR_2025_paper.pdf) | |
| BWFormer: Building Wireframe Reconstruction from Airborne LiDAR Point Cloud with Transformer | [code](https://github.com/3dv-casia/BWformer/) | [CVPR 2025] BWFormer: Building Wireframe Reconstruction from airborne LiDAR point clouds with Transformer | Python | 59 | 2 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_BWFormer_Building_Wireframe_Reconstruction_from_Airborne_LiDAR_Point_Cloud_with_CVPR_2025_paper.pdf) | |
| Diffusion-4K: Ultra-High-Resolution Image Synthesis with Latent Diffusion Models | [code](https://github.com/zhang0jhon/diffusion-4k) | [CVPR 2025] Diffusion-4K: Ultra-High-Resolution Image Synthesis with Latent Diffusion Models | Python | 344 | 11 | 12 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Diffusion-4K_Ultra-High-Resolution_Image_Synthesis_with_Latent_Diffusion_Models_CVPR_2025_paper.pdf) | |
| DKC: Differentiated Knowledge Consolidation for Cloth-Hybrid Lifelong Person Re-identification | [code](https://github.com/PKU-ICST-MIPL/DKC-CVPR2025) |  | Python | 4 | 3 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_DKC_Differentiated_Knowledge_Consolidation_for_Cloth-Hybrid_Lifelong_Person_Re-identification_CVPR_2025_paper.pdf) | |
| Enhancing Facial Privacy Protection via Weakening Diffusion Purification | [code](https://github.com/parham1998/Facial-Privacy-Protection) | [CVPR 2025] Official Implementation of the Paper "Enhancing Facial Privacy Protection via Weakening Diffusion Purification" | Python | 14 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Salar_Enhancing_Facial_Privacy_Protection_via_Weakening_Diffusion_Purification_CVPR_2025_paper.pdf) | |
| Image Generation Diversity Issues and How to Tame Them | [code](https://github.com/MischaD/beyondfid) | A python package to streamline evaluation of unconditional image generation models | Python | 14 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dombrowski_Image_Generation_Diversity_Issues_and_How_to_Tame_Them_CVPR_2025_paper.pdf) | |
| Effective Cloud Removal for Remote Sensing Images by an Improved Mean-Reverting Denoising Model with Elucidated Design Space | [code](https://github.com/Ly403/EMRDM) | [CVPR 2025] The official implementation of EMRDM, which is a novel diffusion model for cloud removal of remote sensing images. | Python | 46 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Effective_Cloud_Removal_for_Remote_Sensing_Images_by_an_Improved_CVPR_2025_paper.pdf) | |
| Dataset Distillation with Neural Characteristic Function: A Minmax Perspective | [code](https://github.com/gszfwsb/NCFM) | Official PyTorch implementation of the paper "Dataset Distillation with Neural Characteristic Function: A Minmax Perspective" (NCFM) in CVPR 2025 (Full Score, Highlight). | Python | 402 | 34 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Dataset_Distillation_with_Neural_Characteristic_Function_A_Minmax_Perspective_CVPR_2025_paper.pdf) | |
| DIFFER: Disentangling Identity Features via Semantic Cues for Clothes-Changing Person Re-ID | [code](https://github.com/xliangp/DIFFER.git) | Official implementation for CVPR 2025 paper: DIFFER: Disentangling Identity Features via Semantic Cues for Clothes-Changing Person Re-ID. | Python | 23 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_DIFFER_Disentangling_Identity_Features_via_Semantic_Cues_for_Clothes-Changing_Person_CVPR_2025_paper.pdf) | |
| Mono3DVLT: Monocular-Video-Based 3D Visual Language Tracking | [code](https://github.com/hongkai-wei/Mono3DVLT) |  |  | 0 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_Mono3DVLT_Monocular-Video-Based_3D_Visual_Language_Tracking_CVPR_2025_paper.pdf) | |
| What Makes a Good Dataset for Knowledge Distillation? | [code](https://github.com/osu-cvl/good-kd-dataset) |  |  | 4 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Frank_What_Makes_a_Good_Dataset_for_Knowledge_Distillation_CVPR_2025_paper.pdf) | |
| CaricatureBooth: Data-Free Interactive Caricature Generation in a Photo Booth | [code](https://github.com/WinKawaks/CaricatureBooth) | [CVPR 2025] CaricatureBooth: Data-Free Interactive Caricature Generation in a Photo Booth | Python | 3 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_CaricatureBooth_Data-Free_Interactive_Caricature_Generation_in_a_Photo_Booth_CVPR_2025_paper.pdf) | |
| Precise; Fast; and Low-cost Concept Erasure in Value Space:  Orthogonal Complement Matters | [code](https://github.com/WYuan1001/AdaVD) | [CVPR2025] Precise, Fast, and Low-cost Concept Erasure in Value Space: Orthogonal Complement Matters | Jupyter Notebook | 43 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Precise_Fast_and_Low-cost_Concept_Erasure_in_Value_Space__CVPR_2025_paper.pdf) | |
| T2ISafety: Benchmark for Assessing Fairness; Toxicity; and Privacy in Image Generation | [code](https://github.com/adwardlee/t2i_safety) | [CVPR2025] T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation |  | 29 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_T2ISafety_Benchmark_for_Assessing_Fairness_Toxicity_and_Privacy_in_Image_CVPR_2025_paper.pdf) | |
| Foveated Instance Segmentation | [code](https://github.com/SAI-Lab-NYU/Foveated-Instance-Segmentation) |  | Python | 8 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_Foveated_Instance_Segmentation_CVPR_2025_paper.pdf) | |
| Universal Domain Adaptation for Semantic Segmentation | [code](https://github.com/KU-VGI/UniDA-SS) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Choe_Universal_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios | [code](https://github.com/NUS-HPC-AI-Lab/EDF) |  | Python | 23 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Emphasizing_Discriminative_Features_for_Dataset_Distillation_in_Complex_Scenarios_CVPR_2025_paper.pdf) | |
| LMO: Linear Mamba Operator for MRI Reconstruction | [code](https://github.com/ZhengJianwei2/LMO) | LMO: Linear Mamba operator for MRI Reconstruction. |  | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LMO_Linear_Mamba_Operator_for_MRI_Reconstruction_CVPR_2025_paper.pdf) | |
| AnomalyNCD: Towards Novel Anomaly Class Discovery in Industrial Scenarios | [code](https://github.com/HUST-SLOW/AnomalyNCD) | [CVPR2025] AnomalyNCD: Towards Novel Anomaly Class Discovery in Industrial Scenarios. Paper is available at https://arxiv.org/abs/2410.14379 | Python | 132 | 12 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_AnomalyNCD_Towards_Novel_Anomaly_Class_Discovery_in_Industrial_Scenarios_CVPR_2025_paper.pdf) | |
| Ges3ViG : Incorporating Pointing Gestures into Language-Based 3D Visual Grounding for Embodied Reference Understanding | [code](https://github.com/AtharvMane/Ges3ViG) |  | Python | 6 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mane_Ges3ViG__Incorporating_Pointing_Gestures_into_Language-Based_3D_Visual_Grounding_CVPR_2025_paper.pdf) | |
| BiomedCoOp: Learning to Prompt for Biomedical Vision-Language Models | [code](https://github.com/HealthX-Lab/BiomedCoOp) | [CVPR 2025] Official implementation of BiomedCoOp | Python | 106 | 12 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Koleilat_BiomedCoOp_Learning_to_Prompt_for_Biomedical_Vision-Language_Models_CVPR_2025_paper.pdf) | |
| AnySat: One Earth Observation Model for Many Resolutions; Scales; and Modalities | [code](https://github.com/gastruc/AnySat) |  | Python | 179 | 13 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Astruc_AnySat_One_Earth_Observation_Model_for_Many_Resolutions_Scales_and_CVPR_2025_paper.pdf) | |
| VideoComp: Advancing Fine-Grained Compositional and Temporal Alignment in Video-Text Models | [code](https://github.com/google-deepmind/video_comp) |  |  | 6 | 0 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_VideoComp_Advancing_Fine-Grained_Compositional_and_Temporal_Alignment_in_Video-Text_Models_CVPR_2025_paper.pdf) | |
| One Model for ALL: Low-Level Task Interaction Is a Key to Task-Agnostic Image Fusion | [code](https://github.com/AWCXV/GIFNet) | (2025' CVPR) This is the official code for the paper titled "One Model for ALL: Low-Level Task Interaction Is a Key to Task-Agnostic Image Fusion". | Python | 63 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_One_Model_for_ALL_Low-Level_Task_Interaction_Is_a_Key_CVPR_2025_paper.pdf) | |
| GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving | [code](https://github.com/YvanYin/GoalFlow) | Repo of "GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving" | Python | 340 | 35 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_GoalFlow_Goal-Driven_Flow_Matching_for_Multimodal_Trajectories_Generation_in_End-to-End_CVPR_2025_paper.pdf) | |
| GuardSplat: Efficient and Robust Watermarking for 3D Gaussian Splatting | [code](https://github.com/NarcissusEx/GuardSplat) | [CVPR 2025] GuardSplat: Efficient and Robust Watermarking for 3D Gaussian Splatting | Python | 41 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_GuardSplat_Efficient_and_Robust_Watermarking_for_3D_Gaussian_Splatting_CVPR_2025_paper.pdf) | |
| Weakly Supervised Contrastive Adversarial Training for Learning Robust Features from Semi-supervised Data | [code](https://github.com/zhang-lilin/WSCAT) | Implementation code for "Weakly Supervised Contrastive Adversarial Training for Learning Robust Features from Semi-supervised Data". | Python | 0 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Weakly_Supervised_Contrastive_Adversarial_Training_for_Learning_Robust_Features_from_CVPR_2025_paper.pdf) | |
| ColabSfM: Collaborative Structure-from-Motion by Point Cloud Registration | [code](https://github.com/EricssonResearch/ColabSfM) |  | Python | 23 | 0 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Edstedt_ColabSfM_Collaborative_Structure-from-Motion_by_Point_Cloud_Registration_CVPR_2025_paper.pdf) | |
| Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World | [code](https://github.com/WU-CVGL/GlobustVP) | [CVPR 2025 Award Candidate & Oral] Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World | Python | 134 | 5 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_Convex_Relaxation_for_Robust_Vanishing_Point_Estimation_in_Manhattan_World_CVPR_2025_paper.pdf) | |
| Linguistics-aware Masked Image Modeling for Self-supervised Scene Text Recognition | [code](https://github.com/zhangyifei01/LMIM) | Linguistics-aware Masked Image Modeling for Self-supervised Scene Text Recognition | Python | 14 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Linguistics-aware_Masked_Image_Modeling_for_Self-supervised_Scene_Text_Recognition_CVPR_2025_paper.pdf) | |
| Take the Bull by the Horns: Learning to Segment Hard Samples | [code](https://github.com/TqlYuanGie/L2S) |  |  | 0 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Take_the_Bull_by_the_Horns_Learning_to_Segment_Hard_CVPR_2025_paper.pdf) | |
| MIMO: A Medical Vision Language Model with Visual Referring Multimodal Input and Pixel Grounding Multimodal Output | [code](https://github.com/pkusixspace/MIMO) |  |  | 10 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_MIMO_A_Medical_Vision_Language_Model_with_Visual_Referring_Multimodal_CVPR_2025_paper.pdf) | |
| Blood Flow Speed Estimation with Optical Coherence Tomography Angiography Images | [code](https://github.com/Spritea/OCTA-Flow) | Blood Flow Speed Estimation with Optical Coherence Tomography Angiography Images [CVPR 2025] | Python | 10 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_Blood_Flow_Speed_Estimation_with_Optical_Coherence_Tomography_Angiography_Images_CVPR_2025_paper.pdf) | |
| DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation | [code](https://github.com/VILA-Lab/DELT) | (CVPR 2025) Official implementation to DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation which outperforms SOTA top 1-acc by +1.3% and increases diversity per class by +5% | Python | 26 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_DELT_A_Simple_Diversity-driven_EarlyLate_Training_for_Dataset_Distillation_CVPR_2025_paper.pdf) | |
| MESC-3D:Mining Effective Semantic Cues for 3D Reconstruction from a Single Image | [code](https://github.com/QINGQINGLE/MESC-3D) | Our code will be released soon. | Python | 28 | 2 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MESC-3DMining_Effective_Semantic_Cues_for_3D_Reconstruction_from_a_Single_CVPR_2025_paper.pdf) | |
| TAET: Two-Stage Adversarial Equalization Training on Long-Tailed  Distributions | [code](https://github.com/BuhuiOK/TAET-Two-Stage-Adversarial-Equalization-Training-on-Long-Tailed-Distributions) |  | Jupyter Notebook | 9 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu-Hang_TAET_Two-Stage_Adversarial_Equalization_Training_on_Long-Tailed__Distributions_CVPR_2025_paper.pdf) | |
| Few-shot Personalized Scanpath Prediction | [code](https://github.com/cvlab-stonybrook/few-shot-scanpath) |  | Python | 14 | 3 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_Few-shot_Personalized_Scanpath_Prediction_CVPR_2025_paper.pdf) | |
| Do Your Best and Get Enough Rest for Continual Learning | [code](https://github.com/hankyul2/ViewBatchModel) | [CVPR'25] Do Your Best and Get Enough Rest for Continual Learning | Python | 18 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kang_Do_Your_Best_and_Get_Enough_Rest_for_Continual_Learning_CVPR_2025_paper.pdf) | |
| Enhancing Few-Shot Class-Incremental Learning via Training-Free Bi-Level Modality Calibration | [code](https://github.com/yychen016/BiMC) |  |  | 12 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Enhancing_Few-Shot_Class-Incremental_Learning_via_Training-Free_Bi-Level_Modality_Calibration_CVPR_2025_paper.pdf) | |
| Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models | [code](https://github.com/lntzm/HICom) | [CVPR2025] Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models | Python | 16 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hybrid-Level_Instruction_Injection_for_Video_Token_Compression_in_Multi-modal_Large_CVPR_2025_paper.pdf) | |
| Mamba4D: Efficient 4D Point Cloud Video Understanding with Disentangled Spatial-Temporal State Space Models | [code](https://github.com/IRMVLab/Mamba4D) | [CVPR 2025] Official codes for the paper 'Mamba4D: Efficient 4D Point Cloud Video Understanding with Disentangled Spatial-Temporal State Space Models' | Python | 34 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Mamba4D_Efficient_4D_Point_Cloud_Video_Understanding_with_Disentangled_Spatial-Temporal_CVPR_2025_paper.pdf) | |
| Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation | [code](https://github.com/devinxzhang/MFuser) | [CVPR 2025 Highlight] Official code for paper "Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation" | Python | 52 | 5 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Mamba_as_a_Bridge_Where_Vision_Foundation_Models_Meet_Vision_CVPR_2025_paper.pdf) | |
| ChainHOI: Joint-based Kinematic Chain Modeling for Human-Object Interaction Generation | [code](https://github.com/qinghuannn/ChainHOI) |  |  | 17 | 0 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_ChainHOI_Joint-based_Kinematic_Chain_Modeling_for_Human-Object_Interaction_Generation_CVPR_2025_paper.pdf) | |
| Universal Actions for Enhanced Embodied Foundation Models | [code](https://github.com/2toinf/UniAct) | [CVPR 2025] The offical Implementation of "Universal Actions for Enhanced Embodied Foundation Models" | Python | 224 | 11 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Universal_Actions_for_Enhanced_Embodied_Foundation_Models_CVPR_2025_paper.pdf) | |
| Learning to Filter Outlier Edges in Global SfM | [code](https://github.com/DmblnNicole/LFOE-GlobalSfM) | Learning to Filter Outlier Edges in Global SfM. | C++ | 9 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Damblon_Learning_to_Filter_Outlier_Edges_in_Global_SfM_CVPR_2025_paper.pdf) | |
| WAVE: Weight Templates for Adaptive Initialization of Variable-sized Models | [code](https://github.com/fu-feng/WAVE) | WAVE: Weight Templates for Adaptive Initialization of Variable-sized Models. CVPR2025 |  | 0 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_WAVE_Weight_Templates_for_Adaptive_Initialization_of_Variable-sized_Models_CVPR_2025_paper.pdf) | |
| KAC: Kolmogorov-Arnold Classifier for Continual Learning | [code](https://github.com/Ethanhuhuhu/KAC) |  | Python | 16 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_KAC_Kolmogorov-Arnold_Classifier_for_Continual_Learning_CVPR_2025_paper.pdf) | |
| BOOTPLACE: Bootstrapped Object Placement with Detection Transformers | [code](https://github.com/RyanHangZhou/BOOTPLACE) | PyTorch Implementation of "BOOTPLACE: Bootstrapped Object Placement with Detection Transformers", CVPR 2025 | Python | 24 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_BOOTPLACE_Bootstrapped_Object_Placement_with_Detection_Transformers_CVPR_2025_paper.pdf) | |
| FASTer: Focal token Acquiring-and-Scaling Transformer for Long-term 3D Objection Detection | [code](https://github.com/MSunDYY/FASTer.git) | [CVPR 2025] FASTer: Focal Token Acquiring-and-Scaling Transformer for Long-term 3D Object Detection | Python | 11 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dang_FASTer_Focal_token_Acquiring-and-Scaling_Transformer_for_Long-term_3D_Objection_Detection_CVPR_2025_paper.pdf) | |
| LibraGrad: Balancing Gradient Flow for Universally Better Vision Transformer Attributions | [code](https://github.com/NightMachinery/LibraGrad) | Balancing Gradient Flow for Universally Better Vision Transformer Attributions | Jupyter Notebook | 10 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mehri_LibraGrad_Balancing_Gradient_Flow_for_Universally_Better_Vision_Transformer_Attributions_CVPR_2025_paper.pdf) | |
| Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and Deceptive Jailbreaking | [code](https://github.com/fhdnskfbeuv/attackIPA) | Jailbreaking T2I-DM equipped with the IP-Adapter | Python | 11 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Mind_the_Trojan_Horse_Image_Prompt_Adapter_Enabling_Scalable_and_CVPR_2025_paper.pdf) | |
| Continual SFT Matches Multimodal RLHF with Negative Supervision | [code](https://github.com/Kevinz-code/nSFT/) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Continual_SFT_Matches_Multimodal_RLHF_with_Negative_Supervision_CVPR_2025_paper.pdf) | |
| Scene-Centric Unsupervised Panoptic Segmentation | [code](https://github.com/visinf/cups) | Scene-Centric Unsupervised Panoptic Segmentation (CVPR 2025 Highlight) | Python | 79 | 6 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hahn_Scene-Centric_Unsupervised_Panoptic_Segmentation_CVPR_2025_paper.pdf) | |
| Learning Physics From Video: Unsupervised Physical Parameter Estimation for Continuous Dynamical Systems | [code](https://github.com/Alejandro-neuro/Learning_physics_from_video) |  | Jupyter Notebook | 14 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Garcia_Learning_Physics_From_Video_Unsupervised_Physical_Parameter_Estimation_for_Continuous_CVPR_2025_paper.pdf) | |
| Auto-Encoded Supervision for Perceptual Image Super-Resolution | [code](https://github.com/2minkyulee/AESOP-Auto-Encoded-Supervision-for-Perceptual-Image-Super-Resolution) | [CVPR2025] Official Repository for AESOP: Auto-Encoded Supervision for Perceptual Image Super-Resolution | Python | 82 | 2 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Auto-Encoded_Supervision_for_Perceptual_Image_Super-Resolution_CVPR_2025_paper.pdf) | |
| Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise | [code](https://github.com/Eyeline-Research/Go-with-the-Flow) | We rebranded https://github.com/Eyeline-Labs  |  | 0 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Burgert_Go-with-the-Flow_Motion-Controllable_Video_Diffusion_Models_Using_Real-Time_Warped_Noise_CVPR_2025_paper.pdf) | |
| Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation | [code](https://github.com/yuangan/Silencer) | [CVPR 2025] Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation | Python | 19 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gan_Silence_is_Golden_Leveraging_Adversarial_Examples_to_Nullify_Audio_Control_CVPR_2025_paper.pdf) | |
| MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research | [code](https://huggingface.co/datasets/jmhb/microvqa) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Burgess_MicroVQA_A_Multimodal_Reasoning_Benchmark_for_Microscopy-Based_Scientific_Research_CVPR_2025_paper.pdf) | |
| CustAny: Customizing Anything from A Single Example | [code](https://github.com/LingjieKong-fdu/CustAny) | Official code for CustAny: Customizing Anything from A Single Example. Accepted by CVPR2025 (Oral) |  | 48 | 0 | 10 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kong_CustAny_Customizing_Anything_from_A_Single_Example_CVPR_2025_paper.pdf) | |
| 3D-LLaVA: Towards Generalist 3D LMMs with Omni Superpoint Transformer | [code](https://github.com/djiajunustc/3D-LLaVA) | [CVPR 2025] 3D-LLaVA: Towards Generalist 3D LMMs with Omni Superpoint Transformer | Python | 85 | 6 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_3D-LLaVA_Towards_Generalist_3D_LMMs_with_Omni_Superpoint_Transformer_CVPR_2025_paper.pdf) | |
| Masked Scene Modeling: Narrowing the Gap Between Supervised and Self-Supervised Learning in 3D Scene Understanding | [code](https://github.com/phermosilla/msm) | Official repostory of the paper: Masked Scene Modeling (CVPR 2025) | Python | 16 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hermosilla_Masked_Scene_Modeling_Narrowing_the_Gap_Between_Supervised_and_Self-Supervised_CVPR_2025_paper.pdf) | |
| Boost the Inference with Co-training: A Depth-guided Mutual Learning Framework for Semi-supervised Medical Polyp Segmentation | [code](https://github.com/pingchuan/RD-Net) | Boost the Inference with Co-training: A Depth-guided Mutual Learning Framework for Semi-supervised Medical Polyp Segmentation (CVPR 2025) | Python | 13 | 0 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Boost_the_Inference_with_Co-training_A_Depth-guided_Mutual_Learning_Framework_CVPR_2025_paper.pdf) | |
| From Laboratory to Real World: A New Benchmark Towards Privacy-Preserved Visible-Infrared Person Re-Identification | [code](https://github.com/Joey623/L2RW) | [CVPR2025] From Laboratory to Real World: A New Benchmark Towards Privacy-Preserved Visible-Infrared Person Re-Identification | Jupyter Notebook | 16 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_From_Laboratory_to_Real_World_A_New_Benchmark_Towards_Privacy-Preserved_CVPR_2025_paper.pdf) | |
| Interpreting Object-level Foundation Models via Visual Precision Search | [code](https://github.com/RuoyuChen10/VPS) | [CVPR 2025 Highlight] Interpreting Object-level Foundation Models via Visual Precision Search | Jupyter Notebook | 54 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Interpreting_Object-level_Foundation_Models_via_Visual_Precision_Search_CVPR_2025_paper.pdf) | |
| PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter | [code](https://github.com/zyh16143998882/PMA) | The code for the paper "PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter" (CVPR'25). | Python | 2 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zha_PMA_Towards_Parameter-Efficient_Point_Cloud_Understanding_via_Point_Mamba_Adapter_CVPR_2025_paper.pdf) | |
| LC-Mamba: Local and Continuous Mamba with Shifted Windows for Frame Interpolation | [code](https://github.com/Miinuuu/LC-Mamba.git) |  | Python | 8 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_LC-Mamba_Local_and_Continuous_Mamba_with_Shifted_Windows_for_Frame_CVPR_2025_paper.pdf) | |
| CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment | [code](https://github.com/edsonroteia/cav-mae-sync) | [CVPR25] Official Implementation of CAV-MAE Sync | Python | 30 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Araujo_CAV-MAE_Sync_Improving_Contrastive_Audio-Visual_Mask_Autoencoders_via_Fine-Grained_Alignment_CVPR_2025_paper.pdf) | |
| Dual Consolidation for Pre-Trained Model-Based Domain-Incremental Learning | [code](https://github.com/Estrella-fugaz/CVPR25-Duct) | Dual Consolidation for Pre-Trained Model-Based Domain-Incremental Learning ï¼ˆCVPR 2025ï¼‰ | Python | 28 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Dual_Consolidation_for_Pre-Trained_Model-Based_Domain-Incremental_Learning_CVPR_2025_paper.pdf) | |
| EmoEdit: Evoking Emotions through Image Manipulation | [code](https://github.com/JingyuanYY/EmoEdit) | This is the official implementation of 2025 CVPR paper "EmoEdit: Evoking Emotions through Image Manipulation". | Python | 34 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_EmoEdit_Evoking_Emotions_through_Image_Manipulation_CVPR_2025_paper.pdf) | |
| RORem: Training a Robust Object Remover with Human-in-the-Loop | [code](https://github.com/leeruibin/RORem) | [CVPR2025] RORem: Training a Robust Object Remover with Human-in-the-Loop | Python | 62 | 3 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_RORem_Training_a_Robust_Object_Remover_with_Human-in-the-Loop_CVPR_2025_paper.pdf) | |
| TopoCellGen: Generating Histopathology Cell Topology with a Diffusion Model | [code](https://github.com/Melon-Xu/TopoCellGen) |  | Python | 23 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_TopoCellGen_Generating_Histopathology_Cell_Topology_with_a_Diffusion_Model_CVPR_2025_paper.pdf) | |
| Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video | [code](https://github.com/HoangChuongNguyen/cope-nerf) | Joint optimization of NeRF and continuous camera motions from a monocular video.  | Python | 7 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_Joint_Optimization_of_Neural_Radiance_Fields_and_Continuous_Camera_Motion_CVPR_2025_paper.pdf) | |
| A Data-Centric Revisit of Pre-Trained Vision Models for Robot Learning | [code](https://github.com/CVMI-Lab/SlotMIM) | (CVPR 2025) A Data-Centric Revisit of Pre-Trained Vision Models for Robot Learning | Python | 22 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wen_A_Data-Centric_Revisit_of_Pre-Trained_Vision_Models_for_Robot_Learning_CVPR_2025_paper.pdf) | |
| TAMT: Temporal-Aware Model Tuning for Cross-Domain Few-Shot Action Recognition | [code](https://github.com/TJU-YDragonW/TAMT) |  | Python | 14 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TAMT_Temporal-Aware_Model_Tuning_for_Cross-Domain_Few-Shot_Action_Recognition_CVPR_2025_paper.pdf) | |
| BioX-CPath: Biologically-driven Explainable Diagnostics for Multistain IHC Computational Pathology | [code](https://github.com/AmayaGS/BioX-CPath) | A biologically interpretable graph neural network for multistain computational pathology - CVPR 2025 | Python | 26 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gallagher-Syed_BioX-CPath_Biologically-driven_Explainable_Diagnostics_for_Multistain_IHC_Computational_Pathology_CVPR_2025_paper.pdf) | |
| Wavelet and Prototype Augmented Query-based Transformer for Pixel-level Surface Defect Detection | [code](https://github.com/yfhdm/WPFormer) | [CVPR 2025] \| Wavelet and Prototype Augmented Query-based Transformer for Pixel-level Surface Defect Detection | Python | 64 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Wavelet_and_Prototype_Augmented_Query-based_Transformer_for_Pixel-level_Surface_Defect_CVPR_2025_paper.pdf) | |
| GaussianWorld: Gaussian World Model for Streaming 3D Occupancy Prediction | [code](https://github.com/zuosc19/GaussianWorld) |  | Python | 136 | 8 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zuo_GaussianWorld_Gaussian_World_Model_for_Streaming_3D_Occupancy_Prediction_CVPR_2025_paper.pdf) | |
| Optimizing for the Shortest Path in Denoising Diffusion Model | [code](https://github.com/UnicomAI/ShortDF) | Optimizing for the Shortest Path in Denoising Diffusion Model (CVPR2025) | Python | 21 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Optimizing_for_the_Shortest_Path_in_Denoising_Diffusion_Model_CVPR_2025_paper.pdf) | |
| Language-Guided Audio-Visual Learning for Long-Term Sports Assessment | [code](https://github.com/XuHuangbiao/MLAVL) | [CVPR'25] Code for ''Language-Guided Audio-Visual Learning for Long-Term Sports Assessment'' | Python | 10 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Language-Guided_Audio-Visual_Learning_for_Long-Term_Sports_Assessment_CVPR_2025_paper.pdf) | |
| WeakMCN: Multi-task Collaborative Network for Weakly Supervised Referring Expression Comprehension and Segmentation | [code](https://github.com/MRUIL/WeakMCN) |  | Jupyter Notebook | 68 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_WeakMCN_Multi-task_Collaborative_Network_for_Weakly_Supervised_Referring_Expression_Comprehension_CVPR_2025_paper.pdf) | |
| Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation | [code](https://github.com/Wakals/GASCOL) | Official implementary of HCoG: Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation [CVPR 2025] | Python | 58 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_Apply_Hierarchical-Chain-of-Generation_to_Complex_Attributes_Text-to-3D_Generation_CVPR_2025_paper.pdf) | |
| PersonaHOI: Effortlessly Improving Face Personalization in Human-Object Interaction Generation | [code](https://github.com/JoyHuYY1412/PersonaHOI) |  |  | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_PersonaHOI_Effortlessly_Improving_Face_Personalization_in_Human-Object_Interaction_Generation_CVPR_2025_paper.pdf) | |
| COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation | [code](http://github.com/hf618/COSMIC) |  | Python | 13 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_COSMIC_Clique-Oriented_Semantic_Multi-space_Integration_for_Robust_CLIP_Test-Time_Adaptation_CVPR_2025_paper.pdf) | |
| MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth Foundation Models | [code](https://github.com/CUHK-AIM-Group/MonoSplat) | [CVPR'25] MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth Foundation Models | Python | 59 | 5 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MonoSplat_Generalizable_3D_Gaussian_Splatting_from_Monocular_Depth_Foundation_Models_CVPR_2025_paper.pdf) | |
| Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation | [code](https://github.com/fhgyuanshen/HybridGL) | [CVPR 2025] Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation | Python | 29 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hybrid_Global-Local_Representation_with_Augmented_Spatial_Guidance_for_Zero-Shot_Referring_CVPR_2025_paper.pdf) | |
| Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection | [code](https://github.com/xiaohainku/EASE) | [CVPR 2025] Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection | Python | 7 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Du_Shift_the_Lens_Environment-Aware_Unsupervised_Camouflaged_Object_Detection_CVPR_2025_paper.pdf) | |
| Every SAM Drop Counts: Embracing Semantic Priors for Multi-Modality Image Fusion and Beyond | [code](https://github.com/RollingPlain/SAGE_IVIF) | CVPR 2025 \| Every SAM Drop Counts: Embracing Semantic Priors for Multi-Modality Image Fusion and Beyond | Python | 92 | 7 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Every_SAM_Drop_Counts_Embracing_Semantic_Priors_for_Multi-Modality_Image_CVPR_2025_paper.pdf) | |
| EgoLife: Towards Egocentric Life Assistant | [code](https://github.com/EvolvingLMMs-Lab/EgoLife) | [CVPR 2025] EgoLife: Towards Egocentric Life Assistant | Python | 373 | 19 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_EgoLife_Towards_Egocentric_Life_Assistant_CVPR_2025_paper.pdf) | |
| Prior-free 3D Object Tracking | [code](https://github.com/songxiuqiang/BIT.git) | The sources codes of BIT. | C++ | 18 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Song_Prior-free_3D_Object_Tracking_CVPR_2025_paper.pdf) | |
| Progressive Correspondence Regenerator for Robust 3D Registration | [code](https://github.com/GuiyuZhao/Regor) | [CVPR 2025] Progressive Correspondence Regenerator for Robust 3D Registration | Python | 15 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Progressive_Correspondence_Regenerator_for_Robust_3D_Registration_CVPR_2025_paper.pdf) | |
| Full-DoF Egomotion Estimation for Event Cameras Using Geometric Solvers | [code](https://github.com/jizhaox/relpose-event) | [CVPR 2025] This is the official implementation of [Full-DoF Egomotion Estimation for Event Cameras Using Geometric Solvers] | C++ | 12 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Full-DoF_Egomotion_Estimation_for_Event_Cameras_Using_Geometric_Solvers_CVPR_2025_paper.pdf) | |
| 3DGUT: Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting | [code](https://github.com/nv-tlabs/3dgrut) | Ray tracing and hybrid rasterization of Gaussian particles | Python | 1830 | 176 | 36 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_3DGUT_Enabling_Distorted_Cameras_and_Secondary_Rays_in_Gaussian_Splatting_CVPR_2025_paper.pdf) | |
| Marten: Visual Question Answering with Mask Generation for Multi-modal Document Understanding | [code](https://github.com/PriNing/Marten) | Visual Question Answering with Mask generation | Python | 11 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Marten_Visual_Question_Answering_with_Mask_Generation_for_Multi-modal_Document_CVPR_2025_paper.pdf) | |
| Open Set Label Shift with Test Time Out-of-Distribution Reference | [code](https://github.com/ChangkunYe/OpenSetLabelShift) | This is the official implementation of the CVPR 2025 paper "Open Set Label Shift with Test Time Out-of-Distribution Reference". | Python | 3 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Open_Set_Label_Shift_with_Test_Time_Out-of-Distribution_Reference_CVPR_2025_paper.pdf) | |
| Pixel-level and Semantic-level Adjustable Super-resolution: A Dual-LoRA Approach | [code](https://github.com/csslc/PiSA-SR) | [CVPR 2025] Official code repository for "Pixel-level and Semantic-level Adjustable Super-resolution: A Dual-LoRA Approach" | Python | 286 | 8 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Pixel-level_and_Semantic-level_Adjustable_Super-resolution_A_Dual-LoRA_Approach_CVPR_2025_paper.pdf) | |
| Let Samples Speak: Mitigating Spurious Correlation by Exploiting the Clusterness of Samples | [code](https://github.com/davelee-uestc/nsf_debiasing) |  | Python | 5 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Let_Samples_Speak_Mitigating_Spurious_Correlation_by_Exploiting_the_Clusterness_CVPR_2025_paper.pdf) | |
| Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes | [code](https://github.com/Dou-Yiming/hearing_hands/) | [CVPR 2025] Official repository for "Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes".  | Python | 9 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dou_Hearing_Hands_Generating_Sounds_from_Physical_Interactions_in_3D_Scenes_CVPR_2025_paper.pdf) | |
| Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language Models | [code](https://github.com/BerasiDavide/vlm_image_compositionality) | [CVPR'25] Official implementation of the paper "Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language Models". | Python | 16 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Berasi_Not_Only_Text_Exploring_Compositionality_of_Visual_Representations_in_Vision-Language_CVPR_2025_paper.pdf) | |
| Exploring Scene Affinity for Semi-Supervised LiDAR Semantic Segmentation | [code](https://github.com/azhuantou/AIScene) | [CVPR 2025] Exploring Scene Affinity for Semi-Supervised LiDAR Semantic Segmentation |  | 1 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Exploring_Scene_Affinity_for_Semi-Supervised_LiDAR_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| Minority-Focused Text-to-Image Generation via Prompt Optimization | [code](https://github.com/soobin-um/MinorityPrompt) | Official PyTorch Implementation of "Minority-Focused Text-to-Image Generation via Prompt Optimization" (CVPR 2025 Oral) | Python | 27 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Um_Minority-Focused_Text-to-Image_Generation_via_Prompt_Optimization_CVPR_2025_paper.pdf) | |
| SCSegamba: Lightweight Structure-Aware Vision Mamba for Crack Segmentation in Structures | [code](https://github.com/Karl1109/SCSegamba) | [CVPR 2025] SCSegamba: Lightweight Structure-Aware Vision Mamba for Crack Segmentation in Structures | Python | 220 | 20 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_SCSegamba_Lightweight_Structure-Aware_Vision_Mamba_for_Crack_Segmentation_in_Structures_CVPR_2025_paper.pdf) | |
| Number it: Temporal Grounding Videos like Flipping Manga | [code](https://github.com/yongliang-wu/NumPro) | [CVPR2025] Number it: Temporal Grounding Videos like Flipping Manga | Python | 142 | 6 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Number_it_Temporal_Grounding_Videos_like_Flipping_Manga_CVPR_2025_paper.pdf) | |
| RGBAvatar: Reduced Gaussian Blendshapes for Online Modeling of Head Avatars | [code](https://github.com/gapszju/RGBAvatar) | RGBAvatar: Reduced Gaussian Blendshapes for Online Modeling of Head Avatars | Python | 120 | 13 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_RGBAvatar_Reduced_Gaussian_Blendshapes_for_Online_Modeling_of_Head_Avatars_CVPR_2025_paper.pdf) | |
| ReCon: Enhancing True Correspondence Discrimination through Relation Consistency for Robust Noisy Correspondence Learning | [code](https://github.com/qxzha/ReCon) | Enhancing True Correspondence Discrimination through Relation Consistency for Robust Noisy Correspondence Learning (CVPR 2025, pytorch code) | Python | 14 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zha_ReCon_Enhancing_True_Correspondence_Discrimination_through_Relation_Consistency_for_Robust_CVPR_2025_paper.pdf) | |
| ECBench: Can Multi-modal Foundation Models Understand the Egocentric World? A Holistic Embodied Cognition Benchmark | [code](https://github.com/Rh-Dang/ECBench) | A Holistic Embodied Cognition Benchmark | Python | 18 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dang_ECBench_Can_Multi-modal_Foundation_Models_Understand_the_Egocentric_World_A_CVPR_2025_paper.pdf) | |
| SfM-Free 3D Gaussian Splatting via Hierarchical Training | [code](https://github.com/jibo27/3DGS_Hierarchical_Training/) | SfM-Free 3D Gaussian Splatting via Hierarchical Training | Python | 66 | 5 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ji_SfM-Free_3D_Gaussian_Splatting_via_Hierarchical_Training_CVPR_2025_paper.pdf) | |
| Large Self-Supervised Models Bridge the Gap in Domain Adaptive Object Detection | [code](https://github.com/TRAILab/DINO_Teacher) | Source code for "Large Self-Supervised Models Bridge the Gap in Domain Adaptive Object Detection"  | Python | 46 | 7 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lavoie_Large_Self-Supervised_Models_Bridge_the_Gap_in_Domain_Adaptive_Object_CVPR_2025_paper.pdf) | |
| Dynamic Updates for Language Adaptation in Visual-Language Tracking | [code](https://github.com/GXNU-ZhongLab/DUTrack) | The official implementation for the CVPR'2025 paper Dynamic Updates for Language Adaptation in Visual-Language Tracking | Python | 36 | 2 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Dynamic_Updates_for_Language_Adaptation_in_Visual-Language_Tracking_CVPR_2025_paper.pdf) | |
| Multi-focal Conditioned Latent Diffusion for Person Image Synthesis | [code](https://github.com/jqliu09/mcld) | [CVPR 2025] Multi-focal Conditioned Latent Diffusion for Person Image Synthesis | Python | 19 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Multi-focal_Conditioned_Latent_Diffusion_for_Person_Image_Synthesis_CVPR_2025_paper.pdf) | |
| MINIMA: Modality Invariant Image Matching | [code](https://github.com/LSXI7/MINIMA) | [CVPR 2025] MINIMA: Modality Invariant Image Matching | Python | 559 | 43 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_MINIMA_Modality_Invariant_Image_Matching_CVPR_2025_paper.pdf) | |
| OccMamba: Semantic Occupancy Prediction with State Space Models | [code](https://github.com/USTCLH/OccMamba) | [CVPR'25] OccMamba: Semantic Occupancy Prediction with State Space Models | Python | 46 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_OccMamba_Semantic_Occupancy_Prediction_with_State_Space_Models_CVPR_2025_paper.pdf) | |
| Is `Right' Right? Enhancing Object Orientation Understanding in Multimodal Large Language Models through Egocentric Instruction Tuning | [code](https://github.com/jhCOR/EgoOrientBench) | The Official Code Repo for EgoOrientBench [CVPR25] | Jupyter Notebook | 14 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Is_Right_Right_Enhancing_Object_Orientation_Understanding_in_Multimodal_Large_CVPR_2025_paper.pdf) | |
| On Denoising Walking Videos for Gait Recognition | [code](https://github.com/ShiqiYu/OpenGait) | A flexible and extensible framework for gait recognition. You can focus on designing your own models and comparing with state-of-the-arts easily with the help of OpenGait. | Python | 1025 | 215 | 14 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_On_Denoising_Walking_Videos_for_Gait_Recognition_CVPR_2025_paper.pdf) | |
| SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding | [code](https://github.com/zackhxn/SeriesBench-CVPR2025) |  |  | 2 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_SeriesBench_A_Benchmark_for_Narrative-Driven_Drama_Series_Understanding_CVPR_2025_paper.pdf) | |
| FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation | [code](https://github.com/ShiheWang/FIMA-Q) | [CVPR 2025 Highlight] FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation | Python | 21 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_FIMA-Q_Post-Training_Quantization_for_Vision_Transformers_by_Fisher_Information_Matrix_CVPR_2025_paper.pdf) | |
| Libra-Merging: Importance-redundancy and Pruning-merging Trade-off for Acceleration Plug-in in Large Vision-Language Model | [code](https://github.com/longrongyang/Libra-Merging) |  |  | 0 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Libra-Merging_Importance-redundancy_and_Pruning-merging_Trade-off_for_Acceleration_Plug-in_in_Large_CVPR_2025_paper.pdf) | |
| PanSplat: 4K Panorama Synthesis with Feed-Forward Gaussian Splatting | [code](https://github.com/chengzhag/PanSplat) | ðŸ³ [CVPR'25] PanSplat: 4K Panorama Synthesis with Feed-Forward Gaussian Splatting | Python | 199 | 13 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_PanSplat_4K_Panorama_Synthesis_with_Feed-Forward_Gaussian_Splatting_CVPR_2025_paper.pdf) | |
| Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting Conditions with View-Adaptive Curve Adjustment | [code](https://github.com/cuiziteng/Luminance-GS) | ðŸŒ• [CVPR 2025] Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting Conditions with View-Adaptive Curve Adjustment | Python | 59 | 5 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_Luminance-GS_Adapting_3D_Gaussian_Splatting_to_Challenging_Lighting_Conditions_with_CVPR_2025_paper.pdf) | |
| SemiDAViL: Semi-supervised Domain Adaptation with Vision-Language Guidance for Semantic Segmentation | [code](https://github.com/hritam-98/SemiDAViL) |  | Python | 9 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Basak_SemiDAViL_Semi-supervised_Domain_Adaptation_with_Vision-Language_Guidance_for_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| Learning Partonomic 3D Reconstruction from Image Collections | [code](https://github.com/XiaoqianRuan1/Partonomic_Reconstruction) |  | Python | 2 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ruan_Learning_Partonomic_3D_Reconstruction_from_Image_Collections_CVPR_2025_paper.pdf) | |
| ODA-GAN: Orthogonal Decoupling Alignment GAN Assisted by Weakly-supervised Learning for Virtual Immunohistochemistry Staining | [code](https://github.com/ittong/ODA-GAN) |  |  | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_ODA-GAN_Orthogonal_Decoupling_Alignment_GAN_Assisted_by_Weakly-supervised_Learning_for_CVPR_2025_paper.pdf) | |
| Crab: A Unified Audio-Visual Scene Understanding Model with Explicit Cooperation | [code](https://github.com/GeWu-Lab/Crab) | [CVPR 2025] Crab: A Unified Audio-Visual Scene Understanding Model with Explicit Cooperation | Python | 80 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Du_Crab_A_Unified_Audio-Visual_Scene_Understanding_Model_with_Explicit_Cooperation_CVPR_2025_paper.pdf) | |
| Nullu: Mitigating Object Hallucinations in Large Vision-Language Models via HalluSpace Projection | [code](https://github.com/Ziwei-Zheng/Nullu) | Code for paper: Nullu: Mitigating Object Hallucinations in Large Vision-Language Models via HalluSpace Projection | OpenEdge ABL | 49 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Nullu_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_via_HalluSpace_CVPR_2025_paper.pdf) | |
| Audio-Visual Instance Segmentation | [code](https://github.com/ruohaoguo/avis) | [CVPR 2025] ðŸ”¥ Official impl. of "Audio-Visual Instance Segmentation". | Python | 41 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Audio-Visual_Instance_Segmentation_CVPR_2025_paper.pdf) | |
| Probabilistic Prompt Distribution Learning for Animal Pose Estimation | [code](https://github.com/Raojiyong/PPAP) | [CVPR 2025] PPAP: Probabilistic Prompt Distribution Learning for Animal Pose Estimation |  | 11 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Rao_Probabilistic_Prompt_Distribution_Learning_for_Animal_Pose_Estimation_CVPR_2025_paper.pdf) | |
| Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention | [code](https://github.com/Lackel/AGLA) | [CVPR 2025] Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention | Python | 59 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/An_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_with_Assembly_of_CVPR_2025_paper.pdf) | |
| VGGT: Visual Geometry Grounded Transformer | [code](https://github.com/facebookresearch/vggt) | [CVPR 2025 Best Paper Award] VGGT: Visual Geometry Grounded Transformer | Python | 12181 | 1291 | 480 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VGGT_Visual_Geometry_Grounded_Transformer_CVPR_2025_paper.pdf) | |
| UniSTD: Towards Unified Spatio-Temporal Learning across Diverse Disciplines | [code](https://github.com/1hunters/UniSTD) |  |  | 0 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_UniSTD_Towards_Unified_Spatio-Temporal_Learning_across_Diverse_Disciplines_CVPR_2025_paper.pdf) | |
| Visual Consensus Prompting for Co-Salient Object Detection | [code](https://github.com/WJ-CV/VCP) |  |  | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Visual_Consensus_Prompting_for_Co-Salient_Object_Detection_CVPR_2025_paper.pdf) | |
| UniHOPE: A Unified Approach for Hand-Only and Hand-Object Pose Estimation | [code](https://github.com/JoyboyWang/UniHOPE_Pytorch) | This is the official implementation of our paper, UniHOPE: A Unified Approach for Hand-Only and Hand-Object Pose Estimation | Python | 16 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_UniHOPE_A_Unified_Approach_for_Hand-Only_and_Hand-Object_Pose_Estimation_CVPR_2025_paper.pdf) | |
| Quantization without Tears | [code](https://github.com/wujx2001/QwT) | Official PyTorch implementation of QwTâ€”â€œQuantization without Tearsâ€ (CVPR 2025): fast, accurate, and hassle-free post-training network quantization with lightweight linear compensation layers. | Python | 29 | 3 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Quantization_without_Tears_CVPR_2025_paper.pdf) | |
| PHGC: Procedural Heterogeneous Graph Completion for Natural Language Task Verification in Egocentric Videos | [code](https://github.com/XunCHN/PHGC) |  | Python | 3 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_PHGC_Procedural_Heterogeneous_Graph_Completion_for_Natural_Language_Task_Verification_CVPR_2025_paper.pdf) | |
| Recognition-Synergistic Scene Text Editing | [code](https://github.com/ZhengyaoFang/RS-STE) | The official implementation of RS-STE proposed by our paper Recognition-Synergistic Scene Text Editing (CVPR 2025). | Python | 29 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Recognition-Synergistic_Scene_Text_Editing_CVPR_2025_paper.pdf) | |
| Rectified Diffusion Guidance for Conditional Generation | [code](https://github.com/thuxmf/recfg) | [CVPR 2025] Official PyTorch implementation of Rectified Diffusion Guidance for Conditional Generation | Python | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Rectified_Diffusion_Guidance_for_Conditional_Generation_CVPR_2025_paper.pdf) | |
| FloVD: Optical Flow Meets Video Diffusion Model for Enhanced Camera-Controlled Video Synthesis | [code](https://github.com/JinWonjoon/FloVD) | FloVD official pytorch codes | Python | 44 | 4 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_FloVD_Optical_Flow_Meets_Video_Diffusion_Model_for_Enhanced_Camera-Controlled_CVPR_2025_paper.pdf) | |
| AutoLUT: LUT-Based Image Super-Resolution with Automatic Sampling and Adaptive Residual Learning | [code](https://github.com/SuperKenVery/AutoLUT) | Official repo for CVPR 2025 paper AutoLUT: LUT-Based Image Super-Resolution with Automatic Sampling and Adaptive Residual Learning | Jupyter Notebook | 67 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_AutoLUT_LUT-Based_Image_Super-Resolution_with_Automatic_Sampling_and_Adaptive_Residual_CVPR_2025_paper.pdf) | |
| Fuzzy Multimodal Learning for Trusted Cross-modal Retrieval | [code](https://github.com/siyuancncd/FUME) | This is the official implementation of "Fuzzy Multimodal Learning for Trusted Cross-modal Retrieval" (CVPR 2025) | Python | 38 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_Fuzzy_Multimodal_Learning_for_Trusted_Cross-modal_Retrieval_CVPR_2025_paper.pdf) | |
| VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding | [code](https://github.com/KangsanKim07/VideoICL) | [CVPR2025] VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding | Python | 22 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_VideoICL_Confidence-based_Iterative_In-context_Learning_for_Out-of-Distribution_Video_Understanding_CVPR_2025_paper.pdf) | |
| Zero-Shot Image Restoration Using Few-Step Guidance of Consistency Models (and Beyond) | [code](https://github.com/tirer-lab/CM4IR) |  | Python | 20 | 6 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Garber_Zero-Shot_Image_Restoration_Using_Few-Step_Guidance_of_Consistency_Models_and_CVPR_2025_paper.pdf) | |
| Similarity-Guided Layer-Adaptive Vision Transformer for UAV Tracking | [code](https://github.com/GXNU-ZhongLab/SGLATrack) | Similarity-Guided Layer-Adaptive Vision Transformer for UAV Tracking (CVPR 2025) | Python | 78 | 6 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_Similarity-Guided_Layer-Adaptive_Vision_Transformer_for_UAV_Tracking_CVPR_2025_paper.pdf) | |
| MoEdit: On Learning Quantity Perception for Multi-object Image Editing | [code](https://github.com/Tear-kitty/MoEdit) | The source code of MoEdit |  | 5 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MoEdit_On_Learning_Quantity_Perception_for_Multi-object_Image_Editing_CVPR_2025_paper.pdf) | |
| Modeling Thousands of Human Annotators for Generalizable Text-to-Image Person Re-identification | [code](https://github.com/sssaury/HAM) | Code for Modeling Thousands of Human Annotators for Generalizable Text-to-Image Person Re-identification (CVPR2025) | Python | 35 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Modeling_Thousands_of_Human_Annotators_for_Generalizable_Text-to-Image_Person_Re-identification_CVPR_2025_paper.pdf) | |
| AeroGen: Enhancing Remote Sensing Object Detection with Diffusion-Driven Data Generation | [code](https://github.com/Sonettoo/AeroGen) | AeroGen: Enhancing Remote Sensing Object Detection with Diffusion-Driven Data Generation | Python | 135 | 14 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_AeroGen_Enhancing_Remote_Sensing_Object_Detection_with_Diffusion-Driven_Data_Generation_CVPR_2025_paper.pdf) | |
| Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key | [code](https://github.com/zhyang2226/OPA-DPO) | [CVPR 2025 (Oral)] Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key | Python | 100 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_DPO_On-Policy_Data_CVPR_2025_paper.pdf) | |
| Uncertainty-Instructed Structure Injection for Generalizable HD Map Construction | [code](https://github.com/xiaolul2/UIGenMap) | [CVPR2025] The code for "Uncertainty-Instructed Structure Injection for Generalizable HD Map Construction." | Python | 19 | 2 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Uncertainty-Instructed_Structure_Injection_for_Generalizable_HD_Map_Construction_CVPR_2025_paper.pdf) | |
| 5%>100%: Breaking Performance Shackles of Full Fine-Tuning on Visual Recognition Tasks | [code](https://github.com/Leiyi-Hu/mona) | The official implementation of [CVPR 2025] "5%>100%: Breaking Performance Shackles of Full Fine-Tuning on Visual Recognition Tasks". | Python | 389 | 18 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_5100_Breaking_Performance_Shackles_of_Full_Fine-Tuning_on_Visual_Recognition_CVPR_2025_paper.pdf) | |
| Steady Progress Beats Stagnation: Mutual Aid of Foundation and Conventional Models in Mixed Domain Semi-Supervised Medical Image Segmentation | [code](https://github.com/MQinghe/SynFoC) | [CVPR 2025] Steady Progress Beats Stagnation: Mutual Aid of Foundation and Conventional Models in Mixed Domain Semi-Supervised Medical Image Segmentation | Python | 32 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Steady_Progress_Beats_Stagnation_Mutual_Aid_of_Foundation_and_Conventional_CVPR_2025_paper.pdf) | |
| Towards More General Video-based Deepfake Detection through Facial Component Guided Adaptation for Foundation Model | [code](https://github.com/aiiu-lab/DFD-FCG) | [CVPR'25] Towards More General Video-based Deepfake Detection through Facial Feature Guided Adaptation for Foundation Model (DFD-FCG) | Python | 41 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Towards_More_General_Video-based_Deepfake_Detection_through_Facial_Component_Guided_CVPR_2025_paper.pdf) | |
| WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model | [code](https://github.com/PKU-YuanGroup/WF-VAE) | [CVPR 2025ðŸ”¥] Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model | Python | 190 | 9 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_WF-VAE_Enhancing_Video_VAE_by_Wavelet-Driven_Energy_Flow_for_Latent_CVPR_2025_paper.pdf) | |
| SP3D: Boosting Sparsely-Supervised 3D Object Detection via Accurate Cross-Modal Semantic Prompts | [code](https://github.com/xmuqimingxia/SP3D) | SP3D: Boosting Sparsely-Supervised 3D Object Detection via Accurate Cross-Modal Semantic Prompts. (CVPR2025-HighLight) | Python | 29 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_SP3D_Boosting_Sparsely-Supervised_3D_Object_Detection_via_Accurate_Cross-Modal_Semantic_CVPR_2025_paper.pdf) | |
| ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding | [code](https://huggingface.co/datasets/labelmaker/arkit_labelmaker) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ji_ARKit_LabelMaker_A_New_Scale_for_Indoor_3D_Scene_Understanding_CVPR_2025_paper.pdf) | |
| StreamingT2V: Consistent; Dynamic; and Extendable Long Video Generation from Text | [code](https://github.com/Picsart-AI-Research/StreamingT2V) | [CVPR 2025] StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text | Python | 1620 | 162 | 42 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Henschel_StreamingT2V_Consistent_Dynamic_and_Extendable_Long_Video_Generation_from_Text_CVPR_2025_paper.pdf) | |
| AFL: A Single-Round Analytic Approach for Federated Learning with Pre-trained Models | [code](https://github.com/ZHUANGHP/Analytic-federated-learning) | This repo will be continually updating analytic federated learning methods. | Python | 68 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/He_AFL_A_Single-Round_Analytic_Approach_for_Federated_Learning_with_Pre-trained_CVPR_2025_paper.pdf) | |
| BOLT: Boost Large Vision-Language Model Without Training for Long-form Video Understanding | [code](https://github.com/sming256/BOLT) | [CVPR2025] BOLT: Boost Large Vision-Language Model Without Training for Long-form Video Understanding |  | 36 | 2 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_BOLT_Boost_Large_Vision-Language_Model_Without_Training_for_Long-form_Video_CVPR_2025_paper.pdf) | |
| StyleSSP: Sampling StartPoint Enhancement for Training-free Diffusion-based Method for Style Transfer | [code](https://github.com/bytedance/StyleSSP) | [CVPR 2025] StyleSSP: Sampling StartPoint Enhancement for Training-free Diffusion-based Method for Style Transfer | Python | 76 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_StyleSSP_Sampling_StartPoint_Enhancement_for_Training-free_Diffusion-based_Method_for_Style_CVPR_2025_paper.pdf) | |
| One is Plenty: A Polymorphic Feature Interpreter for Immutable Heterogeneous Collaborative Perception | [code](https://github.com/yuchen-xia/PolyInter) |  | Python | 13 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_One_is_Plenty_A_Polymorphic_Feature_Interpreter_for_Immutable_Heterogeneous_CVPR_2025_paper.pdf) | |
| Towards All-in-One Medical Image Re-Identification | [code](https://github.com/tianyuan168326/All-in-One-MedReID-Pytorch) | Official Code for All-in-One Medical Image Re-Identification (CVPR2025) | Python | 18 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Towards_All-in-One_Medical_Image_Re-Identification_CVPR_2025_paper.pdf) | |
| SegAgent: Exploring Pixel Understanding Capabilities in MLLMs by Imitating Human Annotator Trajectories | [code](https://github.com/aim-uofa/SegAgent) | [CVPR2025] SegAgent: Exploring Pixel Understanding Capabilities in MLLMs by Imitating Human Annotator Trajectories | Python | 88 | 2 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_SegAgent_Exploring_Pixel_Understanding_Capabilities_in_MLLMs_by_Imitating_Human_CVPR_2025_paper.pdf) | |
| AMO Sampler: Enhancing Text Rendering with Overshooting | [code](https://github.com/hxixixh/amo-release) | Official implementation for CVPR 2025 paper "AMO Sampler: Enhancing Text Rendering with Overshooting" | Python | 30 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_AMO_Sampler_Enhancing_Text_Rendering_with_Overshooting_CVPR_2025_paper.pdf) | |
| Saliuitl: Ensemble Salience Guided Recovery of Adversarial Patches against CNNs | [code](https://github.com/Saliuitl/Saliuitl/tree/main) | Code for the CVPR2025 Paper "Saliuitl: Ensemble Salience Guided Recovery  of Adversarial Patches against CNNs" | Python | 4 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Victorica_Saliuitl_Ensemble_Salience_Guided_Recovery_of_Adversarial_Patches_against_CNNs_CVPR_2025_paper.pdf) | |
| ResCLIP: Residual Attention for Training-free Dense Vision-language Inference | [code](https://github.com/yvhangyang/ResCLIP) | Official implementation of ResCLIP: Residual Attention for Training-free Dense Vision-language Inference | Python | 56 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_ResCLIP_Residual_Attention_for_Training-free_Dense_Vision-language_Inference_CVPR_2025_paper.pdf) | |
| CPath-Omni: A Unified Multimodal Foundation Model for Patch and Whole Slide Image Analysis in Computational Pathology | [code](https://github.com/PathFoundation/CPath-Omni) |  | Python | 27 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_CPath-Omni_A_Unified_Multimodal_Foundation_Model_for_Patch_and_Whole_CVPR_2025_paper.pdf) | |
| Dispider: Enabling Video LLMs with Active Real-Time Interaction via Disentangled Perception; Decision; and Reaction | [code](https://github.com/Mark12Ding/Dispider) | [CVPR 2025]Dispider: Enabling Video LLMs with Active Real-Time Interaction via Disentangled Perception, Decision, and Reaction | Python | 155 | 10 | 12 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_Dispider_Enabling_Video_LLMs_with_Active_Real-Time_Interaction_via_Disentangled_CVPR_2025_paper.pdf) | |
| MVGenMaster: Scaling Multi-View Generation from Any Image via 3D Priors Enhanced Diffusion Model | [code](https://github.com/ewrfcas/MVGenMaster/) | [CVPR2025] MVGenMaster: Scaling Multi-View Generation from Any Image via 3D Priors Enhanced Diffusion Model | Python | 140 | 5 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_MVGenMaster_Scaling_Multi-View_Generation_from_Any_Image_via_3D_Priors_CVPR_2025_paper.pdf) | |
| Attribute-formed Class-specific Concept Space: Endowing Language Bottleneck Model with Better Interpretability and Scalability | [code](https://github.com/tiggers23/ALBM) |  | Python | 2 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Attribute-formed_Class-specific_Concept_Space_Endowing_Language_Bottleneck_Model_with_Better_CVPR_2025_paper.pdf) | |
| EfficientViM: Efficient Vision Mamba with Hidden State Mixer based State Space Duality | [code](https://github.com/mlvlab/EfficientViM) | [CVPR 25] Official Implementation (Pytorch) of "EfficientViM: Efficient Vision Mamba with Hidden State Mixer-based State Space Duality" | Python | 113 | 4 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_EfficientViM_Efficient_Vision_Mamba_with_Hidden_State_Mixer_based_State_CVPR_2025_paper.pdf) | |
| RoGSplat: Learning Robust Generalizable Human Gaussian Splatting from Sparse Multi-View Images | [code](https://github.com/iSEE-Laboratory/RoGSplat) | Code of CVPR2025 paper "RoGSplat: Learning Robust Generalizable Human Gaussian Splatting from Sparse Multi-View Images" | Python | 39 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_RoGSplat_Learning_Robust_Generalizable_Human_Gaussian_Splatting_from_Sparse_Multi-View_CVPR_2025_paper.pdf) | |
| SPMTrack: Spatio-Temporal Parameter-Efficient Fine-Tuning with Mixture of Experts for Scalable Visual Tracking | [code](https://github.com/WenRuiCai/SPMTrack) | Official implementation of "SPMTrack: Spatio-Temporal Parameter-Efficient Fine-Tuning with Mixture of Experts for Scalable Visual Tracking". (CVPR 2025) | Python | 39 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_SPMTrack_Spatio-Temporal_Parameter-Efficient_Fine-Tuning_with_Mixture_of_Experts_for_Scalable_CVPR_2025_paper.pdf) | |
| LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation | [code](https://github.com/vladan-stojnic/LPOSS) | Code for LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation (CVPR2025) | Python | 22 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Stojnic_LPOSS_Label_Propagation_Over_Patches_and_Pixels_for_Open-vocabulary_Semantic_CVPR_2025_paper.pdf) | |
| Docopilot: Improving Multimodal Models for Document-Level Understanding | [code](https://github.com/OpenGVLab/Docopilot) | [CVPR 2025] Docopilot: Improving Multimodal Models for Document-Level Understanding | Python | 36 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_Docopilot_Improving_Multimodal_Models_for_Document-Level_Understanding_CVPR_2025_paper.pdf) | |
| Exact: Exploring Space-Time Perceptive Clues for Weakly Supervised Satellite Image Time Series Semantic Segmentation | [code](https://github.com/MiSsU-HH/Exact) | [CVPR 2025 Highlight] Exact: Exploring Space-Time Perceptive Clues for Weakly Supervised Satellite Image Time Series Semantic Segmentation | Python | 51 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Exact_Exploring_Space-Time_Perceptive_Clues_for_Weakly_Supervised_Satellite_Image_CVPR_2025_paper.pdf) | |
| PolarFree: Polarization-based Reflection-Free Imaging | [code](https://github.com/mdyao/PolarFree) | [CVPR 2025] Official Implementation of "PolarFree: Polarization-based Reflection-Free Imaging" | Python | 51 | 5 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_PolarFree_Polarization-based_Reflection-Free_Imaging_CVPR_2025_paper.pdf) | |
| Effortless Active Labeling for Long-Term Test-Time Adaptation | [code](https://github.com/flash1803/EATTA) |  | Python | 4 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Effortless_Active_Labeling_for_Long-Term_Test-Time_Adaptation_CVPR_2025_paper.pdf) | |
| Logits DeConfusion with CLIP for Few-Shot Learning | [code](https://github.com/LiShuo1001/LDC) | The code of "Logits DeConfusion with CLIP for Few-Shot Learning" (CVPR 2025) | Python | 64 | 7 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Logits_DeConfusion_with_CLIP_for_Few-Shot_Learning_CVPR_2025_paper.pdf) | |
| 2DMamba: Efficient State Space Model for Image Representation with Applications on Giga-Pixel Whole Slide Image Classification | [code](https://github.com/AtlasAnalyticsLab/2DMamba) | [CVPR 2025] 2DMamba: Efficient State Space Model for Image Representation | Python | 74 | 10 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_2DMamba_Efficient_State_Space_Model_for_Image_Representation_with_Applications_CVPR_2025_paper.pdf) | |
| MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation | [code](https://github.com/xmed-lab/MuTri) | CVPR 2025: MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_MuTri_Multi-view_Tri-alignment_for_OCT_to_OCTA_3D_Image_Translation_CVPR_2025_paper.pdf) | |
| Sketchy Bounding-box Supervision for 3D Instance Segmentation | [code](https://github.com/dengq7/Sketchy-3DIS) |  | Python | 11 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Sketchy_Bounding-box_Supervision_for_3D_Instance_Segmentation_CVPR_2025_paper.pdf) | |
| DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image | [code](https://github.com/barry664/DeformCL) |  | Python | 30 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DeformCL_Learning_Deformable_Centerline_Representation_for_Vessel_Extraction_in_3D_CVPR_2025_paper.pdf) | |
| Learning Person-Specific Animatable Face Models from In-the-Wild Images via a Shared Base Model | [code](https://github.com/danielmao2000/person-specific-animatable-face) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_Learning_Person-Specific_Animatable_Face_Models_from_In-the-Wild_Images_via_a_CVPR_2025_paper.pdf) | |
| RaCFormer: Towards High-Quality 3D Object Detection via Query-based Radar-Camera Fusion | [code](https://github.com/cxmomo/RaCFormer) | Official PyTorch Implementation of "RaCFormer: Towards High-Quality 3D Object Detection via Query-based Radar-Camera Fusion" (CVPR 2025) | Python | 58 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chu_RaCFormer_Towards_High-Quality_3D_Object_Detection_via_Query-based_Radar-Camera_Fusion_CVPR_2025_paper.pdf) | |
| Adaptive Keyframe Sampling for Long Video Understanding | [code](https://github.com/ncTimTang/AKS) | [CVPR 2025] Adaptive Keyframe Sampling for Long Video Understanding | Python | 158 | 13 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Adaptive_Keyframe_Sampling_for_Long_Video_Understanding_CVPR_2025_paper.pdf) | |
| Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning | [code](https://github.com/info-ucr/PEFTLeak) |  | Jupyter Notebook | 3 | 2 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sami_Gradient_Inversion_Attacks_on_Parameter-Efficient_Fine-Tuning_CVPR_2025_paper.pdf) | |
| DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer | [code](https://github.com/Dotori-HJ/DiGIT) | [CVPR 2025] Official implementation of the paper "DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer" | Python | 24 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_DiGIT_Multi-Dilated_Gated_Encoder_and_Central-Adjacent_Region_Integrated_Decoder_for_CVPR_2025_paper.pdf) | |
| MBQ: Modality-Balanced Quantization for Large Vision-Language Models | [code](https://github.com/thu-nics/MBQ) | The code repository of "MBQ: Modality-Balanced Quantization for Large Vision-Language Models" | Python | 73 | 4 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MBQ_Modality-Balanced_Quantization_for_Large_Vision-Language_Models_CVPR_2025_paper.pdf) | |
| Realistic Test-Time Adaptation of Vision-Language Models | [code](https://github.com/MaxZanella/StatA) | [CVPR 2025 - Highlight] Official implementation of the paper "Realistic Test-Time Adaptation of Vision-Language Models" (StatA). | Python | 56 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zanella_Realistic_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2025_paper.pdf) | |
| Exploring Simple Open-Vocabulary Semantic Segmentation | [code](https://github.com/zlai0/S-Seg) |  |  | 23 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_Exploring_Simple_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| MP-GUI: Modality Perception with MLLMs for GUI Understanding | [code](https://github.com/BigTaige/MP-GUI) | CVPR25 | Python | 26 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MP-GUI_Modality_Perception_with_MLLMs_for_GUI_Understanding_CVPR_2025_paper.pdf) | |
| Improving Adversarial Transferability on Vision Transformers via Forward Propagation Refinement | [code](https://github.com/RYC-98/FPR) | Official codes for FPR  (Accepted by CVPR2025) | Python | 12 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Improving_Adversarial_Transferability_on_Vision_Transformers_via_Forward_Propagation_Refinement_CVPR_2025_paper.pdf) | |
| Enhancing Online Continual Learning with Plug-and-Play State Space Model and Class-Conditional Mixture of Discretization | [code](https://github.com/MyToumaKazusa/S6MOD) | The official repository of CVPR2025 paper "Enhancing Online Continual Learning with Plug-and-Play State Space Model and Class-Conditional Mixture of Discretization" | Python | 13 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Enhancing_Online_Continual_Learning_with_Plug-and-Play_State_Space_Model_and_CVPR_2025_paper.pdf) | |
| Building Vision Models upon Heat Conduction | [code](https://github.com/MzeroMiko/vHeat) | vHeat: Building Vision Models upon Heat Conduction | Python | 267 | 10 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Building_Vision_Models_upon_Heat_Conduction_CVPR_2025_paper.pdf) | |
| Model Poisoning Attacks to Federated Learning via Multi-Round Consistency | [code](https://github.com/xyq7/PoisonedFL/) | CVPR 2025, Model Poisoning Attacks to Federated Learning via Multi-Round Consistency | Python | 10 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Model_Poisoning_Attacks_to_Federated_Learning_via_Multi-Round_Consistency_CVPR_2025_paper.pdf) | |
| Closest Neighbors are Harmful for Lightweight Masked Auto-encoders | [code](https://github.com/SeoLabCornell/NoR-MAE) | Official Implementation of NoR-MAE (CVPR, 2025) | Python | 2 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_Closest_Neighbors_are_Harmful_for_Lightweight_Masked_Auto-encoders_CVPR_2025_paper.pdf) | |
| GIF: Generative Inspiration for Face Recognition at Scale | [code](https://github.com/msed-Ebrahimi/GIF) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ebrahimi_GIF_Generative_Inspiration_for_Face_Recognition_at_Scale_CVPR_2025_paper.pdf) | |
| Practical Solutions to the Relative Pose of Three Calibrated Cameras | [code](https://github.com/kocurvik/threeview) | [CVPR 2025] Practical solutions to the relative pose of three calibrated cameras | Python | 6 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tzamos_Practical_Solutions_to_the_Relative_Pose_of_Three_Calibrated_Cameras_CVPR_2025_paper.pdf) | |
| PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models | [code](https://github.com/NVlabs/PARC) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Schmalfuss_PARC_A_Quantitative_Framework_Uncovering_the_Symmetries_within_Vision_Language_CVPR_2025_paper.pdf) | |
| Redefining <Creative> in Dictionary: Towards an Enhanced Semantic Understanding of Creative Generation | [code](https://github.com/fu-feng/CreTok) | Redefining <Creative> in Dictionary: Towards an Enhanced Semantic Understanding of Creative Generation. CVPR25 |  | 0 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Redefining_Creative_in_Dictionary_Towards_an_Enhanced_Semantic_Understanding_of_CVPR_2025_paper.pdf) | |
| FiRe: Fixed-points of Restoration Priors for Solving Inverse Problems | [code](https://github.com/matthieutrs/fire) |  | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Terris_FiRe_Fixed-points_of_Restoration_Priors_for_Solving_Inverse_Problems_CVPR_2025_paper.pdf) | |
| Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation | [code](https://github.com/xujiaommcome/DiCo) | Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation | Python | 7 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Learning_Dynamic_Collaborative_Network_for_Semi-supervised_3D_Vessel_Segmentation_CVPR_2025_paper.pdf) | |
| Temporal Alignment-Free Video Matching for Few-shot Action Recognition | [code](http://github.com/leesb7426/TEAM) |  | Python | 33 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Temporal_Alignment-Free_Video_Matching_for_Few-shot_Action_Recognition_CVPR_2025_paper.pdf) | |
| VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary | [code](https://github.com/showlab/VLog) | [CVPR 2025] Video Narration as Vocabulary & Video as Long Document | Python | 583 | 31 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_VLog_Video-Language_Models_by_Generative_Retrieval_of_Narration_Vocabulary_CVPR_2025_paper.pdf) | |
| Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline | [code](https://github.com/uni-medical/IMIS-Bench) | Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline | Jupyter Notebook | 258 | 8 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_Interactive_Medical_Image_Segmentation_A_Benchmark_Dataset_and_Baseline_CVPR_2025_paper.pdf) | |
| AutoSSVH: Exploring Automated Frame Sampling for Efficient Self-Supervised Video Hashing | [code](https://github.com/EliSpectre/CVPR25-AutoSSVH) | This repository contains the PyTorch implementation of our work at CVPR 2025 | Python | 9 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lian_AutoSSVH_Exploring_Automated_Frame_Sampling_for_Efficient_Self-Supervised_Video_Hashing_CVPR_2025_paper.pdf) | |
| DifIISR: A Diffusion Model with Gradient Guidance for Infrared Image Super-Resolution | [code](https://github.com/zirui0625/DifIISR) | [CVPR 2025] Official implementation for "Diffusion Model with Gradient Guidance for Infrared Image Super-Resolution". | Python | 91 | 6 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DifIISR_A_Diffusion_Model_with_Gradient_Guidance_for_Infrared_Image_CVPR_2025_paper.pdf) | |
| Recurrent Feature Mining and Keypoint Mixup Padding for Category-Agnostic Pose Estimation | [code](https://github.com/chenbys/FMMP) | In CVPR 2025, Recurrent Feature Mining and Keypoint Mixup Padding for Category-Agnostic Pose Estimation | Python | 13 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Recurrent_Feature_Mining_and_Keypoint_Mixup_Padding_for_Category-Agnostic_Pose_CVPR_2025_paper.pdf) | |
| Samba: A Unified Mamba-based Framework for General Salient Object Detection | [code](https://github.com/Jia-hao999/Samba) |  | Python | 47 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/He_Samba_A_Unified_Mamba-based_Framework_for_General_Salient_Object_Detection_CVPR_2025_paper.pdf) | |
| PAVE: Patching and Adapting Video Large Language Models | [code](https://github.com/dragonlzm/PAVE) | This repo holds the implementation of PAVE: Patching and Adapting Video Large Language Models (CVPR2025) | Python | 26 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_PAVE_Patching_and_Adapting_Video_Large_Language_Models_CVPR_2025_paper.pdf) | |
| Revisiting Audio-Visual Segmentation with Vision-Centric Transformer | [code](https://github.com/spyflying/VCT_AVS) | Official PyTorch implementation for 'Revisiting Audio-Visual Segmentation with Vision-Centric Transformer' | Python | 12 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Revisiting_Audio-Visual_Segmentation_with_Vision-Centric_Transformer_CVPR_2025_paper.pdf) | |
| DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models | [code](https://github.com/JREion/DPC) | [CVPR 2025] Official PyTorch Code for "DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models" | Python | 38 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DPC_Dual-Prompt_Collaboration_for_Tuning_Vision-Language_Models_CVPR_2025_paper.pdf) | |
| Dual-Granularity Semantic Guided Sparse Routing Diffusion Model for General Pansharpening | [code](https://github.com/codgodtao/SGDiff) | offical implement of paper SGDIFF: Dual-Granularity Semantic Guided Sparse Routing Diffusion Model for General Pansharpening | Python | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_Dual-Granularity_Semantic_Guided_Sparse_Routing_Diffusion_Model_for_General_Pansharpening_CVPR_2025_paper.pdf) | |
| SOAP: Vision-Centric 3D Semantic Scene Completion with Scene-Adaptive Decoder and Occluded Region-Aware View Projection | [code](https://github.com/gywns6287/SOAP) | Official code for SOAP implementation | Python | 12 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_SOAP_Vision-Centric_3D_Semantic_Scene_Completion_with_Scene-Adaptive_Decoder_and_CVPR_2025_paper.pdf) | |
| Active Event-based Stereo Vision | [code](https://github.com/jianing-li/active_event_based_stereo) |  | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Active_Event-based_Stereo_Vision_CVPR_2025_paper.pdf) | |
| From Zero to Detail: Deconstructing Ultra-High-Definition Image Restoration from Progressive Spectral Perspective | [code](https://github.com/NJU-PCALab/ERR) | [CVPR 2025] Official code of "From Zero to Detail: Deconstructing Ultra-High-Definition Image Restoration from Progressive Spectral Perspective" | Python | 48 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_From_Zero_to_Detail_Deconstructing_Ultra-High-Definition_Image_Restoration_from_Progressive_CVPR_2025_paper.pdf) | |
| SMILE: Infusing Spatial and Motion Semantics in Masked Video Learning | [code](https://github.com/fmthoker/SMILE) | Codebase for our CVPR 2025 paper "SMILE ðŸ˜Š : Infusing Spatial and Motion Semantics in Masked Video Learning" | Python | 14 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Thoker_SMILE_Infusing_Spatial_and_Motion_Semantics_in_Masked_Video_Learning_CVPR_2025_paper.pdf) | |
| COSMOS: Cross-Modality Self-Distillation for Vision Language Pre-training | [code](https://github.com/ExplainableML/cosmos) | [CVPR 2025] COSMOS: Cross-Modality Self-Distillation for Vision Language Pre-training | Python | 38 | 3 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_COSMOS_Cross-Modality_Self-Distillation_for_Vision_Language_Pre-training_CVPR_2025_paper.pdf) | |
| TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in Vision-Language Models | [code](https://github.com/xinwong/TAPT) | [CVPR 2025] TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in Vision-Language Models | Python | 12 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TAPT_Test-Time_Adversarial_Prompt_Tuning_for_Robust_Inference_in_Vision-Language_CVPR_2025_paper.pdf) | |
| Cross-Rejective Open-Set SAR Image Registration | [code](https://github.com/XDyaoshi/CroR-OSIR-main) | This repository is used to store the code corresponding to the paper Cross-Rejective Open-Set SAR Image Registration. We provide copyrighted remote sensing or natural image datasets for training. The code will be maintained periodically, and we welcome any feedback or suggestions! | Python | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_Cross-Rejective_Open-Set_SAR_Image_Registration_CVPR_2025_paper.pdf) | |
| Can't Slow Me Down: Learning Robust and Hardware-Adaptive Object Detectors against Latency Attacks for Edge Devices | [code](https://github.com/Hill-Wu-1998/underload) | CVPR 2025: Learning Robust and Hardware-Adaptive Object Detectors against Latency Attacks for Edge Devices | Python | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Cant_Slow_Me_Down_Learning_Robust_and_Hardware-Adaptive_Object_Detectors_CVPR_2025_paper.pdf) | |
| Multi-modal Knowledge Distillation-based Human Trajectory Forecasting | [code](https://github.com/Jaewoo97/KDTF) | [CVPR 2025] Multi-modal Knowledge Distillation-based Human Trajectory Forecasting | Python | 17 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_Multi-modal_Knowledge_Distillation-based_Human_Trajectory_Forecasting_CVPR_2025_paper.pdf) | |
| ShiftwiseConv: Small Convolutional Kernel with Large Kernel Effect | [code](https://github.com/lidc54/shift-wiseConv) | Shift-ConvNets: Small Convolutional Kernel with Large Kernel Effects | Python | 53 | 9 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_ShiftwiseConv_Small_Convolutional_Kernel_with_Large_Kernel_Effect_CVPR_2025_paper.pdf) | |
| GaussianIP: Identity-Preserving Realistic 3D Human Generation via Human-Centric Diffusion Prior | [code](https://github.com/silence-tang/GaussianIP) | [CVPR 2025] Official Implementation of GaussianIP: Identity-Preserving Realistic 3D Human Generation via Human-Centric Diffusion Prior | Python | 23 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_GaussianIP_Identity-Preserving_Realistic_3D_Human_Generation_via_Human-Centric_Diffusion_Prior_CVPR_2025_paper.pdf) | |
| FineVQ: Fine-Grained User Generated Content Video Quality Assessment | [code](https://github.com/IntMeGroup/FineVQ) | [CVPR 2025] FineVQ: Fine-Grained User Generated Content Video Quality Assessment | Python | 75 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_FineVQ_Fine-Grained_User_Generated_Content_Video_Quality_Assessment_CVPR_2025_paper.pdf) | |
| Object-Shot Enhanced Grounding Network for Egocentric Video | [code](https://github.com/Yisen-Feng/OSGNet) |  | Python | 10 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Object-Shot_Enhanced_Grounding_Network_for_Egocentric_Video_CVPR_2025_paper.pdf) | |
| MANTA: Diffusion Mamba for Efficient and Effective Stochastic Long-Term Dense Action Anticipation | [code](https://github.com/olga-zats/DIFF_MANTA) | [CVPR 2025] MANTA: Diffusion Mamba for Efficient and Effective Stochastic Long-Term Dense Anticipation | Python | 23 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zatsarynna_MANTA_Diffusion_Mamba_for_Efficient_and_Effective_Stochastic_Long-Term_Dense_CVPR_2025_paper.pdf) | |
| Sim-to-Real Causal Transfer: A Metric Learning Approach to Causally-Aware Interaction Representations | [code](https://github.com/vita-epfl/CausalSim2Real) |  | Python | 2 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Rahimi_Sim-to-Real_Causal_Transfer_A_Metric_Learning_Approach_to_Causally-Aware_Interaction_CVPR_2025_paper.pdf) | |
| Ev-3DOD: Pushing the Temporal Boundaries of 3D Object Detection with Event Cameras | [code](https://github.com/mickeykang16/Ev3DOD) | [CVPR 2025 Highlight] Ev3DOD: Pushing the Temporal Boundaries of 3D Object Detection with Event Cameras | Python | 25 | 6 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cho_Ev-3DOD_Pushing_the_Temporal_Boundaries_of_3D_Object_Detection_with_CVPR_2025_paper.pdf) | |
| PhyT2V: LLM-Guided Iterative Self-Refinement for Physics-Grounded Text-to-Video Generation | [code](https://github.com/pittisl/PhyT2V) | official code repo of CVPR 2025 paper PhyT2V: LLM-Guided Iterative Self-Refinement for Physics-Grounded Text-to-Video Generation | Python | 59 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_PhyT2V_LLM-Guided_Iterative_Self-Refinement_for_Physics-Grounded_Text-to-Video_Generation_CVPR_2025_paper.pdf) | |
| Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation | [code](https://github.com/BasitAlawode/MR-PLIP) |  | Python | 26 | 1 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Albastaki_Multi-Resolution_Pathology-Language_Pre-training_Model_with_Text-Guided_Visual_Representation_CVPR_2025_paper.pdf) | |
| MammAlps: A Multi-view Video Behavior Monitoring Dataset of Wild Mammals in the Swiss Alps | [code](https://github.com/eceo-epfl/MammAlps) | Official codebase for MammAlps | Python | 25 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gabeff_MammAlps_A_Multi-view_Video_Behavior_Monitoring_Dataset_of_Wild_Mammals_CVPR_2025_paper.pdf) | |
| Towards Satellite Image Road Graph Extraction: A Global-Scale Dataset and A Novel Method | [code](https://github.com/earth-insights/samroadplus) | [CVPR 2025] Towards Satellite Image Road Graph Extraction: A Global-Scale Dataset and A Novel Method | Python | 72 | 9 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_Towards_Satellite_Image_Road_Graph_Extraction_A_Global-Scale_Dataset_and_CVPR_2025_paper.pdf) | |
| SuperLightNet: Lightweight Parameter Aggregation Network for Multimodal Brain Tumor Segmentation | [code](https://github.com/WTU1020-Medical-Segmentation/SuperLightNet) |  |  | 1 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_SuperLightNet_Lightweight_Parameter_Aggregation_Network_for_Multimodal_Brain_Tumor_Segmentation_CVPR_2025_paper.pdf) | |
| Self-Supervised Spatial Correspondence Across Modalities | [code](https://github.com/ayshrv/cmrw) | Official PyTorch implementation of Self-Supervised Spatial Correspondence Across Modalities, CVPR 2025. |  | 18 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shrivastava_Self-Supervised_Spatial_Correspondence_Across_Modalities_CVPR_2025_paper.pdf) | |
| Finer-CAM: Spotting the Difference Reveals Finer Details for Visual Explanation | [code](https://github.com/Imageomics/Finer-CAM) | This is an official implementation for Finer-CAM: Spotting the Difference Reveals Finer Details for Visual Explanation. [CVPR'25] | Jupyter Notebook | 46 | 4 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Finer-CAM_Spotting_the_Difference_Reveals_Finer_Details_for_Visual_Explanation_CVPR_2025_paper.pdf) | |
| COB-GS: Clear Object Boundaries in 3DGS Segmentation Based on Boundary-Adaptive Gaussian Splitting | [code](https://github.com/ZestfulJX/COB-GS) | COB-GS: Clear Object Boundaries in 3DGS Segmentation Based on Boundary-Adaptive Gaussian Splitting | C++ | 62 | 3 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_COB-GS_Clear_Object_Boundaries_in_3DGS_Segmentation_Based_on_Boundary-Adaptive_CVPR_2025_paper.pdf) | |
| Weakly Supervised Semantic Segmentation via Progressive Confidence Region Expansion | [code](https://github.com/xxf011/WSSS-PCRE) |  |  | 0 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Weakly_Supervised_Semantic_Segmentation_via_Progressive_Confidence_Region_Expansion_CVPR_2025_paper.pdf) | |
| UniK3D: Universal Camera Monocular 3D Estimation | [code](http://github.com/lpiccinelli-eth/unik3d) | [CVPR 2025] UniK3D: Universal Camera Monocular 3D Estimation | Python | 674 | 56 | 19 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Piccinelli_UniK3D_Universal_Camera_Monocular_3D_Estimation_CVPR_2025_paper.pdf) | |
| ConMo: Controllable Motion Disentanglement and Recomposition for Zero-Shot Motion Transfer | [code](https://github.com/Andyplus1/ConMo) |  | Python | 9 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_ConMo_Controllable_Motion_Disentanglement_and_Recomposition_for_Zero-Shot_Motion_Transfer_CVPR_2025_paper.pdf) | |
| AG-VPReID: A Challenging Large-Scale Benchmark for Aerial-Ground Video-based Person Re-Identification | [code](https://github.com/agvpreid25/AG-VPReID-Net) |  |  | 18 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_AG-VPReID_A_Challenging_Large-Scale_Benchmark_for_Aerial-Ground_Video-based_Person_Re-Identification_CVPR_2025_paper.pdf) | |
| Benchmarking Object Detectors under Real-World Distribution Shifts in Satellite Imagery | [code](https://github.com/RWGAI/RWDS) |  | Python | 10 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Al-Emadi_Benchmarking_Object_Detectors_under_Real-World_Distribution_Shifts_in_Satellite_Imagery_CVPR_2025_paper.pdf) | |
| Closed-Loop Supervised Fine-Tuning of Tokenized Traffic Models | [code](https://github.com/NVlabs/catk) | Closed-Loop Supervised Fine-Tuning of Tokenized Traffic Models. CVPR Oral 2025. | Python | 172 | 14 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Closed-Loop_Supervised_Fine-Tuning_of_Tokenized_Traffic_Models_CVPR_2025_paper.pdf) | |
| Mind the Gap: Confidence Discrepancy Can Guide Federated Semi-Supervised Learning Across Pseudo-Mismatch | [code](https://github.com/Jay-Codeman/SAGE) | This is the repository of the CVPR 2025 paper: "Mind the Gap: Confidence Discrepancy Can Guide Federated Semi-Supervised Learning Across Pseudo-Mismatch". | Python | 21 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Mind_the_Gap_Confidence_Discrepancy_Can_Guide_Federated_Semi-Supervised_Learning_CVPR_2025_paper.pdf) | |
| Preserve or Modify? Context-Aware Evaluation for Balancing Preservation and Modification in Text-Guided Image Editing | [code](https://github.com/augclip/augclip_eval) |  | Jupyter Notebook | 6 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Preserve_or_Modify_Context-Aware_Evaluation_for_Balancing_Preservation_and_Modification_CVPR_2025_paper.pdf) | |
| Mask-Adapter: The Devil is in the Masks for Open-Vocabulary Segmentation | [code](https://github.com/hustvl/MaskAdapter) | [CVPR 2025] Official repository of the paper "Mask-Adapter: The Devil is in the Masks for Open-Vocabulary Segmentation" | Python | 120 | 2 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Mask-Adapter_The_Devil_is_in_the_Masks_for_Open-Vocabulary_Segmentation_CVPR_2025_paper.pdf) | |
| CMMLoc: Advancing Text-to-PointCloud Localization with Cauchy-Mixture-Model Based Framework | [code](https://github.com/anonymous0819/CMMLoc) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_CMMLoc_Advancing_Text-to-PointCloud_Localization_with_Cauchy-Mixture-Model_Based_Framework_CVPR_2025_paper.pdf) | |
| Learning from Synchronization: Self-Supervised Uncalibrated Multi-View Person Association in Challenging Scenes | [code](https://github.com/CAMMA-public/Self-MVA) | Official code for "Learning from Synchronization: Self-Supervised Uncalibrated Multi-View Person Association in Challenging Scenes" | Python | 7 | 3 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Learning_from_Synchronization_Self-Supervised_Uncalibrated_Multi-View_Person_Association_in_Challenging_CVPR_2025_paper.pdf) | |
| CLIP-driven Coarse-to-fine Semantic Guidance for Fine-grained Open-set Semi-supervised Learning | [code](https://github.com/LxxxxK/CFSG-CLIP) |  |  | 1 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CLIP-driven_Coarse-to-fine_Semantic_Guidance_for_Fine-grained_Open-set_Semi-supervised_Learning_CVPR_2025_paper.pdf) | |
| Sampling Innovation-Based Adaptive Compressive Sensing | [code](https://github.com/giant-pandada/SIB-ACS_CVPR2025) |  | Python | 9 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Sampling_Innovation-Based_Adaptive_Compressive_Sensing_CVPR_2025_paper.pdf) | |
| A Simple Data Augmentation for Feature Distribution Skewed Federated Learning | [code](https://github.com/IAMJackYan/FedRDN) | official code of CVPR2025-FedRDN | Python | 8 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_A_Simple_Data_Augmentation_for_Feature_Distribution_Skewed_Federated_Learning_CVPR_2025_paper.pdf) | |
| Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning | [code](https://github.com/LuFan31/CompreCap) | CVPR2025: Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning | Python | 37 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Benchmarking_Large_Vision-Language_Models_via_Directed_Scene_Graph_for_Comprehensive_CVPR_2025_paper.pdf) | |
| FlashSloth : Lightning Multimodal Large Language Models via Embedded Visual Compression | [code](https://github.com/codefanw/FlashSloth) | [CVPR2025] FlashSloth: Lightning Multimodal Large Language Models via Embedded Visual Compression | Python | 59 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tong_FlashSloth__Lightning_Multimodal_Large_Language_Models_via_Embedded_Visual_CVPR_2025_paper.pdf) | |
| Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation | [code](https://github.com/wslh852/Wav2Sem.git) |  | Jupyter Notebook | 9 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Wav2Sem_Plug-and-Play_Audio_Semantic_Decoupling_for_3D_Speech-Driven_Facial_Animation_CVPR_2025_paper.pdf) | |
| T2SG: Traffic Topology Scene Graph for Topology Reasoning in Autonomous Driving | [code](https://github.com/MICLAB-BUPT/T2SG) | Code of CVPR2025 Paper ã€ŠT2SG: Traffic Topology Scene Graph for Topology Reasoning in Autonomous Drivingã€‹ | Python | 9 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lv_T2SG_Traffic_Topology_Scene_Graph_for_Topology_Reasoning_in_Autonomous_CVPR_2025_paper.pdf) | |
| T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting | [code](https://github.com/cha15yq/T2ICount) | Official implement of CVPR2025 paper: "T2ICount: Enhancing Cross-modal Understanding for zero-shot Counting"  | Python | 22 | 4 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_T2ICount_Enhancing_Cross-modal_Understanding_for_Zero-Shot_Counting_CVPR_2025_paper.pdf) | |
| ReNeg: Learning Negative Embedding with Reward Guidance | [code](https://github.com/AMD-AIG-AIMA/ReNeg) | ReNeg: Learning Negative Embedding with Reward Guidance | Python | 17 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_ReNeg_Learning_Negative_Embedding_with_Reward_Guidance_CVPR_2025_paper.pdf) | |
| Scale Efficient Training for Large Datasets | [code](https://github.com/mrazhou/SeTa) | [CVPR2025] Official code repository for SeTa: "Scale Efficient Training for Large Datasets" | Python | 21 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Scale_Efficient_Training_for_Large_Datasets_CVPR_2025_paper.pdf) | |
| Distilled Prompt Learning for Incomplete Multimodal Survival Prediction | [code](https://github.com/Innse/DisPro) | [CVPR 2025] The official implementation of "Distilled Prompt Learning for Incomplete Multimodal Survival Prediction". | Python | 6 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Distilled_Prompt_Learning_for_Incomplete_Multimodal_Survival_Prediction_CVPR_2025_paper.pdf) | |
| Decoder Gradient Shield: Provable and High-Fidelity Prevention of Gradient-Based Box-Free Watermark Removal | [code](https://github.com/haonanAN309/CVPR-2025-Official-Implementation-Decoder-Gradient-Shield) | (CVPR 2025) Official Implementation: Decoder Gradient Shield: Provable and High-Fidelity Prevention of Gradient-Based Box-Free Watermark Removal | Python | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/An_Decoder_Gradient_Shield_Provable_and_High-Fidelity_Prevention_of_Gradient-Based_Box-Free_CVPR_2025_paper.pdf) | |
| Hyperbolic Safety-Aware Vision-Language Models | [code](https://github.com/aimagelab/HySAC) | Hyperbolic Safety-Aware Vision-Language Models. CVPR 2025 | Python | 26 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Poppi_Hyperbolic_Safety-Aware_Vision-Language_Models_CVPR_2025_paper.pdf) | |
| Relative Pose Estimation through Affine Corrections of Monocular Depth Priors | [code](https://github.com/MarkYu98/madpose) | [CVPR 2025 Highlight] Official implementation of the solvers and estimators proposed in the paper "Relative Pose Estimation through Affine Corrections of Monocular Depth Priors" | C++ | 226 | 15 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Relative_Pose_Estimation_through_Affine_Corrections_of_Monocular_Depth_Priors_CVPR_2025_paper.pdf) | |
| Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video Diffusion | [code](https://github.com/ZhenglinZhou/Zero-1-to-A) | [CVPR 2025] Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video Diffusion |  | 42 | 1 | 10 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Zero-1-to-A_Zero-Shot_One_Image_to_Animatable_Head_Avatars_Using_Video_CVPR_2025_paper.pdf) | |
| Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model | [code](https://github.com/keke-nice/Period-LLM) | CVPR2025 | Python | 45 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Period-LLM_Extending_the_Periodic_Capability_of_Multimodal_Large_Language_Model_CVPR_2025_paper.pdf) | |
| Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field Rendering | [code](https://github.com/NVlabs/svraster) | [CVPR 2025] Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field Rendering | Jupyter Notebook | 889 | 57 | 27 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Sparse_Voxels_Rasterization_Real-time_High-fidelity_Radiance_Field_Rendering_CVPR_2025_paper.pdf) | |
| MambaIC: State Space Models for High-Performance Learned Image Compression | [code](https://github.com/AuroraZengfh/MambaIC) | [CVPR'25] Official Implementation of MambaIC: State Space Models for High-Performance Learned Image Compression | Python | 77 | 1 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_MambaIC_State_Space_Models_for_High-Performance_Learned_Image_Compression_CVPR_2025_paper.pdf) | |
| SCAP: Transductive Test-Time Adaptation via Supportive Clique-based Attribute Prompting | [code](https://github.com/zhoujiahuan1991/CVPR2025-SCAP) |  | Python | 7 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_SCAP_Transductive_Test-Time_Adaptation_via_Supportive_Clique-based_Attribute_Prompting_CVPR_2025_paper.pdf) | |
| Locality-Aware Zero-Shot Human-Object Interaction Detection | [code](https://github.com/OreoChocolate/LAIN) | The official code for Locality-Aware Zero-Shot Human-Object Interaction Detection, CVPR2025 | Python | 14 | 7 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Locality-Aware_Zero-Shot_Human-Object_Interaction_Detection_CVPR_2025_paper.pdf) | |
| PEACE: Empowering Geologic Map Holistic Understanding with MLLMs | [code](https://github.com/microsoft/PEACE) | PEACE: Empowering Geologic Map Holistic Understanding with MLLMs [Official, CVPR 2025] | Python | 67 | 12 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_PEACE_Empowering_Geologic_Map_Holistic_Understanding_with_MLLMs_CVPR_2025_paper.pdf) | |
| SGFormer: Satellite-Ground Fusion for 3D Semantic Scene Completion | [code](https://github.com/gxytcrc/SGFormer) | Satellite-Ground Fusion for 3D Semantic Scene Completion | Python | 28 | 5 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_SGFormer_Satellite-Ground_Fusion_for_3D_Semantic_Scene_Completion_CVPR_2025_paper.pdf) | |
| Rethinking End-to-End 2D to 3D Scene Segmentation in Gaussian Splatting | [code](https://github.com/Runsong123/Unified-Lift) | Code Release for CVPR 2025, "Rethinking End-to-End 2D to 3D Scene Segmentation in Gaussian Splatting" | Jupyter Notebook | 74 | 2 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Rethinking_End-to-End_2D_to_3D_Scene_Segmentation_in_Gaussian_Splatting_CVPR_2025_paper.pdf) | |
| Adaptive Unimodal Regulation for Balanced Multimodal Information Acquisition | [code](https://github.com/GeWu-Lab/InfoReg_CVPR2025) | This is the repo for "Adaptive Unimodal Regulation for Balanced Multimodal Information Acquisition", CVPR2025. | Python | 19 | 5 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Adaptive_Unimodal_Regulation_for_Balanced_Multimodal_Information_Acquisition_CVPR_2025_paper.pdf) | |
| ESC: Erasing Space Concept for Knowledge Deletion | [code](https://github.com/KU-VGI/ESC) | [CVPR 2025 Highlight] ESC: Erasing Space Concept for Knowledge Deletion | Python | 8 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_ESC_Erasing_Space_Concept_for_Knowledge_Deletion_CVPR_2025_paper.pdf) | |
| Language Guided Concept Bottleneck Models for Interpretable Continual Learning | [code](https://github.com/FisherCats/CLG-CBM) | The official PyTorch implementation of CVPR2025 paper "Language Guided Concept Bottleneck Models for Interpretable Continual Learning" | Python | 29 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Language_Guided_Concept_Bottleneck_Models_for_Interpretable_Continual_Learning_CVPR_2025_paper.pdf) | |
| One-Way Ticket: Time-Independent Unified Encoder for Distilling Text-to-Image Diffusion Models | [code](https://github.com/sen-mao/Loopfree) | [CVPR2025] Official Implementations "One-Way Ticket : Time-Independent Unified Encoder for Distilling Text-to-Image Diffusion Models" | Python | 28 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_One-Way_Ticket_Time-Independent_Unified_Encoder_for_Distilling_Text-to-Image_Diffusion_Models_CVPR_2025_paper.pdf) | |
| Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data | [code](https://github.com/tntek/GUES) | Code for [CVPR 2025] Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data. | Python | 9 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Su_Domain_Adaptive_Diabetic_Retinopathy_Grading_with_Model_Absence_and_Flowing_CVPR_2025_paper.pdf) | |
| Temporal Separation with Entropy Regularization for Knowledge Distillation in Spiking Neural Networks | [code](https://github.com/yukairong/TSER) | Source code for CVPR 2025 paper: Temporal Separation with Entropy Regularization for Knowledge Distillation in Spiking Neural Networks | Python | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Temporal_Separation_with_Entropy_Regularization_for_Knowledge_Distillation_in_Spiking_CVPR_2025_paper.pdf) | |
| Theoretical Insights in Model Inversion Robustness and Conditional Entropy Maximization for Collaborative Inference Systems | [code](https://github.com/xiasong0501/CEM) |  | Python | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Theoretical_Insights_in_Model_Inversion_Robustness_and_Conditional_Entropy_Maximization_CVPR_2025_paper.pdf) | |
| FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations | [code](https://github.com/hmrishavbandy/FlipSketch) | FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations | Python | 359 | 38 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Bandyopadhyay_FlipSketch_Flipping_Static_Drawings_to_Text-Guided_Sketch_Animations_CVPR_2025_paper.pdf) | |
| GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis | [code](https://github.com/KLMAV-CUC/GoLF-NRT) | This repo is for GoLF-NRT: Integrating Global Context and Local Geometry for Few Shot View Synthesis | Python | 3 | 2 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_GoLF-NRT_Integrating_Global_Context_and_Local_Geometry_for_Few-Shot_View_CVPR_2025_paper.pdf) | |
| Deep Change Monitoring: A Hyperbolic Representative Learning Framework and a Dataset for Long-term Fine-grained Tree Change Detection | [code](https://github.com/liyantett/Tree-Changes-Detection-with-Siamese-Hyperbolic-network) | Deep Change Monitoring: A Hyperbolic Representative Learning Framework and a Dataset for Long-term Fine-grained Tree Change Detection | Python | 9 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Deep_Change_Monitoring_A_Hyperbolic_Representative_Learning_Framework_and_a_CVPR_2025_paper.pdf) | |
| VolFormer: Explore More Comprehensive Cube Interaction for Hyperspectral Image Restoration and Beyond | [code](https://github.com/yudadabing/VolFormer) | VolFormer: Explore More Comprehensive Cube Interaction for Hyperspectral Image Restoration and Beyond | Python | 16 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_VolFormer_Explore_More_Comprehensive_Cube_Interaction_for_Hyperspectral_Image_Restoration_CVPR_2025_paper.pdf) | |
| MLVU: Benchmarking Multi-task Long Video Understanding | [code](https://github.com/JUNJIE99/MLVU) | ðŸ”¥ðŸ”¥MLVU: Multi-task Long Video Understanding Benchmark | Python | 237 | 5 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_MLVU_Benchmarking_Multi-task_Long_Video_Understanding_CVPR_2025_paper.pdf) | |
| SmartCLIP: Modular Vision-language Alignment with Identification Guarantees | [code](https://github.com/Mid-Push/SmartCLIP) | SmartCLIP: A training method to improve CLIP with both short and long texts | Python | 36 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_SmartCLIP_Modular_Vision-language_Alignment_with_Identification_Guarantees_CVPR_2025_paper.pdf) | |
| MaSS13K: A Matting-level Semantic Segmentation Benchmark | [code](https://github.com/xiechenxi99/MaSS13K) | [CVPR 2025] Official code repository for "MaSS13K: A Matting-level Semantic Segmentation Benchmark" | Python | 48 | 2 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_MaSS13K_A_Matting-level_Semantic_Segmentation_Benchmark_CVPR_2025_paper.pdf) | |
| OmniStereo: Real-time Omnidireactional Depth Estimation with Multiview Fisheye Cameras | [code](https://github.com/DengJiaxi1/OmniStereo) |  | Python | 19 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_OmniStereo_Real-time_Omnidireactional_Depth_Estimation_with_Multiview_Fisheye_Cameras_CVPR_2025_paper.pdf) | |
| SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D Multimodal Occupancy Prediction | [code](https://github.com/DzpLab/SDGOCC) |  | Python | 27 | 3 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_SDGOCC_Semantic_and_Depth-Guided_Birds-Eye_View_Transformation_for_3D_Multimodal_CVPR_2025_paper.pdf) | |
| nnWNet: Rethinking the Use of Transformers in Biomedical Image Segmentation and Calling for a Unified Evaluation Benchmark | [code](https://github.com/Yanfeng-Zhou/nnWNet) | [CVPR 2025] nnWNet: Rethinking the Use of Transformers in Biomedical Image Segmentation and Calling for a Unified Evaluation Benchmark | Python | 59 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_nnWNet_Rethinking_the_Use_of_Transformers_in_Biomedical_Image_Segmentation_CVPR_2025_paper.pdf) | |
| Efficient Video Face Enhancement with Enhanced Spatial-Temporal Consistency | [code](https://github.com/Dixin-Lab/BFVR-STC) | [CVPR 2025] Efficient Video Face Enhancement with Enhanced Spatial-Temporal Consistency | Python | 56 | 3 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Efficient_Video_Face_Enhancement_with_Enhanced_Spatial-Temporal_Consistency_CVPR_2025_paper.pdf) | |
| LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty | [code](https://github.com/cspartalis/LoTUS) | Implementation of the CVPR2025 paper LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty. | Jupyter Notebook | 16 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Spartalis_LoTUS_Large-Scale_Machine_Unlearning_with_a_Taste_of_Uncertainty_CVPR_2025_paper.pdf) | |
| SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models | [code](https://github.com/taco-group/SleeperMark) | [CVPR2025] We present SleeperMark, a novel framework designed to embed resilient watermarks into T2I diffusion models | Python | 36 | 5 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SleeperMark_Towards_Robust_Watermark_against_Fine-Tuning_Text-to-image_Diffusion_Models_CVPR_2025_paper.pdf) | |
| Lessons and Insights from a Unifying Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition | [code](https://github.com/OSU-MLB/ViT_PEFT_Vision) | [CVPR'25 (Highlight)] Lessons and Insights from a Unifying Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition | Jupyter Notebook | 46 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mai_Lessons_and_Insights_from_a_Unifying_Study_of_Parameter-Efficient_Fine-Tuning_CVPR_2025_paper.pdf) | |
| H2ST: Hierarchical Two-Sample Tests for Continual Out-of-Distribution Detection | [code](https://github.com/YuhangLiuu/H2ST) |  | Python | 3 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_H2ST_Hierarchical_Two-Sample_Tests_for_Continual_Out-of-Distribution_Detection_CVPR_2025_paper.pdf) | |
| MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders | [code](https://github.com/hey-cjj/MoVE-KD) | [CVPR 2025] Official implementation of paper "MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders". | Python | 48 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_MoVE-KD_Knowledge_Distillation_for_VLMs_with_Mixture_of_Visual_Encoders_CVPR_2025_paper.pdf) | |
| EchoWorld: Learning Motion-Aware World Models for Echocardiography Probe Guidance | [code](https://github.com/LeapLabTHU/EchoWorld) | [CVPR 2025] EchoWorld: Learning Motion-Aware World Models for Echocardiography Probe Guidance | Python | 38 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yue_EchoWorld_Learning_Motion-Aware_World_Models_for_Echocardiography_Probe_Guidance_CVPR_2025_paper.pdf) | |
| FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs | [code](https://github.com/tiiuae/FineLIP) | code for FineLIP | Python | 38 | 3 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Asokan_FineLIP_Extending_CLIPs_Reach_via_Fine-Grained_Alignment_with_Longer_Text_CVPR_2025_paper.pdf) | |
| Illumination Spectrum Estimation for Multispectral Images via Surface Reflectance Modeling and Spatial-Spectral Feature Generation | [code](https://github.com/heyjinnii/ISS-MSI.git) | This is a repository of Illumination Spectrum Estimation for Multispectral Images via Surface Reflectance Modeling and Spatial-Spectral Feature Generation - CVPR 2025 |  | 3 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Oh_Illumination_Spectrum_Estimation_for_Multispectral_Images_via_Surface_Reflectance_Modeling_CVPR_2025_paper.pdf) | |
| UHD-processer: Unified UHD Image Restoration with Progressive Frequency Learning and Degradation-aware Prompts | [code](https://github.com/lyd-2022/UHD-processer) |  | Python | 18 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_UHD-processer_Unified_UHD_Image_Restoration_with_Progressive_Frequency_Learning_and_CVPR_2025_paper.pdf) | |
| Divot: Diffusion Powers Video Tokenizer for Comprehension and Generation | [code](https://github.com/TencentARC/Divot) | Diffusion Powers Video Tokenizer for Comprehension and Generation (CVPR 2025) | Python | 86 | 2 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ge_Divot_Diffusion_Powers_Video_Tokenizer_for_Comprehension_and_Generation_CVPR_2025_paper.pdf) | |
| SACB-Net: Spatial-awareness Convolutions for Medical Image Registration | [code](https://github.com/x-xc/SACB_Net) | SACB-Net: Spatial-awareness Convolutions for Medical Image Registration(CVPR2025) | Python | 29 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_SACB-Net_Spatial-awareness_Convolutions_for_Medical_Image_Registration_CVPR_2025_paper.pdf) | |
| DCEvo: Discriminative Cross-Dimensional Evolutionary Learning for Infrared and Visible Image Fusion | [code](https://github.com/Beate-Suy-Zhang/DCEvo) | CVPR 2025 \| DCEvo: Discriminative Cross-dimensional Evolutionary Learning for Infrared and Visible Image Fusion | Python | 76 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_DCEvo_Discriminative_Cross-Dimensional_Evolutionary_Learning_for_Infrared_and_Visible_Image_CVPR_2025_paper.pdf) | |
| PO3AD: Predicting Point Offsets toward Better 3D Point Cloud Anomaly Detection | [code](https://github.com/yjnanan/PO3AD) | Official Code for ''PO3AD: Predicting Point Offsets toward Better 3D Point Cloud Anomaly Detection'', Accepted by CVPR2025! | Python | 19 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_PO3AD_Predicting_Point_Offsets_toward_Better_3D_Point_Cloud_Anomaly_CVPR_2025_paper.pdf) | |
| Face Forgery Video Detection via Temporal Forgery Cue Unraveling | [code](https://github.com/zhenglab/TFCU) | Face Forgery Video Detection via Temporal Forgery Cue Unraveling | Python | 10 | 1 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Face_Forgery_Video_Detection_via_Temporal_Forgery_Cue_Unraveling_CVPR_2025_paper.pdf) | |
| MC^2: Multi-concept Guidance for Customized  Multi-concept Generation | [code](https://github.com/JIANGJiaXiu/MC-2) | MC$^2$: Multi-concept Guidance for Customized Multi-concept Generation |  | 31 | 0 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_MC2_Multi-concept_Guidance_for_Customized__Multi-concept_Generation_CVPR_2025_paper.pdf) | |
| Exploring Contextual Attribute Density in Referring Expression Counting | [code](http://github.com/Xu3XiWang/CAD-GD) | (CVPR25) Exploring Contextual Attribute Density in Referring Expression Counting | Python | 19 | 3 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Exploring_Contextual_Attribute_Density_in_Referring_Expression_Counting_CVPR_2025_paper.pdf) | |
| Learning Affine Correspondences by Integrating Geometric Constraints | [code](https://github.com/stilcrad/DenseAffine) |  | Python | 29 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Learning_Affine_Correspondences_by_Integrating_Geometric_Constraints_CVPR_2025_paper.pdf) | |
| SegMAN: Omni-scale Context Modeling with State Space Models and Local Attention for Semantic Segmentation | [code](https://github.com/yunxiangfu2001/SegMAN) | [CVPR 2025] SegMAN: Omni-scale Context Modeling with State Space Models and Local Attention for Semantic Segmentation | Python | 206 | 17 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_SegMAN_Omni-scale_Context_Modeling_with_State_Space_Models_and_Local_CVPR_2025_paper.pdf) | |
| OmniFlow: Any-to-Any Generation with Multi-Modal Rectified Flows | [code](https://github.com/jacklishufan/OmniFlows) | The official implementation of OmniFlow: Any-to-Any Generation with Multi-Modal Rectified Flows | Jupyter Notebook | 122 | 11 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_OmniFlow_Any-to-Any_Generation_with_Multi-Modal_Rectified_Flows_CVPR_2025_paper.pdf) | |
| Multiple Object Tracking as ID Prediction | [code](https://github.com/MCG-NJU/MOTIP) | [CVPR 2025] Multiple Object Tracking as ID Prediction | Python | 449 | 34 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Multiple_Object_Tracking_as_ID_Prediction_CVPR_2025_paper.pdf) | |
| SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos | [code](https://github.com/PKU-VCL-3DV/SLAM3R) | [CVPR 2025 Highlight] Real-time dense scene reconstruction with SLAM3R | Python | 1059 | 63 | 35 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_SLAM3R_Real-Time_Dense_Scene_Reconstruction_from_Monocular_RGB_Videos_CVPR_2025_paper.pdf) | |
| PIDLoc: Cross-View Pose Optimization Network Inspired by PID Controllers | [code](https://github.com/url-kaist/PIDLoc) | PIDLoc: Cross-View Pose Optimization Network Inspired by PID Controllers @ CVPR'25 |  | 32 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_PIDLoc_Cross-View_Pose_Optimization_Network_Inspired_by_PID_Controllers_CVPR_2025_paper.pdf) | |
| Learning Hazing to Dehazing: Towards Realistic Haze Generation for Real-World Image Dehazing | [code](https://github.com/ruiyi-w/Learning-Hazing-to-Dehazing) | [CVPR 2025] Learning Hazing to Dehazing: Towards Realistic Haze Generation for Real-World Image Dehazing | Python | 64 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Learning_Hazing_to_Dehazing_Towards_Realistic_Haze_Generation_for_Real-World_CVPR_2025_paper.pdf) | |
| Curriculum Direct Preference Optimization for Diffusion and Consistency Models | [code](https://github.com/CroitoruAlin/Curriculum-DPO) | Curriculum Direct Preference Optimization for Diffusion and Consistency Models | Python | 5 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Croitoru_Curriculum_Direct_Preference_Optimization_for_Diffusion_and_Consistency_Models_CVPR_2025_paper.pdf) | |
| IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera | [code](https://github.com/wu-cvgl/IncEventGS) | [CVPR 2025 Highlight]: IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera | Python | 101 | 9 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_IncEventGS_Pose-Free_Gaussian_Splatting_from_a_Single_Event_Camera_CVPR_2025_paper.pdf) | |
| OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection | [code](https://github.com/remic-othr/OpenMIBOOD) | Medical Imaging Benchmarks for Out-Of-Distribution Detection | Python | 35 | 6 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gutbrod_OpenMIBOOD_Open_Medical_Imaging_Benchmarks_for_Out-Of-Distribution_Detection_CVPR_2025_paper.pdf) | |
| FactCheXcker: Mitigating Measurement Hallucinations in Chest X-ray Report Generation Models | [code](https://github.com/rajpurkarlab/FactCheXcker) | This repository contains code to run the FactCheXcker pipeline on model-generated chest X-ray reports that contain quantifiable metrics, such as endotracheal tube placements. | Jupyter Notebook | 11 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Heiman_FactCheXcker_Mitigating_Measurement_Hallucinations_in_Chest_X-ray_Report_Generation_Models_CVPR_2025_paper.pdf) | |
| When the Future Becomes the Past: Taming Temporal Correspondence for Self-supervised Video Representation Learning | [code](https://github.com/yafeng19/T-CORE) | [CVPR 2025] PyTorch implementation of T-CORE, introduced in "When the Future Becomes the Past: Taming Temporal Correspondence for Self-supervised Video Representation Learning". | Python | 18 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_When_the_Future_Becomes_the_Past_Taming_Temporal_Correspondence_for_CVPR_2025_paper.pdf) | |
| UniPose: A Unified Multimodal Framework for Human Pose Comprehension; Generation and Editing | [code](https://github.com/liyiheng23/UniPose) | [CVPR 2025] UniPose: A Unified Multimodal Framework for Human Pose Comprehension, Generation and Editing | Python | 55 | 5 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_UniPose_A_Unified_Multimodal_Framework_for_Human_Pose_Comprehension_Generation_CVPR_2025_paper.pdf) | |
| NN-Former: Rethinking Graph Structure in Neural Architecture Representation | [code](https://github.com/XuRuihan/NNFormer) | Neural predictor for neural architecture | Python | 7 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_NN-Former_Rethinking_Graph_Structure_in_Neural_Architecture_Representation_CVPR_2025_paper.pdf) | |
| Reasoning to Attend: Try to Understand How <SEG> Token Works | [code](https://github.com/rui-qian/READ) | Rui Qian, Xin Yin, Dejing Douâ€ : Reasoning to Attend: Try to Understand How <SEG> Token Works (CVPR 2025) | Python | 51 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_Reasoning_to_Attend_Try_to_Understand_How_SEG_Token_Works_CVPR_2025_paper.pdf) | |
| ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams | [code](https://github.com/cdjkim/ReSpec) |  | Python | 7 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_ReSpec_Relevance_and_Specificity_Grounded_Online_Filtering_for_Learning_on_CVPR_2025_paper.pdf) | |
| A Unified Image-Dense Annotation Generation Model for Underwater Scenes | [code](https://github.com/HongkLin/TIDE) | [CVPR 2025] A Unified Image-Dense Annotation Generation Model for Underwater Scenes | Python | 52 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_A_Unified_Image-Dense_Annotation_Generation_Model_for_Underwater_Scenes_CVPR_2025_paper.pdf) | |
| R-SCoRe: Revisiting Scene Coordinate Regression for Robust Large-Scale Visual Localization | [code](https://github.com/cvg/scrstudio) | [CVPR 2025] A unified framework for Scene Coordinate Regression-based visual localization | Python | 127 | 2 | 11 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_R-SCoRe_Revisiting_Scene_Coordinate_Regression_for_Robust_Large-Scale_Visual_Localization_CVPR_2025_paper.pdf) | |
| DynRefer: Delving into Region-level Multimodal Tasks via Dynamic Resolution | [code](https://github.com/callsys/DynRefer) | [CVPR 2025] DynRefer: Delving into Region-level Multimodal Tasks via Dynamic Resolution | Python | 57 | 7 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DynRefer_Delving_into_Region-level_Multimodal_Tasks_via_Dynamic_Resolution_CVPR_2025_paper.pdf) | |
| Playing the Fool: Jailbreaking LLMs and Multimodal LLMs with Out-of-Distribution Strategy | [code](https://github.com/naver-ai/JOOD) | [CVPR 2025] Official implementation for JOOD "Playing the Fool: Jailbreaking LLMs and Multimodal LLMs with Out-of-Distribution Strategy" | Python | 19 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_Playing_the_Fool_Jailbreaking_LLMs_and_Multimodal_LLMs_with_Out-of-Distribution_CVPR_2025_paper.pdf) | |
| Style Evolving along Chain-of-Thought for Unknown-Domain Object Detection | [code](https://github.com/ZZ2490/SE-COT) |  | Jupyter Notebook | 7 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Style_Evolving_along_Chain-of-Thought_for_Unknown-Domain_Object_Detection_CVPR_2025_paper.pdf) | |
| OmniSplat: Taming Feed-Forward 3D Gaussian Splatting for Omnidirectional Images with Editable Capabilities | [code](https://github.com/esw0116/OmniSplat) | [CVPR 2025] OmniSplat: Taming Feed-Forward 3D Gaussian Splatting for Omnidirectional Images with Editable Capabilities | Python | 31 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_OmniSplat_Taming_Feed-Forward_3D_Gaussian_Splatting_for_Omnidirectional_Images_with_CVPR_2025_paper.pdf) | |
| FSHNet: Fully Sparse Hybrid Network for 3D Object Detection | [code](https://github.com/Say2L/FSHNet) | [CVPR2025] Implementation of "FSHNet: Fully Sparse Hybrid Network for 3D Object Detection" | Python | 40 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_FSHNet_Fully_Sparse_Hybrid_Network_for_3D_Object_Detection_CVPR_2025_paper.pdf) | |
| UniVAD: A Training-free Unified Model for Few-shot Visual Anomaly Detection | [code](https://github.com/FantasticGNU/UniVAD) | [CVPR 2025] UniVAD: A Training-free Unified Model for Few-shot Visual Anomaly Detection | Jupyter Notebook | 173 | 16 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_UniVAD_A_Training-free_Unified_Model_for_Few-shot_Visual_Anomaly_Detection_CVPR_2025_paper.pdf) | |
| Cross-Modal and Uncertainty-Aware Agglomeration for Open-Vocabulary 3D Scene Understanding | [code](https://github.com/TyroneLi/CUA_O3D) | CVPR2025 | Jupyter Notebook | 21 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Cross-Modal_and_Uncertainty-Aware_Agglomeration_for_Open-Vocabulary_3D_Scene_Understanding_CVPR_2025_paper.pdf) | |
| Instruct-CLIP: Improving Instruction-Guided Image Editing with Automated Data Refinement Using Contrastive Learning | [code](https://github.com/SherryXTChen/Instruct-CLIP.git) | Instruct-CLIP: Improving Instruction-Guided Image Editing with Automated Data Refinement Using Contrastive Learning (CVPR 2025) | Python | 33 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Instruct-CLIP_Improving_Instruction-Guided_Image_Editing_with_Automated_Data_Refinement_Using_CVPR_2025_paper.pdf) | |
| Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation | [code](https://github.com/mkarmann/m2n2) | Official Implementation of Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation |  | 5 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Karmann_Repurposing_Stable_Diffusion_Attention_for_Training-Free_Unsupervised_Interactive_Segmentation_CVPR_2025_paper.pdf) | |
| GO-N3RDet: Geometry Optimized NeRF-enhanced 3D Object Detector | [code](https://github.com/ZechuanLi/GO-N3RDet) | [CVPR 2025] GO-N3RDet: Geometry Optimized NeRF-enhanced 3D Object Detector | Python | 16 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_GO-N3RDet_Geometry_Optimized_NeRF-enhanced_3D_Object_Detector_CVPR_2025_paper.pdf) | |
| EvEnhancer: Empowering Effectiveness; Efficiency and Generalizability for Continuous Space-Time Video Super-Resolution with Events | [code](https://github.com/W-Shuoyan/EvEnhancer) | EvEnhancer: Empowering Effectiveness, Efficiency and Generalizability for Continuous Space-Time Video Super-Resolution with Events (CVPR 2025, Highlight) | Python | 33 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_EvEnhancer_Empowering_Effectiveness_Efficiency_and_Generalizability_for_Continuous_Space-Time_Video_CVPR_2025_paper.pdf) | |
| Reason-before-Retrieve: One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval | [code](https://github.com/microsoft/ACV/tree/main/OSrCIR) | A series of work towards achieving ACV. | Jupyter Notebook | 28 | 5 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Reason-before-Retrieve_One-Stage_Reflective_Chain-of-Thoughts_for_Training-Free_Zero-Shot_Composed_Image_Retrieval_CVPR_2025_paper.pdf) | |
| Skip Tuning: Pre-trained Vision-Language Models are Effective and Efficient Adapters Themselves | [code](https://github.com/anonymity-007/SkipT) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Skip_Tuning_Pre-trained_Vision-Language_Models_are_Effective_and_Efficient_Adapters_CVPR_2025_paper.pdf) | |
| PatchDPO: Patch-level DPO for Finetuning-free Personalized Image Generation | [code](https://github.com/hqhQAQ/PatchDPO) | [CVPR 2025] PatchDPO: Patch-level DPO for Finetuning-free Personalized Image Generation | Python | 44 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_PatchDPO_Patch-level_DPO_for_Finetuning-free_Personalized_Image_Generation_CVPR_2025_paper.pdf) | |
| Learning to Normalize on the SPD Manifold under Bures-Wasserstein Geometry | [code](https://github.com/jjscc/GBWBN) | (CVPR25) Learning to Normalize on the SPD Manifold under Bures-Wasserstein Geometry | Python | 12 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Learning_to_Normalize_on_the_SPD_Manifold_under_Bures-Wasserstein_Geometry_CVPR_2025_paper.pdf) | |
| SAMWISE: Infusing Wisdom in SAM2 for Text-Driven Video Segmentation | [code](https://github.com/ClaudiaCuttano/SAMWISE) | [CVPR 2025 Highlight] Official repository for the paper: "SAMWISE: Infusing Wisdom in SAM2 for Text-Driven Video Segmentation" | Python | 356 | 24 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cuttano_SAMWISE_Infusing_Wisdom_in_SAM2_for_Text-Driven_Video_Segmentation_CVPR_2025_paper.pdf) | |
| Omnia de EgoTempo: Benchmarking Temporal Understanding of Multi-Modal LLMs in Egocentric Videos | [code](https://github.com/google-research-datasets/egotempo.git) |  | Jupyter Notebook | 26 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Plizzari_Omnia_de_EgoTempo_Benchmarking_Temporal_Understanding_of_Multi-Modal_LLMs_in_CVPR_2025_paper.pdf) | |
| Identity-Preserving Text-to-Video Generation by Frequency Decomposition | [code](https://github.com/PKU-YuanGroup/ConsisID) | [CVPR 2025 HighlightðŸ”¥] Identity-Preserving Text-to-Video Generation by Frequency Decomposition | Python | 796 | 44 | 13 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_Identity-Preserving_Text-to-Video_Generation_by_Frequency_Decomposition_CVPR_2025_paper.pdf) | |
| FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity | [code](https://github.com/vLAR-group/FreeGave) | ðŸ”¥FreeGave in PyTorch (CVPR 2025) | Python | 33 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_FreeGave_3D_Physics_Learning_from_Dynamic_Videos_by_Gaussian_Velocity_CVPR_2025_paper.pdf) | |
| MMRL: Multi-Modal Representation Learning for Vision-Language Models | [code](https://github.com/yunncheng/MMRL) | [CVPR 2025] Official PyTorch Code for "MMRL: Multi-Modal Representation Learning for Vision-Language Models" and its extension "MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models". | Python | 90 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_MMRL_Multi-Modal_Representation_Learning_for_Vision-Language_Models_CVPR_2025_paper.pdf) | |
| MOS: Modeling Object-Scene Associations in Generalized Category Discovery | [code](https://github.com/JethroPeng/MOS) | MOS: Modeling Object-Scene Associations in Generalized Category Discovery (CVPR 2025) | Python | 9 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_MOS_Modeling_Object-Scene_Associations_in_Generalized_Category_Discovery_CVPR_2025_paper.pdf) | |
| Anchor-Aware Similarity Cohesion in Target Frames Enables Predicting Temporal Moment Boundaries in 2D | [code](https://github.com/ExMorgan-Alter/AFAFSGD) |  | Python | 6 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_Anchor-Aware_Similarity_Cohesion_in_Target_Frames_Enables_Predicting_Temporal_Moment_CVPR_2025_paper.pdf) | |
| Breaking the Low-Rank Dilemma of Linear Attention | [code](https://github.com/qhfan/RALA) | [CVPR2025] Breaking the Low-Rank Dilemma of Linear Attention | Python | 38 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_Breaking_the_Low-Rank_Dilemma_of_Linear_Attention_CVPR_2025_paper.pdf) | |
| Embracing Collaboration Over Competition: Condensing Multiple Prompts for Visual In-Context Learning | [code](https://github.com/gimpong/CVPR25-Condenser) | The code for the paper "Embracing Collaboration Over Competition: Condensing Multiple Prompts for Visual In-Context Learning" (CVPR'25). | Python | 12 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Embracing_Collaboration_Over_Competition_Condensing_Multiple_Prompts_for_Visual_In-Context_CVPR_2025_paper.pdf) | |
| Rethinking Reconstruction and Denoising in the Dark: New Perspective; General Architecture and Beyond | [code](https://github.com/csmty/CANS) | [CVPR 2025] Rethinking Reconstruction and Denoising in the Dark:New Perspective, General Architecture and Beyond | Python | 7 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Rethinking_Reconstruction_and_Denoising_in_the_Dark_New_Perspective_General_CVPR_2025_paper.pdf) | |
| Revealing Key Details to See Differences: A Novel Prototypical Perspective for Skeleton-based Action Recognition | [code](https://github.com/firework8/ProtoGCN) | [CVPR 2025 Highlight] PyTorch implementation of "Revealing Key Details to See Differences: A Novel Prototypical Perspective for Skeleton-based Action Recognition" | Python | 128 | 16 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Revealing_Key_Details_to_See_Differences_A_Novel_Prototypical_Perspective_CVPR_2025_paper.pdf) | |
| VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection | [code](https://github.com/hshjerry/VideoEspresso) | [CVPR 2025 Oral] VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection | Python | 131 | 5 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Han_VideoEspresso_A_Large-Scale_Chain-of-Thought_Dataset_for_Fine-Grained_Video_Reasoning_via_CVPR_2025_paper.pdf) | |
| DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation | [code](https://github.com/TencentARC/DiTCtrl) | [CVPR 2025] Official code of "DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation" | Python | 320 | 9 | 16 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_DiTCtrl_Exploring_Attention_Control_in_Multi-Modal_Diffusion_Transformer_for_Tuning-Free_CVPR_2025_paper.pdf) | |
| GREAT: Geometry-Intention Collaborative Inference for Open-Vocabulary 3D Object Affordance Grounding | [code](https://github.com/yawen-shao/GREAT_code) | [CVPR-2025] GREAT: Geometry-Intention Collaborative Inference for Open-Vocabulary 3D Object Affordance Grounding | Python | 33 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shao_GREAT_Geometry-Intention_Collaborative_Inference_for_Open-Vocabulary_3D_Object_Affordance_Grounding_CVPR_2025_paper.pdf) | |
| RENO: Real-Time Neural Compression for 3D LiDAR Point Clouds | [code](https://github.com/NJUVISION/RENO) | [CVPR 2025] RENO: Real-Time Neural Compression for 3D LiDAR Point Clouds | Python | 53 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/You_RENO_Real-Time_Neural_Compression_for_3D_LiDAR_Point_Clouds_CVPR_2025_paper.pdf) | |
| End-to-End Implicit Neural Representations for Classification | [code](https://github.com/SanderGielisse/MWT) | Official Repository of End-to-End Implicit Neural Representations for Classification (CVPR 2025) | Python | 11 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gielisse_End-to-End_Implicit_Neural_Representations_for_Classification_CVPR_2025_paper.pdf) | |
| FADE: Frequency-Aware Diffusion Model Factorization for Video Editing | [code](https://github.com/EternalEvan/FADE) | This is the official implementation of FADE: Frequency-Aware Diffusion Model Factorization for Video Editing (CVPR 2025) |  | 13 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_FADE_Frequency-Aware_Diffusion_Model_Factorization_for_Video_Editing_CVPR_2025_paper.pdf) | |
| Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning | [code](https://github.com/WeiDai-David/2025CVPR_GGEUR) | Geometric Knowledge-Guided Localized Global Distribution Alignment for  Federated Learning | Python | 18 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Geometric_Knowledge-Guided_Localized_Global_Distribution_Alignment_for_Federated_Learning_CVPR_2025_paper.pdf) | |
| Towards Human-Understandable Multi-Dimensional Concept Discovery | [code](https://github.com/grobruegge/hu-mcd) | Towards Human-Understandable Multi-Dimensional Concept Discovery (HU-MCD) | Python | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Grobrugge_Towards_Human-Understandable_Multi-Dimensional_Concept_Discovery_CVPR_2025_paper.pdf) | |
| ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval | [code](https://github.com/mvrl/ConText-CIR) | [CVPR'25] ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval  | Python | 15 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_ConText-CIR_Learning_from_Concepts_in_Text_for_Composed_Image_Retrieval_CVPR_2025_paper.pdf) | |
| MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks | [code](https://github.com/kaikai23/MaskGaussian) | [CVPR 2025] MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks | Python | 94 | 4 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MaskGaussian_Adaptive_3D_Gaussian_Representation_from_Probabilistic_Masks_CVPR_2025_paper.pdf) | |
| Learning Compatible Multi-Prize Subnetworks for Asymmetric Retrieval | [code](https://github.com/Bunny-Black/PrunNet) | cvpr 2025 PrunNet | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Learning_Compatible_Multi-Prize_Subnetworks_for_Asymmetric_Retrieval_CVPR_2025_paper.pdf) | |
| MetricGrids: Arbitrary Nonlinear Approximation with Elementary Metric Grids based Implicit Neural Representation | [code](https://github.com/wangshu31/MetricGrids) | [CVPR2025] MetricGrids:  Arbitrary Nonlinear Approximation with Elementary Metric Grids based Implicit Neural Representation | Python | 14 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MetricGrids_Arbitrary_Nonlinear_Approximation_with_Elementary_Metric_Grids_based_Implicit_CVPR_2025_paper.pdf) | |
| Navigating Image Restoration with VAR's Distribution Alignment Prior | [code](https://github.com/siywang541/Varformer) |  | Python | 61 | 5 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Navigating_Image_Restoration_with_VARs_Distribution_Alignment_Prior_CVPR_2025_paper.pdf) | |
| MovieBench: A Hierarchical Movie Level Dataset for Long Video Generation | [code](https://github.com/showlab/MovieBecnh) | [CVPR 2025] A Hierarchical Movie Level Dataset for Long Video Generation | Python | 78 | 2 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_MovieBench_A_Hierarchical_Movie_Level_Dataset_for_Long_Video_Generation_CVPR_2025_paper.pdf) | |
| ArtFormer: Controllable Generation of Diverse 3D Articulated Objects | [code](https://github.com/ShuYuMo2003/ArtFormer) | [CVPR 2025] ArtFormer: Controllable Generation of Diverse 3D Articulated Objects | Python | 37 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Su_ArtFormer_Controllable_Generation_of_Diverse_3D_Articulated_Objects_CVPR_2025_paper.pdf) | |
| Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations | [code](https://github.com/park-jungin/byov) | Official implementation for BYOV (CVPR 2025) | Python | 6 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Bootstrap_Your_Own_Views_Masked_Ego-Exo_Modeling_for_Fine-grained_View-invariant_CVPR_2025_paper.pdf) | |
| Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis | [code](https://github.com/Tonniia/EVS) | [CVPR 2025] Official implementation of paper: Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis | Python | 7 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Su_Encapsulated_Composition_of_Text-to-Image_and_Text-to-Video_Models_for_High-Quality_Video_CVPR_2025_paper.pdf) | |
| TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation | [code](https://github.com/ByteFlow-AI/TokenFlow) | [CVPR 2025] ðŸ”¥ Official impl. of "TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation". | Python | 419 | 6 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_TokenFlow_Unified_Image_Tokenizer_for_Multimodal_Understanding_and_Generation_CVPR_2025_paper.pdf) | |
| Improving Personalized Search with Regularized Low-Rank Parameter Updates | [code](http://github.com/adobe-research/polar-vl) | Improving Personalized Search with Regularized Low-Rank Parameter Updates (CVPR 2025, Highlight) | Jupyter Notebook | 6 | 2 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ryan_Improving_Personalized_Search_with_Regularized_Low-Rank_Parameter_Updates_CVPR_2025_paper.pdf) | |
| Adapting Dense Matching for Homography Estimation with Grid-based Acceleration | [code](https://github.com/KN-Zhang/GFNet) | Adapting Dense Matching for Homography Estimation with Grid-based Acceleration (CVPR'25) | Python | 23 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Adapting_Dense_Matching_for_Homography_Estimation_with_Grid-based_Acceleration_CVPR_2025_paper.pdf) | |
| ACE: Anti-Editing Concept Erasure in Text-to-Image Models | [code](https://github.com/120L020904/ACE) | Official implementation of â€œACE: Anti-Editing Concept Erasure in Text-to-Image Modelsâ€ | Python | 14 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_ACE_Anti-Editing_Concept_Erasure_in_Text-to-Image_Models_CVPR_2025_paper.pdf) | |
| CoSDH: Communication-Efficient Collaborative Perception via Supply-Demand Awareness and Intermediate-Late Hybridization | [code](https://github.com/Xu2729/CoSDH) |  | Python | 27 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_CoSDH_Communication-Efficient_Collaborative_Perception_via_Supply-Demand_Awareness_and_Intermediate-Late_Hybridization_CVPR_2025_paper.pdf) | |
| Stereo Anywhere: Robust Zero-Shot Deep Stereo Matching Even Where Either Stereo or Mono Fail | [code](https://github.com/bartn8/stereoanywhere) | [CVPR 2025] Stereo Anywhere: Robust Zero-Shot Deep Stereo Matching Even Where Either Stereo or Mono Fail | Python | 244 | 7 | 15 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Bartolomei_Stereo_Anywhere_Robust_Zero-Shot_Deep_Stereo_Matching_Even_Where_Either_CVPR_2025_paper.pdf) | |
| Order-Robust Class Incremental Learning: Graph-Driven Dynamic Similarity Grouping | [code](https://github.com/AIGNLAI/GDDSG) |  | Python | 19 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_Order-Robust_Class_Incremental_Learning_Graph-Driven_Dynamic_Similarity_Grouping_CVPR_2025_paper.pdf) | |
| Cross-Modal Interactive Perception Network with Mamba for Lung Tumor Segmentation in PET-CT Images | [code](https://github.com/mj129/CIPA) | The official code of "Cross-Modal Interactive Perception Network with Mamba for Lung Tumor Segmentation in PET-CT Images", CVPR 2025 | Python | 61 | 2 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mei_Cross-Modal_Interactive_Perception_Network_with_Mamba_for_Lung_Tumor_Segmentation_CVPR_2025_paper.pdf) | |
| DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification | [code](https://github.com/darrylho/DejaVid) |  | Python | 6 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ho_DejaVid_Encoder-Agnostic_Learned_Temporal_Matching_for_Video_Classification_CVPR_2025_paper.pdf) | |
| HVI: A New Color Space for Low-light Image Enhancement | [code](https://github.com/Fediory/HVI-CIDNet) | [CVPR2025 && NTIRE2025] HVI: A New Color Space for Low-light Image Enhancement (Official Implementation) | Python | 708 | 73 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_HVI_A_New_Color_Space_for_Low-light_Image_Enhancement_CVPR_2025_paper.pdf) | |
| One Diffusion to Generate Them All | [code](https://github.com/lehduong/OneDiffusion) | Official implementation of OneDiffusion paper (CVPR 2025) | Python | 662 | 19 | 34 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Le_One_Diffusion_to_Generate_Them_All_CVPR_2025_paper.pdf) | |
| Let's Verify and Reinforce Image Generation Step by Step | [code](https://github.com/ZiyuGuo99/Image-Generation-CoT) | [CVPR 2025] The First Investigation of CoT Reasoning (RL, TTS, Reflection) in Image Generation | Python | 848 | 26 | 17 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Lets_Verify_and_Reinforce_Image_Generation_Step_by_Step_CVPR_2025_paper.pdf) | |
| Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model | [code](https://github.com/Zhu1116/ARGS-Diff) | [CVPR 2025] Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model | Python | 22 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Self-Learning_Hyperspectral_and_Multispectral_Image_Fusion_via_Adaptive_Residual_Guided_CVPR_2025_paper.pdf) | |
| Reversible Decoupling Network for Single Image Reflection Removal | [code](https://github.com/lime-j/RDNet) | Reversible Decoupling Network for Single Image Reflection Removal, To be appeared in CVPR 2025 | Python | 61 | 10 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Reversible_Decoupling_Network_for_Single_Image_Reflection_Removal_CVPR_2025_paper.pdf) | |
| UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning | [code](https://github.com/ZhouLong0/UNEM-Transductive) | Code implementation for our CVPR 2025 paper: UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning | Jupyter Notebook | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_UNEM_UNrolled_Generalized_EM_for_Transductive_Few-Shot_Learning_CVPR_2025_paper.pdf) | |
| SASep: Saliency-Aware Structured Separation of Geometry and Feature for Open Set Learning on Point Clouds | [code](https://github.com/JinfengX/SASep) | SASep: Saliency-Aware Structured Separation of Geometry and Feature for Open Set Learning on Point Clouds [CVPR 2025] | Python | 2 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_SASep_Saliency-Aware_Structured_Separation_of_Geometry_and_Feature_for_Open_CVPR_2025_paper.pdf) | |
| Explaining Domain Shifts in Language: Concept Erasing for Interpretable Image Classification | [code](https://github.com/joeyz0z/LanCE) | (CVPR2025) Explaining Domain Shifts in Language: Concept erasing for Interpretable Image Classification | Python | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_Explaining_Domain_Shifts_in_Language_Concept_Erasing_for_Interpretable_Image_CVPR_2025_paper.pdf) | |
| NeighborRetr: Balancing Hub Centrality in Cross-Modal Retrieval | [code](https://github.com/zzezze/NeighborRetr) | Official implementation of "NeighborRetr: Balancing Hub Centrality in Cross-Modal Retrieval (CVPR 2025)" | Python | 8 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_NeighborRetr_Balancing_Hub_Centrality_in_Cross-Modal_Retrieval_CVPR_2025_paper.pdf) | |
| ETAP: Event-based Tracking of Any Point | [code](https://github.com/tub-rip/ETAP) | The official implementation of "ETAP: Event-based Tracking of Any Point" (CVPR 2025 Highlight)  | Python | 81 | 5 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hamann_ETAP_Event-based_Tracking_of_Any_Point_CVPR_2025_paper.pdf) | |
| Global-Local Tree Search in VLMs for 3D Indoor Scene Generation | [code](https://github.com/dw-dengwei/TreeSearchGen) | [CVPR 2025ðŸ”¥] Official codebase for "Global-Local Tree Search in VLMs for 3D Indoor Scene Generation" |  | 20 | 1 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Global-Local_Tree_Search_in_VLMs_for_3D_Indoor_Scene_Generation_CVPR_2025_paper.pdf) | |
| Overcoming Shortcut Problem in VLM for Robust Out-of-Distribution Detection | [code](https://github.com/HAIV-Lab/OSPCoOp_Imagenet-bg) | The official code repository for "Overcoming Shortcut Problem in VLM for Robust Out-of-Distribution Detection" in CVPR, 2025 | Python | 10 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Overcoming_Shortcut_Problem_in_VLM_for_Robust_Out-of-Distribution_Detection_CVPR_2025_paper.pdf) | |
| Accelerating Diffusion Transformer via Increment-Calibrated Caching with Channel-Aware Singular Value Decomposition | [code](https://github.com/ccccczzy/icc) | [CVPR 2025] Accelerating Diffusion Transformer via Increment-Calibrated with Channel-Aware Singular Value Decomposition | Python | 12 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Accelerating_Diffusion_Transformer_via_Increment-Calibrated_Caching_with_Channel-Aware_Singular_Value_CVPR_2025_paper.pdf) | |
| Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models | [code](https://github.com/hustvl/LightningDiT) | [CVPR 2025 Oral] Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models | Python | 1357 | 48 | 10 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_Reconstruction_vs._Generation_Taming_Optimization_Dilemma_in_Latent_Diffusion_Models_CVPR_2025_paper.pdf) | |
| MEAT: Multiview Diffusion Model for Human Generation on Megapixels with Mesh Attention | [code](https://github.com/johannwyh/MEAT) | [CVPR 2025] MEAT: Multiview Diffusion Model for Human Generation on Megapixels with Mesh Attention |  | 40 | 1 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MEAT_Multiview_Diffusion_Model_for_Human_Generation_on_Megapixels_with_CVPR_2025_paper.pdf) | |
| Free Lunch Enhancements for Multi-modal Crowd Counting | [code](https://github.com/HenryCilence/Free-Lunch-Multimodal-Counting) | Official Implement of CVPR 2025 Paper "Free Lunch Enhancements for Multi-modal Crowd Counting" | Python | 9 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_Free_Lunch_Enhancements_for_Multi-modal_Crowd_Counting_CVPR_2025_paper.pdf) | |
| Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment | [code](https://github.com/CompVis/diff2flow) | [CVPR 2025] Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment | Python | 95 | 4 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Schusterbauer_Diff2Flow_Training_Flow_Matching_Models_via_Diffusion_Model_Alignment_CVPR_2025_paper.pdf) | |
| AVQACL: A Novel Benchmark for Audio-Visual Question Answering Continual Learning | [code](https://github.com/kx-wu/CVPR2025_AVQACL) | AVQACL: A Novel Benchmark for Audio-Visual Question Answering Continual Learning | Python | 8 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_AVQACL_A_Novel_Benchmark_for_Audio-Visual_Question_Answering_Continual_Learning_CVPR_2025_paper.pdf) | |
| Attention IoU: Examining Biases in CelebA using Attention Maps | [code](https://github.com/aaronserianni/attention-iou) | [CVPR'25] Attention IoU: Examining Biases in CelebA using Attention Maps | Jupyter Notebook | 12 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Serianni_Attention_IoU_Examining_Biases_in_CelebA_using_Attention_Maps_CVPR_2025_paper.pdf) | |
| DropGaussian: Structural Regularization for Sparse-view Gaussian Splatting | [code](https://github.com/DCVL-3D/DropGaussian) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Park_DropGaussian_Structural_Regularization_for_Sparse-view_Gaussian_Splatting_CVPR_2025_paper.pdf) | |
| All-Day Multi-Camera Multi-Target Tracking | [code](https://github.com/QTRACKY/ADMCMT) | All-Day Multi-Camera Muti-Target Tracking |  | 15 | 0 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_All-Day_Multi-Camera_Multi-Target_Tracking_CVPR_2025_paper.pdf) | |
| Object Detection using Event Camera: A MoE Heat Conduction based Detector and A New Benchmark Dataset | [code](https://github.com/Event-AHU/OpenEvDET) | [CVPR 2025] Event Stream based Object Detection Benchmark Dataset | Python | 58 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Object_Detection_using_Event_Camera_A_MoE_Heat_Conduction_based_CVPR_2025_paper.pdf) | |
| EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering | [code](https://github.com/zhousheng97/EgoTextVQA) | [CVPR'25] ðŸŒŸðŸŒŸ EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering | Python | 44 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_EgoTextVQA_Towards_Egocentric_Scene-Text_Aware_Video_Question_Answering_CVPR_2025_paper.pdf) | |
| STCOcc: Sparse Spatial-Temporal Cascade Renovation for 3D Occupancy and Scene Flow Prediction | [code](https://github.com/lzzzzzm/STCOcc) | [CVPR2025] STCOcc: Sparse Spatial-Temporal Cascade Renovation for 3D Occupancy and Scene Flow Prediction | Python | 79 | 4 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_STCOcc_Sparse_Spatial-Temporal_Cascade_Renovation_for_3D_Occupancy_and_Scene_CVPR_2025_paper.pdf) | |
| Attention Distillation: A Unified Approach to Visual Characteristics Transfer | [code](https://github.com/xugao97/AttentionDistillation) | [CVPR 2025] Attention Distillation: A Unified Approach to Visual Characteristics Transfer | Python | 221 | 21 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Attention_Distillation_A_Unified_Approach_to_Visual_Characteristics_Transfer_CVPR_2025_paper.pdf) | |
| LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table | [code](https://github.com/matsui528/lotf) | [CVPR25] LotusFilter: Fast Diverse Nearest Neighbor Search | Python | 11 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Matsui_LotusFilter_Fast_Diverse_Nearest_Neighbor_Search_via_a_Learned_Cutoff_CVPR_2025_paper.pdf) | |
| Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction | [code](https://github.com/KLMAV-CUC/GDB-NeRF) | [CVPR 2025] Code for "Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction" | Python | 4 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Depth-Guided_Bundle_Sampling_for_Efficient_Generalizable_Neural_Radiance_Field_Reconstruction_CVPR_2025_paper.pdf) | |
| TinyFusion: Diffusion Transformers Learned Shallow | [code](https://github.com/VainF/TinyFusion) | [CVPR 2025 Highlight] TinyFusion: Diffusion Transformers Learned Shallow | Python | 153 | 4 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_TinyFusion_Diffusion_Transformers_Learned_Shallow_CVPR_2025_paper.pdf) | |
| SVG-IR: Spatially-Varying Gaussian Splatting for Inverse Rendering | [code](https://github.com/learner-shx/SVG-IR) |  | Python | 33 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_SVG-IR_Spatially-Varying_Gaussian_Splatting_for_Inverse_Rendering_CVPR_2025_paper.pdf) | |
| Beyond Single-Modal Boundary: Cross-Modal Anomaly Detection through Visual Prototype and Harmonization | [code](https://github.com/Kerio99/CMAD) |  |  | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_Beyond_Single-Modal_Boundary_Cross-Modal_Anomaly_Detection_through_Visual_Prototype_and_CVPR_2025_paper.pdf) | |
| Align-KD: Distilling Cross-Modal Alignment Knowledge for Mobile Vision-Language Large Model Enhancement | [code](https://github.com/fqhank/Align-KD) |  | Python | 33 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Align-KD_Distilling_Cross-Modal_Alignment_Knowledge_for_Mobile_Vision-Language_Large_Model_CVPR_2025_paper.pdf) | |
| Scaling Mesh Generation via Compressive Tokenization | [code](https://github.com/whaohan/bpt) | webpage | JavaScript | 0 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Weng_Scaling_Mesh_Generation_via_Compressive_Tokenization_CVPR_2025_paper.pdf) | |
| LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds | [code](https://github.com/vLARgroup/LogoSP) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_LogoSP_Local-global_Grouping_of_Superpoints_for_Unsupervised_Semantic_Segmentation_of_CVPR_2025_paper.pdf) | |
| Exploring Intrinsic Normal Prototypes within a Single Image for Universal Anomaly Detection | [code](https://github.com/luow23/INP-Former) | [CVPR 2025] official implementation of â€œExploring Intrinsic Normal Prototypes within a Single Image for Universal Anomaly Detectionâ€ | Python | 253 | 30 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Exploring_Intrinsic_Normal_Prototypes_within_a_Single_Image_for_Universal_CVPR_2025_paper.pdf) | |
| X-Dyna: Expressive Dynamic Human Image Animation | [code](https://github.com/bytedance/X-Dyna) | [CVPR 2025 Highlight] X-Dyna: Expressive Dynamic Human Image Animation | Python | 260 | 24 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_X-Dyna_Expressive_Dynamic_Human_Image_Animation_CVPR_2025_paper.pdf) | |
| Towards Effective and Sparse Adversarial Attack on Spiking Neural Networks via Breaking Invisible Surrogate Gradients | [code](https://github.com/ryime/PDSG-SDA) | [CVPR 2025] Official implementation of "Towards Effective and Sparse Adversarial Attack on Spiking Neural Networks via Breaking Invisible Surrogate Gradients" | Python | 8 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lun_Towards_Effective_and_Sparse_Adversarial_Attack_on_Spiking_Neural_Networks_CVPR_2025_paper.pdf) | |
| Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation | [code](https://github.com/ENSTA-U2IS-AI/Uncertainty_diffusion) |  | Python | 3 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Franchi_Towards_Understanding_and_Quantifying_Uncertainty_for_Text-to-Image_Generation_CVPR_2025_paper.pdf) | |
| PS-Diffusion: Photorealistic Subject-Driven Image Editing with Disentangled Control and Attention | [code](https://github.com/wei-cheng777/PS-Diffusion) | Official implementations for paper: PS-Diffusion: Photorealistic Subject-Driven Image Editing with Disentangled Control and Attention | Python | 19 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_PS-Diffusion_Photorealistic_Subject-Driven_Image_Editing_with_Disentangled_Control_and_Attention_CVPR_2025_paper.pdf) | |
| Few-shot Implicit Function Generation via Equivariance | [code](https://github.com/JeanDiable/EquiGen) | Official Implementation of "Few-shot Implicit Function Generation via Equivariance" (CVPR 2025 Highlight) | Python | 9 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Few-shot_Implicit_Function_Generation_via_Equivariance_CVPR_2025_paper.pdf) | |
| RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark | [code](https://github.com/zhasion/RSAR) | [CVPR 2025] Official implementation for the paper "RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark". | Python | 145 | 10 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_RSAR_Restricted_State_Angle_Resolver_and_Rotated_SAR_Benchmark_CVPR_2025_paper.pdf) | |
| DTGBrepGen: A Novel B-rep Generative Model through Decoupling Topology and Geometry | [code](https://github.com/jinli99/DTGBrepGen) | [CVPR 2025] DTGBrepGen: A Novel B-rep Generative Model through Decoupling Topology and Geometry | Python | 64 | 9 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DTGBrepGen_A_Novel_B-rep_Generative_Model_through_Decoupling_Topology_and_CVPR_2025_paper.pdf) | |
| RANGE: Retrieval Augmented Neural Fields for Multi-Resolution Geo-Embeddings | [code](https://github.com/mvrl/RANGE) | RANGE: Retrieval Augmented Neural Fields for Multi-Resolution Geo Embeddings (CVPR 2025) | Python | 9 | 2 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dhakal_RANGE_Retrieval_Augmented_Neural_Fields_for_Multi-Resolution_Geo-Embeddings_CVPR_2025_paper.pdf) | |
| SimMotionEdit: Text-Based Human Motion Editing with Motion Similarity Prediction | [code](https://github.com/lzhyu/SimMotionEdit) | [CVPR 2025] Official implementation of the paper "SimMotionEdit: Text-Based Human Motion Editing with Motion Similarity Prediction" | Python | 42 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_SimMotionEdit_Text-Based_Human_Motion_Editing_with_Motion_Similarity_Prediction_CVPR_2025_paper.pdf) | |
| Object-aware Sound Source Localization via Audio-Visual Scene Understanding | [code](https://github.com/VisualAIKHU/OA-SSL) | Official Repository for "Object-aware Sound Source Localization via Audio-Visual Scene Understanding" (CVPR 2025) |  | 5 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Um_Object-aware_Sound_Source_Localization_via_Audio-Visual_Scene_Understanding_CVPR_2025_paper.pdf) | |
| Augmented Deep Contexts for Spatially Embedded Video Coding | [code](https://github.com/EsakaK/SEVC) | Spatially Embedded Video Codec | Python | 13 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Bian_Augmented_Deep_Contexts_for_Spatially_Embedded_Video_Coding_CVPR_2025_paper.pdf) | |
| Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging | [code](https://github.com/pwangcs/ProxUnroll) | [CVPR 2025]  "Proximal Algorithm Unrolling: Flexible and Interpretable Reconstruction Networks for Single-Pixel Imaging" | Python | 13 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Proximal_Algorithm_Unrolling_Flexible_and_Efficient_Reconstruction_Networks_for_Single-Pixel_CVPR_2025_paper.pdf) | |
| Image Quality Assessment: From Human to Machine Preference | [code](https://github.com/lcysyzxdxc/MPD) | [CVPR 2025 æ»¡åˆ†è®ºæ–‡ Ratings: 555] |  | 36 | 0 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Image_Quality_Assessment_From_Human_to_Machine_Preference_CVPR_2025_paper.pdf) | |
| Sound Bridge: Associating Egocentric and Exocentric Videos via Audio Cues | [code](https://github.com/shhuangcoder/SoundBridge) | SoundBridge | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Sound_Bridge_Associating_Egocentric_and_Exocentric_Videos_via_Audio_Cues_CVPR_2025_paper.pdf) | |
| Detecting Backdoor Attacks in Federated Learning via Direction Alignment Inspection | [code](https://github.com/JiiahaoXU/AlignIns) | [CVPR 2025] The official Pytorch implementation of AlignIns | Python | 15 | 5 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Detecting_Backdoor_Attacks_in_Federated_Learning_via_Direction_Alignment_Inspection_CVPR_2025_paper.pdf) | |
| OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations | [code](https://github.com/opendatalab/OmniDocBench) | [CVPR 2025] A Comprehensive Benchmark for Document Parsing and Evaluation | Python | 1353 | 128 | 11 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ouyang_OmniDocBench_Benchmarking_Diverse_PDF_Document_Parsing_with_Comprehensive_Annotations_CVPR_2025_paper.pdf) | |
| Panorama Generation From NFoV Image Done Right | [code](https://github.com/iSEE-Laboratory/PanoDecouple/) | (CVPR2025 Highlight) Official repository of paper "Panorama Generation From NFoV Image Done Right" |  | 18 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Panorama_Generation_From_NFoV_Image_Done_Right_CVPR_2025_paper.pdf) | |
| Robust Message Embedding via Attention Flow-Based Steganography | [code](https://github.com/huayuan4396/RMSteg) | [CVPR2025ðŸš€] Robust Message Embedding via Attention Flow-Based Steganography | Python | 47 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Robust_Message_Embedding_via_Attention_Flow-Based_Steganography_CVPR_2025_paper.pdf) | |
| Task-driven Image Fusion with Learnable Fusion Loss | [code](https://github.com/HaowenBai/TDFusion) |  | Python | 36 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Bai_Task-driven_Image_Fusion_with_Learnable_Fusion_Loss_CVPR_2025_paper.pdf) | |
| PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies | [code](https://github.com/rohban-lab/PatchGuard) |  | Jupyter Notebook | 14 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Nafez_PatchGuard_Adversarially_Robust_Anomaly_Detection_and_Localization_through_Vision_Transformers_CVPR_2025_paper.pdf) | |
| Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians | [code](https://github.com/murcherful/GauPCRender) | This is the implementation of the paper "Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians"(CVPR 2025). | Python | 17 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Sparse_Point_Cloud_Patches_Rendering_via_Splitting_2D_Gaussians_CVPR_2025_paper.pdf) | |
| Distilling Monocular Foundation Model for Fine-grained Depth Completion | [code](https://github.com/Sharpiless/DMD3C) | 1st Place on KITTI Depth Completion Leaderboard, Official Code of "[CVPR 2025] Distilling Monocular Foundation Model for Fine-grained Depth Completion" | Python | 88 | 6 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Distilling_Monocular_Foundation_Model_for_Fine-grained_Depth_Completion_CVPR_2025_paper.pdf) | |
| Neural Video Compression with Context Modulation | [code](https://github.com/Austin4USTC/DCMVC) |  | Python | 15 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.pdf) | |
| Less Attention is More: Prompt Transformer for Generalized Category Discovery | [code](https://github.com/wendy26zhang/AptGCD) | [CVPR2025] Less Attention is More: Prompt Transformer for Generalized Category Discovery | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Less_Attention_is_More_Prompt_Transformer_for_Generalized_Category_Discovery_CVPR_2025_paper.pdf) | |
| ScaleLSD: Scalable Deep Line Segment Detection Streamlined | [code](https://github.com/ant-research/scalelsd) | [CVPR 2025] ScaleLSD: Scalable Deep Line Segment Detection Streamlined | Python | 39 | 4 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ke_ScaleLSD_Scalable_Deep_Line_Segment_Detection_Streamlined_CVPR_2025_paper.pdf) | |
| CGMatch: A Different Perspective of Semi-supervised Learning | [code](https://github.com/BoCheng-96/CGMatch) |  | Python | 23 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_CGMatch_A_Different_Perspective_of_Semi-supervised_Learning_CVPR_2025_paper.pdf) | |
| D^2iT: Dynamic Diffusion Transformer for Accurate Image Generation | [code](https://github.com/jiawn-creator/Dynamic-DiT) |  |  | 18 | 0 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_D2iT_Dynamic_Diffusion_Transformer_for_Accurate_Image_Generation_CVPR_2025_paper.pdf) | |
| Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval | [code](https://github.com/aimagelab/ReT) | [CVPR 2025] Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval | Python | 33 | 1 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Caffagni_Recurrence-Enhanced_Vision-and-Language_Transformers_for_Robust_Multimodal_Document_Retrieval_CVPR_2025_paper.pdf) | |
| BASKET: A Large-Scale Video Dataset for Fine-Grained Skill Estimation | [code](https://github.com/yulupan00/BASKET) |  | Python | 26 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_BASKET_A_Large-Scale_Video_Dataset_for_Fine-Grained_Skill_Estimation_CVPR_2025_paper.pdf) | |
| DynPose: Largely Improving the Efficiency of Human Pose Estimation by a Simple Dynamic Framework | [code](https://github.com/Aritoria/DynPose) |  | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_DynPose_Largely_Improving_the_Efficiency_of_Human_Pose_Estimation_by_CVPR_2025_paper.pdf) | |
| Arbitrary-steps Image Super-resolution via Diffusion Inversion | [code](https://github.com/zsyOAOA/InvSR) | Arbitrary-steps Image Super-resolution via Diffusion Inversion (CVPR 2025) | Python | 1360 | 88 | 16 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yue_Arbitrary-steps_Image_Super-resolution_via_Diffusion_Inversion_CVPR_2025_paper.pdf) | |
| ComfyBench: Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems | [code](https://github.com/xxyQwQ/ComfyBench) | Implementation for the paper "ComfyBench: Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems". | Python | 197 | 10 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_ComfyBench_Benchmarking_LLM-based_Agents_in_ComfyUI_for_Autonomously_Designing_Collaborative_CVPR_2025_paper.pdf) | |
| Golden Cudgel Network for Real-Time Semantic Segmentation | [code](https://github.com/gyyang23/GCNet) |  | Python | 56 | 6 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Golden_Cudgel_Network_for_Real-Time_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| Multi-Sensor Object Anomaly Detection: Unifying Appearance; Geometry; and Internal Properties | [code](https://github.com/ZZZBBBZZZ/MulSen-AD) | Multi-Sensor Object Anomaly Detection: Unifying Appearance, Geometry, and Internal Properties(CVPR'25) | Python | 76 | 5 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Multi-Sensor_Object_Anomaly_Detection_Unifying_Appearance_Geometry_and_Internal_Properties_CVPR_2025_paper.pdf) | |
| Fancy123: One Image to High-Quality 3D Mesh Generation via Plug-and-Play Deformation | [code](https://github.com/YuQiao0303/Fancy123) | [CVPR2025]Fancy123: One Image to High-Quality 3D Mesh Generation via Plug-and-Play Deformation | Python | 62 | 2 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Fancy123_One_Image_to_High-Quality_3D_Mesh_Generation_via_Plug-and-Play_CVPR_2025_paper.pdf) | |
| AeSPa : Attention-guided Self-supervised Parallel Imaging for MRI Reconstruction | [code](https://github.com/joojinho97/AeSPa.git) | zero shot scan specific mri reconstruction  | Python | 8 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Joo_AeSPa__Attention-guided_Self-supervised_Parallel_Imaging_for_MRI_Reconstruction_CVPR_2025_paper.pdf) | |
| Spatiotemporal Decoupling for Efficient Vision-Based Occupancy Forecasting | [code](https://github.com/BIT-XJY/EfficientOCF) | [CVPR 2025] Spatiotemporal Decoupling for Efficient Vision-Based Occupancy Forecasting | Python | 25 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Spatiotemporal_Decoupling_for_Efficient_Vision-Based_Occupancy_Forecasting_CVPR_2025_paper.pdf) | |
| DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving | [code](https://github.com/hustvl/DiffusionDrive) | [CVPR 2025 Highlight] Truncated Diffusion Model for Real-Time End-to-End Autonomous Driving | Python | 1227 | 110 | 26 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_DiffusionDrive_Truncated_Diffusion_Model_for_End-to-End_Autonomous_Driving_CVPR_2025_paper.pdf) | |
| FFR: Frequency Feature Rectification for Weakly Supervised Semantic Segmentation | [code](https://github.com/yay97/FFR) |  |  | 1 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_FFR_Frequency_Feature_Rectification_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| DriveGEN: Generalized and Robust 3D Detection in Driving via Controllable Text-to-Image Diffusion Generation | [code](https://github.com/Hongbin98/DriveGEN) | This is the official project repository for "DriveGEN: Generalized and Robust 3D Detection in Driving via Controllable Text-to-Image Diffusion Generation" (CVPR 2025) | Python | 35 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_DriveGEN_Generalized_and_Robust_3D_Detection_in_Driving_via_Controllable_CVPR_2025_paper.pdf) | |
| Training-free Dense-Aligned Diffusion Guidance for Modular Conditional Image Synthesis | [code](https://github.com/ZixuanWang0525/DADG) |  |  | 2 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Training-free_Dense-Aligned_Diffusion_Guidance_for_Modular_Conditional_Image_Synthesis_CVPR_2025_paper.pdf) | |
| LightLoc: Learning Outdoor LiDAR Localization at Light Speed | [code](https://github.com/liw95/LightLoc) | [CVPR2025] LightLoc: Learning Outdoor LiDAR Localization at Light Speed | Python | 80 | 5 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LightLoc_Learning_Outdoor_LiDAR_Localization_at_Light_Speed_CVPR_2025_paper.pdf) | |
| Classifier-guided CLIP Distillation for Unsupervised Multi-label Classification | [code](https://github.com/k0u-id/CCD) |  | Python | 7 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Classifier-guided_CLIP_Distillation_for_Unsupervised_Multi-label_Classification_CVPR_2025_paper.pdf) | |
| UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units | [code](https://github.com/kk9six/umotion) | Uncertainty-driven Human Motion Estimation from IMU and UWB | Python | 13 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_UMotion_Uncertainty-driven_Human_Motion_Estimation_from_Inertial_and_Ultra-wideband_Units_CVPR_2025_paper.pdf) | |
| STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models | [code](https://github.com/koushiksrivats/robust-concept-erasing) | [â­ CVPR 2025 Highlight â­] Official Implementation of the paper STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models | Python | 28 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Srivatsan_STEREO_A_Two-Stage_Framework_for_Adversarially_Robust_Concept_Erasing_from_CVPR_2025_paper.pdf) | |
| Enhancing Dataset Distillation via Non-Critical Region Refinement | [code](https://github.com/tmtuan1307/NRR-DD) |  |  | 0 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tran_Enhancing_Dataset_Distillation_via_Non-Critical_Region_Refinement_CVPR_2025_paper.pdf) | |
| Attend to Not Attended: Structure-then-Detail Token Merging for Post-training DiT Acceleration | [code](https://github.com/ICTMCG/SDTM) | Official repository for "Attend to Not Attended: Structure-then-Detail Token Merging for Post-training DiT Acceleration", which has been accepted by CVPR 2025. | Python | 15 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Attend_to_Not_Attended_Structure-then-Detail_Token_Merging_for_Post-training_DiT_CVPR_2025_paper.pdf) | |
| Higher-Order Ratio Cycles for Fast and Globally Optimal Shape Matching | [code](https://github.com/paul0noah/product-graph-cycles/) | Official repository for the CVPR paper: Higher-Order Ratio Cycles for Fast and Globally Optimal Shape Matching | C++ | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Roetzer_Higher-Order_Ratio_Cycles_for_Fast_and_Globally_Optimal_Shape_Matching_CVPR_2025_paper.pdf) | |
| SVFR: A Unified Framework for Generalized Video Face Restoration | [code](https://github.com/wangzhiyaoo/SVFR.git) | Official implementation of SVFR. | Python | 837 | 90 | 14 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SVFR_A_Unified_Framework_for_Generalized_Video_Face_Restoration_CVPR_2025_paper.pdf) | |
| Decoupling Fine Detail and Global Geometry for Compressed Depth Map Super-Resolution | [code](https://github.com/Ian0926/GDNet) | [CVPR 2025] Official implementation for "Decoupling Fine Detail and Global Geometry for Compressed Depth Map Super-Resolution" |  | 3 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Decoupling_Fine_Detail_and_Global_Geometry_for_Compressed_Depth_Map_CVPR_2025_paper.pdf) | |
| Test-Time Visual In-Context Tuning | [code](https://github.com/Jiahao000/VICT) | [CVPR 2025] Test-Time Visual In-Context Tuning | Python | 25 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Test-Time_Visual_In-Context_Tuning_CVPR_2025_paper.pdf) | |
| Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge Models | [code](https://github.com/hren20/NaiviBridger) | [CVPR2025] Prior Does Matter: Visual Navigation via Denoising Diffusion Brdige Models | Python | 67 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Prior_Does_Matter_Visual_Navigation_via_Denoising_Diffusion_Bridge_Models_CVPR_2025_paper.pdf) | |
| MeshGen: Generating PBR Textured Mesh with Render-Enhanced Auto-Encoder and Generative Data Augmentation | [code](https://github.com/heheyas/MeshGen) | [CVPR 2025 Highlight] MeshGen: Generating PBR Textured Mesh with Render-Enhanced Auto-Encoder and Generative Data Augmentation | Python | 62 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_MeshGen_Generating_PBR_Textured_Mesh_with_Render-Enhanced_Auto-Encoder_and_Generative_CVPR_2025_paper.pdf) | |
| Neuron: Learning Context-Aware Evolving Representations for Zero-Shot Skeleton Action Recognition | [code](https://github.com/cseeyangchen/Neuron) | ã€CVPR 25ã€‘This is an official PyTorch code of "Neuron: Learning Context-Aware Evolving Representations for Zero-Shot Skeleton Action Recognition" in CVPR 2025. | Python | 11 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Neuron_Learning_Context-Aware_Evolving_Representations_for_Zero-Shot_Skeleton_Action_Recognition_CVPR_2025_paper.pdf) | |
| High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model | [code](https://github.com/MingtaoGuo/Relightable-Portrait-Animation) | [CVPR 2025] High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model | Python | 58 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_High-Fidelity_Relightable_Monocular_Portrait_Animation_with_Lighting-Controllable_Video_Diffusion_Model_CVPR_2025_paper.pdf) | |
| Plug-and-Play PPO: An Adaptive Point Prompt Optimizer Making SAM Greater | [code](https://github.com/XueyuLiu/PPO) | The official implementation code for Plug-and-Play PPO: An Adaptive Point Prompt Optimizer Making SAM Greater. | Jupyter Notebook | 25 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Plug-and-Play_PPO_An_Adaptive_Point_Prompt_Optimizer_Making_SAM_Greater_CVPR_2025_paper.pdf) | |
| EchoONE: Segmenting Multiple Echocardiography Planes in One Model | [code](https://github.com/a2502503/EchoONE) |  | Python | 20 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_EchoONE_Segmenting_Multiple_Echocardiography_Planes_in_One_Model_CVPR_2025_paper.pdf) | |
| Patch Matters: Training-free Fine-grained Image Caption Enhancement via Local Perception | [code](https://github.com/GeWu-Lab/Patch-Matters) | [CVPR2025] Code Release of Patch Matters: Training-free Fine-grained Image Caption Enhancement via Local Perception | Python | 19 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_Patch_Matters_Training-free_Fine-grained_Image_Caption_Enhancement_via_Local_Perception_CVPR_2025_paper.pdf) | |
| Unlocking Generalization Power in LiDAR Point Cloud Registration | [code](https://github.com/peakpang/UGP) | [CVPR 2025 Highlight] Unlocking Generalization Power in LiDAR Point Cloud Registration |  | 61 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_Unlocking_Generalization_Power_in_LiDAR_Point_Cloud_Registration_CVPR_2025_paper.pdf) | |
| LoRA Recycle: Unlocking Tuning-Free Few-Shot Adaptability in Visual Foundation Models by Recycling Pre-Tuned LoRAs | [code](https://github.com/Egg-Hu/LoRA-Recycle) | [CVPR 2025] LoRA Recycle: Unlocking Tuning-Free Few-Shot Adaptability in Visual Foundation Models by Recycling Pre-Tuned LoRAs | Python | 12 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_LoRA_Recycle_Unlocking_Tuning-Free_Few-Shot_Adaptability_in_Visual_Foundation_Models_CVPR_2025_paper.pdf) | |
| Contextual AD Narration with Interleaved Multimodal Sequence | [code](https://github.com/ant-research/UniAD) | [CVPR'25] Official implementation for paper - Contextual AD Narration with Interleaved Multimodal Sequence | Python | 7 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Contextual_AD_Narration_with_Interleaved_Multimodal_Sequence_CVPR_2025_paper.pdf) | |
| MNE-SLAM: Multi-Agent Neural SLAM for Mobile Robots | [code](https://github.com/dtc111111/MNESLAM) | [CVPR 2025] MNE-SLAM | Python | 171 | 8 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_MNE-SLAM_Multi-Agent_Neural_SLAM_for_Mobile_Robots_CVPR_2025_paper.pdf) | |
| TensoFlow: Tensorial Flow-based Sampler for Inverse Rendering | [code](https://github.com/fudan-zvg/tensoflow) | [CVPR 2025] TensoFlow: Tensorial Flow-based Sampler for Inverse Rendering | Python | 14 | 0 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_TensoFlow_Tensorial_Flow-based_Sampler_for_Inverse_Rendering_CVPR_2025_paper.pdf) | |
| FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering | [code](https://github.com/chengyuehuang511/FRAMES-VQA) | [CVPR'25] The official implementation of "FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering" | Python | 7 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_FRAMES-VQA_Benchmarking_Fine-Tuning_Robustness_across_Multi-Modal_Shifts_in_Visual_Question_CVPR_2025_paper.pdf) | |
| MambaIRv2: Attentive State Space Restoration | [code](https://github.com/csguoh/MambaIR) | [ECCV2024, CVPR2025] MambaIR and MambaIRv2! | Python | 995 | 78 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_MambaIRv2_Attentive_State_Space_Restoration_CVPR_2025_paper.pdf) | |
| POT: Prototypical Optimal Transport for Weakly Supervised Semantic Segmentation | [code](https://github.com/jianwang91/POT) |  | Python | 11 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_POT_Prototypical_Optimal_Transport_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D Semantic Occupancy Prediction | [code](https://github.com/cdb342/GDFusion) | [CVPR 2025] Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D Semantic Occupancy Prediction | Python | 32 | 2 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Rethinking_Temporal_Fusion_with_a_Unified_Gradient_Descent_View_for_CVPR_2025_paper.pdf) | |
| Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents | [code](https://github.com/runamu/monday) | [CVPR 2025] Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents | Python | 32 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Scalable_Video-to-Dataset_Generation_for_Cross-Platform_Mobile_Agents_CVPR_2025_paper.pdf) | |
| STAR-Edge: Structure-aware Local Spherical Curve Representation for Thin-walled Edge Extraction from Unstructured Point Clouds | [code](https://github.com/Miraclelzk/STAR-Edge) | [CVPR 2025] STAR-Edge: Structure-aware Local Spherical Curve Representation for Thin-walled Edge Extraction from Unstructured Point Clouds | C++ | 35 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_STAR-Edge_Structure-aware_Local_Spherical_Curve_Representation_for_Thin-walled_Edge_Extraction_CVPR_2025_paper.pdf) | |
| Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images | [code](https://github.com/CastleChen339/DehazeXL) | [CVPR 2025] Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images | Python | 64 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Tokenize_Image_Patches_Global_Context_Fusion_for_Effective_Haze_Removal_CVPR_2025_paper.pdf) | |
| Complementary Advantages: Exploiting Cross-Field Frequency Correlation for NIR-Assisted Image Denoising | [code](https://github.com/yuchenwang815/FCENet) |  |  | 16 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Complementary_Advantages_Exploiting_Cross-Field_Frequency_Correlation_for_NIR-Assisted_Image_Denoising_CVPR_2025_paper.pdf) | |
| Boosting the Dual-Stream Architecture in Ultra-High Resolution Segmentation with Resolution-Biased Uncertainty Estimation | [code](https://github.com/Qinrong-NKU/RUE) |  | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_Boosting_the_Dual-Stream_Architecture_in_Ultra-High_Resolution_Segmentation_with_Resolution-Biased_CVPR_2025_paper.pdf) | |
| Neuro-3D: Towards 3D Visual Decoding from EEG Signals | [code](https://github.com/gzq17/neuro-3D) |  | Python | 44 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Neuro-3D_Towards_3D_Visual_Decoding_from_EEG_Signals_CVPR_2025_paper.pdf) | |
| FastVLM: Efficient Vision Encoding for Vision Language Models | [code](https://github.com/apple/ml-fastvlm) | This repository contains the official implementation of "FastVLM: Efficient Vision Encoding for Vision Language Models" - CVPR 2025 | Python | 7142 | 530 | 66 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Vasu_FastVLM_Efficient_Vision_Encoding_for_Vision_Language_Models_CVPR_2025_paper.pdf) | |
| VISTA3D: A Unified Segmentation Foundation Model For 3D Medical Imaging | [code](https://github.com/Project-MONAI/VISTA) | MONAI Versatile Imaging Segmentation and Annotation | Python | 258 | 36 | 10 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/He_VISTA3D_A_Unified_Segmentation_Foundation_Model_For_3D_Medical_Imaging_CVPR_2025_paper.pdf) | |
| S2D-LFE: Sparse-to-Dense Light Field Event Generation | [code](https://github.com/Yutong2022/S2D-LFE) |  | C++ | 2 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_S2D-LFE_Sparse-to-Dense_Light_Field_Event_Generation_CVPR_2025_paper.pdf) | |
| Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data | [code](https://github.com/theEricMa/TriplaneTurbo) | [CVPR2025] Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data | Python | 67 | 6 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Progressive_Rendering_Distillation_Adapting_Stable_Diffusion_for_Instant_Text-to-Mesh_Generation_CVPR_2025_paper.pdf) | |
| Derivative-Free Diffusion Manifold-Constrained Gradient for Unified XAI | [code](https://github.com/one-june/FreeMCG) | Official pytorch repository for "Derivative-Free Diffusion Manifold-Constrained Gradient for Unified XAI" | Python | 14 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Derivative-Free_Diffusion_Manifold-Constrained_Gradient_for_Unified_XAI_CVPR_2025_paper.pdf) | |
| Do Computer Vision Foundation Models Learn the Low-level Characteristics of the Human Visual System? | [code](https://github.com/caiyancheng/VFM_HVS_CVPR2025) |  | JavaScript | 13 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_Do_Computer_Vision_Foundation_Models_Learn_the_Low-level_Characteristics_of_CVPR_2025_paper.pdf) | |
| Towards RAW Object Detection in Diverse Conditions | [code](https://github.com/lzyhha/AODRaw) | (CVPR 2025 Highlight) Official repository of paper "AODRaw: Towards RAW Object Detection in Diverse Conditions" (https://arxiv.org/pdf/2411.15678) | Python | 35 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Towards_RAW_Object_Detection_in_Diverse_Conditions_CVPR_2025_paper.pdf) | |
| FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image Pre-training | [code](https://github.com/MIV-XJTU/FLAME) | [CVPR 2025] PyTorch implementation of paper "FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image Pre-training" | Python | 32 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_FLAME_Frozen_Large_Language_Models_Enable_Data-Efficient_Language-Image_Pre-training_CVPR_2025_paper.pdf) | |
| DV-Matcher: Deformation-based Non-rigid Point Cloud Matching Guided by Pre-trained Visual Features | [code](https://github.com/rqhuang88/DV-Matcher) | [CVPR 2025] DV-Matcher: Deformation-based Non-Rigid Point Cloud Matching Guided by Pre-trained Visual Features | Python | 29 | 4 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_DV-Matcher_Deformation-based_Non-rigid_Point_Cloud_Matching_Guided_by_Pre-trained_Visual_CVPR_2025_paper.pdf) | |
| Adapter Merging with Centroid Prototype Mapping for Scalable Class-Incremental Learning | [code](https://github.com/tf63/ACMap) | [CVPR2025] The implementation of Adapter Merging with Centroid Prototype Mapping for Scalable Class-Incremental Learning | Python | 16 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fukuda_Adapter_Merging_with_Centroid_Prototype_Mapping_for_Scalable_Class-Incremental_Learning_CVPR_2025_paper.pdf) | |
| OpenSDI: Spotting Diffusion-Generated Images in the Open World | [code](https://github.com/iamwangyabin/OpenSDI) | Official repository for CVPR 2025 paper: OpenSDI: Spotting Diffusion-Generated Images in the Open World | Python | 39 | 5 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_OpenSDI_Spotting_Diffusion-Generated_Images_in_the_Open_World_CVPR_2025_paper.pdf) | |
| Online Task-Free Continual Learning via Dynamic Expansionable Memory Distribution | [code](https://github.com/dtuzi123/DEMD) |  |  | 1 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Online_Task-Free_Continual_Learning_via_Dynamic_Expansionable_Memory_Distribution_CVPR_2025_paper.pdf) | |
| DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention | [code](https://github.com/hustvl/DiG) | [CVPR 2025] DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention | Python | 176 | 9 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_DiG_Scalable_and_Efficient_Diffusion_Models_with_Gated_Linear_Attention_CVPR_2025_paper.pdf) | |
| Rethinking Token Reduction with Parameter-Efficient Fine-Tuning in ViT for Pixel-Level Tasks | [code](https://github.com/AVC2-UESTC/DAR-TR-PEFT) | [CVPR2025] Rethinking Token Reduction with Parameter-Efficient Fine-Tuning in ViT for Pixel-Level Tasks | Python | 5 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lei_Rethinking_Token_Reduction_with_Parameter-Efficient_Fine-Tuning_in_ViT_for_Pixel-Level_CVPR_2025_paper.pdf) | |
| SVDC: Consistent Direct Time-of-Flight Video Depth Completion with Frequency Selective Fusion | [code](https://github.com/Lan1eve/SVDC) | [CVPR 2025] SVDC : Consistent Direct Time-of-Flight Video Depth Completion with Frequency Selective Fusion | Python | 29 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_SVDC_Consistent_Direct_Time-of-Flight_Video_Depth_Completion_with_Frequency_Selective_CVPR_2025_paper.pdf) | |
| FLAIR: VLM with Fine-grained Language-informed Image Representations | [code](https://github.com/ExplainableML/flair) | [CVPR 2025] FLAIR: VLM with Fine-grained Language-informed Image Representations | Python | 129 | 6 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_FLAIR_VLM_with_Fine-grained_Language-informed_Image_Representations_CVPR_2025_paper.pdf) | |
| Exploiting Temporal State Space Sharing for Video Semantic Segmentation | [code](https://github.com/Ashesham/TV3S.git) | Official implementation of TV3S [CVPR25] | Python | 9 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hesham_Exploiting_Temporal_State_Space_Sharing_for_Video_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| SSHNet: Unsupervised Cross-modal Homography Estimation via Problem Reformulation and Split Optimization | [code](https://github.com/Junchen-Yu/SSHNet) | This is the open source implementation of the CVPR2025 paper "SSHNet: Unsupervised Cross-modal Homography Estimation via Problem Reformulation and Split Optimization" | C++ | 22 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_SSHNet_Unsupervised_Cross-modal_Homography_Estimation_via_Problem_Reformulation_and_Split_CVPR_2025_paper.pdf) | |
| USP-Gaussian: Unifying Spike-based Image Reconstruction; Pose Correction and Gaussian Splatting | [code](https://github.com/chenkang455/USP-Gaussian) | [CVPR 2025 Highlight] USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction and Gaussian Splatting | Python | 28 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_USP-Gaussian_Unifying_Spike-based_Image_Reconstruction_Pose_Correction_and_Gaussian_Splatting_CVPR_2025_paper.pdf) | |
| Adventurer: Optimizing Vision Mamba Architecture Designs for Efficiency | [code](https://github.com/wangf3014/Adventurer) |  | Python | 27 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Adventurer_Optimizing_Vision_Mamba_Architecture_Designs_for_Efficiency_CVPR_2025_paper.pdf) | |
| Beyond Local Sharpness: Communication-Efficient Global Sharpness-aware Minimization for Federated Learning | [code](https://github.com/pietrocagnasso/fedgloss) |  | Python | 21 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Caldarola_Beyond_Local_Sharpness_Communication-Efficient_Global_Sharpness-aware_Minimization_for_Federated_Learning_CVPR_2025_paper.pdf) | |
| QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the Edge | [code](https://github.com/shawnricecake/quart-depth) | [CVPR 2025] QuartDepth | Python | 15 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_QuartDepth_Post-Training_Quantization_for_Real-Time_Depth_Estimation_on_the_Edge_CVPR_2025_paper.pdf) | |
| Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single Panoramic Image for Your Immerse Exploration | [code](https://github.com/LongHZ140516/Scene4U) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Scene4U_Hierarchical_Layered_3D_Scene_Reconstruction_from_Single_Panoramic_Image_CVPR_2025_paper.pdf) | |
| ACAttack: Adaptive Cross Attacking RGB-T Tracker via Multi-Modal Response Decoupling | [code](https://github.com/Xinyu-Xiang/ACAttack) | ACAttack: Adaptive Cross Attacking RGB-T Tracker via Multi-Modal Response Decoupling |  | 5 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiang_ACAttack_Adaptive_Cross_Attacking_RGB-T_Tracker_via_Multi-Modal_Response_Decoupling_CVPR_2025_paper.pdf) | |
| DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos | [code](https://github.com/ZijiaLewisLu/CVPR2025-DeCafNet) | Official Repo for CVPR 2025 Paper -- DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos | Python | 15 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_DeCafNet_Delegate_and_Conquer_for_Efficient_Temporal_Grounding_in_Long_CVPR_2025_paper.pdf) | |
| Subspace Constraint and Contribution Estimation for Heterogeneous Federated Learning | [code](https://github.com/AVC2-UESTC/FedSCE.git) | [CVPR2025] Implementation of â€œSubspace Constraint and Contribution Estimation for Heterogeneous Federated Learningâ€ | Python | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Subspace_Constraint_and_Contribution_Estimation_for_Heterogeneous_Federated_Learning_CVPR_2025_paper.pdf) | |
| ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices | [code](https://github.com/Longin-Yu/ComRoPE) |  | Python | 12 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_ComRoPE_Scalable_and_Robust_Rotary_Position_Embedding_Parameterized_by_Trainable_CVPR_2025_paper.pdf) | |
| SceneTAP: Scene-Coherent Typographic Adversarial Planner against Vision-Language Models in Real-World Environments | [code](https://github.com/tsingqguo/scenetap) |  | Python | 13 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_SceneTAP_Scene-Coherent_Typographic_Adversarial_Planner_against_Vision-Language_Models_in_Real-World_CVPR_2025_paper.pdf) | |
| Collaborative Decoding Makes Visual Auto-Regressive Modeling Efficient | [code](https://github.com/czg1225/CoDe) | [CVPR 2025] CoDe: Collaborative Decoding Makes Visual Auto-Regressive Modeling Efficient | Python | 108 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Collaborative_Decoding_Makes_Visual_Auto-Regressive_Modeling_Efficient_CVPR_2025_paper.pdf) | |
| Towards Training-free Anomaly Detection with Vision and Language Foundation Models | [code](https://github.com/zhang0jhon/LogSAD) | [CVPR 2025] Towards Training-free Anomaly Detection with Vision and Language Foundation Models | Python | 79 | 11 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Towards_Training-free_Anomaly_Detection_with_Vision_and_Language_Foundation_Models_CVPR_2025_paper.pdf) | |
| LiVOS: Light Video Object Segmentation with Gated Linear Matching | [code](https://github.com/uncbiag/LiVOS) | LiVOS: Light Video Object Segmentation with Gated Linear Matching (CVPR 2025) | Python | 44 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_LiVOS_Light_Video_Object_Segmentation_with_Gated_Linear_Matching_CVPR_2025_paper.pdf) | |
| Exploring Sparse MoE in GANs for Text-conditioned Image Synthesis | [code](https://github.com/zhujiapeng/Aurora) | Official implementation of Aurora | Python | 85 | 3 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Exploring_Sparse_MoE_in_GANs_for_Text-conditioned_Image_Synthesis_CVPR_2025_paper.pdf) | |
| Bayesian Prompt Flow Learning for Zero-Shot Anomaly Detection | [code](https://github.com/xiaozhen228/Bayes-PFL) | (CVPR2025) the code of "Bayesian Prompt Flow Learning for Zero-Shot Anomaly Detection" | Python | 56 | 9 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_Bayesian_Prompt_Flow_Learning_for_Zero-Shot_Anomaly_Detection_CVPR_2025_paper.pdf) | |
| Post-pre-training for Modality Alignment in Vision-Language Foundation Models | [code](https://github.com/yshinya6/clip-refine) | Code repository for "Post-pre-training for Modality Alignment in Vision-Language Foundation Models" (CVPR2025) | Python | 37 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yamaguchi_Post-pre-training_for_Modality_Alignment_in_Vision-Language_Foundation_Models_CVPR_2025_paper.pdf) | |
| Pseudo Visible Feature Fine-Grained Fusion for Thermal Object Detection | [code](https://github.com/liting1018/PFGF) | [CVPR' 25] Official implementation of the paper "Pseudo Visible Feature Fine-Grained Fusion for Thermal Object Detection" | Python | 19 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Pseudo_Visible_Feature_Fine-Grained_Fusion_for_Thermal_Object_Detection_CVPR_2025_paper.pdf) | |
| HUNet: Homotopy Unfolding Network for Image Compressive Sensing | [code](https://github.com/ICSResearch/HUNet) |  | Python | 9 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_HUNet_Homotopy_Unfolding_Network_for_Image_Compressive_Sensing_CVPR_2025_paper.pdf) | |
| HalLoc: Token-level Localization of Hallucinations for Vision Language Models | [code](https://github.com/dbsltm/cvpr25_halloc) |  | Python | 1 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Park_HalLoc_Token-level_Localization_of_Hallucinations_for_Vision_Language_Models_CVPR_2025_paper.pdf) | |
| DiffPortrait360: Consistent Portrait Diffusion for 360 View Synthesis | [code](https://github.com/FreedomGu/DiffPortrait360/) | Official Repository of [CVPR'25 Paper Diffportrait360: Consistent portrait diffusion for 360 view synthesis | Python | 106 | 6 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_DiffPortrait360_Consistent_Portrait_Diffusion_for_360_View_Synthesis_CVPR_2025_paper.pdf) | |
| SemiETS: Integrating Spatial and Content Consistencies for Semi-Supervised End-to-end Text Spotting | [code](https://github.com/DrLuo/SemiETS) | ã€CVPR 2025ã€‘SemiETS: Integrating Spatial and Content Consistencies for Semi-Supervised End-to-end Text Spotting | Python | 15 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_SemiETS_Integrating_Spatial_and_Content_Consistencies_for_Semi-Supervised_End-to-end_Text_CVPR_2025_paper.pdf) | |
| PassionSR: Post-Training Quantization with Adaptive Scale in One-Step Diffusion based Image Super-Resolution | [code](https://github.com/libozhu03/PassionSR) |  | Python | 54 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_PassionSR_Post-Training_Quantization_with_Adaptive_Scale_in_One-Step_Diffusion_based_CVPR_2025_paper.pdf) | |
| Noise Diffusion for Enhancing Semantic Faithfulness in Text-to-Image Synthesis | [code](https://github.com/Bomingmiao/NoiseDiffusion) | [CVPR 2025] Noise Diffusion for Enhancing Semantic Faithfulness in Text-to-Image Synthesis | Python | 13 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Miao_Noise_Diffusion_for_Enhancing_Semantic_Faithfulness_in_Text-to-Image_Synthesis_CVPR_2025_paper.pdf) | |
| Three-view Focal Length Recovery From Homographies | [code](https://github.com/kocurvik/hf) | [CVPR 2025] Three-view Focal Length Recovery From Homographies | Python | 8 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ding_Three-view_Focal_Length_Recovery_From_Homographies_CVPR_2025_paper.pdf) | |
| NoPain: No-box Point Cloud Attack via Optimal Transport Singular Boundary | [code](https://github.com/cognaclee/nopain) |  | Python | 6 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_NoPain_No-box_Point_Cloud_Attack_via_Optimal_Transport_Singular_Boundary_CVPR_2025_paper.pdf) | |
| RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models | [code](https://github.com/Hoar012/RAP-MLLM) | [CVPR 2025] RAP: Retrieval-Augmented Personalization | Python | 78 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hao_RAP_Retrieval-Augmented_Personalization_for_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf) | |
| Exploring Semantic Feature Discrimination for Perceptual Image Super-Resolution and Opinion-Unaware No-Reference Image Quality Assessment | [code](https://github.com/GuangluDong0728/SFD) |  | Python | 24 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Exploring_Semantic_Feature_Discrimination_for_Perceptual_Image_Super-Resolution_and_Opinion-Unaware_CVPR_2025_paper.pdf) | |
| Distilling Long-tailed Datasets | [code](https://github.com/ichbill/LTDD) | Official Implementation of paper "Distilling Long-tailed Datasets" [CVPR 2025] | Python | 17 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Distilling_Long-tailed_Datasets_CVPR_2025_paper.pdf) | |
| Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders | [code](http://github.com/fkryan/gazelle) | Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders (CVPR 2025, Highlight) | Python | 809 | 93 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ryan_Gaze-LLE_Gaze_Target_Estimation_via_Large-Scale_Learned_Encoders_CVPR_2025_paper.pdf) | |
| LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models | [code](https://github.com/iSEE-Laboratory/LLMDet) | (CVPR 2025 highlightâœ¨) Official repository of paper "LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models" | Python | 533 | 30 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_LLMDet_Learning_Strong_Open-Vocabulary_Object_Detectors_under_the_Supervision_of_CVPR_2025_paper.pdf) | |
| WeGen: A Unified Model for Interactive Multimodal Generation as We Chat | [code](https://github.com/hzphzp/WeGen) |  | Python | 27 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_WeGen_A_Unified_Model_for_Interactive_Multimodal_Generation_as_We_CVPR_2025_paper.pdf) | |
| HeMoRa: Unsupervised Heuristic Consensus Sampling for Robust Point Cloud Registration | [code](https://github.com/Laka-3DV/HeMoRa) | [CVPR-2025] HeMoRa: Unsupervised Heuristic Consensus Sampling for Robust Point Cloud Registration |  | 11 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.pdf) | |
| Boosting Adversarial Transferability through Augmentation in Hypothesis Space | [code](https://github.com/the-full/OPS) | [CVPR 2025] Boosting Adversarial Transferability through Augmentation in Hypothesis Space | Python | 10 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Boosting_Adversarial_Transferability_through_Augmentation_in_Hypothesis_Space_CVPR_2025_paper.pdf) | |
| Instance-wise Supervision-level Optimization in Active Learning | [code](https://github.com/matsuo-shinnosuke/ISOAL) | Instance-wise Supervision-level Optimization in Active Learning in CVPR2025 | Python | 6 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Matsuo_Instance-wise_Supervision-level_Optimization_in_Active_Learning_CVPR_2025_paper.pdf) | |
| BHViT: Binarized Hybrid Vision Transformer | [code](https://github.com/IMRL/BHViT) |  | Python | 44 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_BHViT_Binarized_Hybrid_Vision_Transformer_CVPR_2025_paper.pdf) | |
| A Distractor-Aware Memory for Visual Object Tracking with SAM2 | [code](https://github.com/jovanavidenovic/DAM4SAM) | [CVPR 2025] "A Distractor-Aware Memory for Visual Object Tracking with SAM2" | Python | 450 | 37 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Videnovic_A_Distractor-Aware_Memory_for_Visual_Object_Tracking_with_SAM2_CVPR_2025_paper.pdf) | |
| Activating Sparse Part Concepts for 3D Class Incremental Learning | [code](https://github.com/zhenyatian/ILPC) |  |  | 1 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Activating_Sparse_Part_Concepts_for_3D_Class_Incremental_Learning_CVPR_2025_paper.pdf) | |
| BFANet: Revisiting 3D Semantic Segmentation with Boundary Feature Analysis | [code](https://github.com/weiguangzhao/BFANet) | [CVPR2025] BFANet: Revisiting 3D Semantic Segmentation with Boundary Feature Analysis | Python | 36 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_BFANet_Revisiting_3D_Semantic_Segmentation_with_Boundary_Feature_Analysis_CVPR_2025_paper.pdf) | |
| Unlocking the Potential of Unlabeled Data in Semi-Supervised Domain Generalization | [code](https://github.com/dongkwani/UPCSC) | The official implementation of "Unlocking the Potential of Unlabeled Data in Semi-Supervised Domain Generalization" (CVPR 2025) | Python | 14 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Unlocking_the_Potential_of_Unlabeled_Data_in_Semi-Supervised_Domain_Generalization_CVPR_2025_paper.pdf) | |
| Steering Away from Harm: An Adaptive Approach to Defending Vision Language Model Against Jailbreaks | [code](https://github.com/ASTRAL-Group/ASTRA) | [CVPR 2025] Official implementation for "Steering Away from Harm: An Adaptive Approach to Defending Vision Language Model Against Jailbreaks" | Python | 47 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Steering_Away_from_Harm_An_Adaptive_Approach_to_Defending_Vision_CVPR_2025_paper.pdf) | |
| VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling | [code](https://github.com/ZeyueT/VidMuse/) |  | Python | 113 | 6 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_VidMuse_A_Simple_Video-to-Music_Generation_Framework_with_Long-Short-Term_Modeling_CVPR_2025_paper.pdf) | |
| Exposure-slot: Exposure-centric Representations Learning with Slot-in-Slot Attention for Region-aware Exposure Correction | [code](https://github.com/kdhRick2222/Exposure-slot) |  Exposure-slot: Exposure-centric representations learning with Slot-in-Slot Attention for Region-aware Exposure Correction, Computer Vision and Pattern Recognition (CVPR), 2025. | Python | 21 | 2 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Exposure-slot_Exposure-centric_Representations_Learning_with_Slot-in-Slot_Attention_for_Region-aware_Exposure_CVPR_2025_paper.pdf) | |
| Task-Aware Clustering for Prompting Vision-Language Models | [code](https://github.com/FushengHao/TAC) | Code for "Task-Aware Clustering for Prompting Vision-Language Models" in CVPR 2025. | Python | 12 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hao_Task-Aware_Clustering_for_Prompting_Vision-Language_Models_CVPR_2025_paper.pdf) | |
| STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification | [code](https://github.com/siyi-wind/STiL) | [CVPR 2025] STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification (an official implementation) | Python | 34 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Du_STiL_Semi-supervised_Tabular-Image_Learning_for_Comprehensive_Task-Relevant_Information_Exploration_in_CVPR_2025_paper.pdf) | |
| Advancing Manga Analysis: Comprehensive Segmentation Annotations for the Manga109 Dataset | [code](https://huggingface.co/datasets/MS92/MangaSegmentation) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Advancing_Manga_Analysis_Comprehensive_Segmentation_Annotations_for_the_Manga109_Dataset_CVPR_2025_paper.pdf) | |
| MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors | [code](https://github.com/PuFanqi23/MonoDGP) | [CVPR 2025] The offical implementation of 'MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors' | Python | 71 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Pu_MonoDGP_Monocular_3D_Object_Detection_with_Decoupled-Query_and_Geometry-Error_Priors_CVPR_2025_paper.pdf) | |
| Chebyshev Attention Depth Permutation Texture Network with Latent Texture Attribute Loss | [code](https://github.com/RavishankarEvani/CAPTN) | [CVPR 2025] Official implementation of Chebyshev Attention Depth Permutation Texture Network with Latent Texture Attribute Loss | Python | 13 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Evani_Chebyshev_Attention_Depth_Permutation_Texture_Network_with_Latent_Texture_Attribute_CVPR_2025_paper.pdf) | |
| Correcting Deviations from Normality: A Reformulated Diffusion Model for Multi-Class Unsupervised Anomaly Detection | [code](https://github.com/farzad-bz/DeCo-Diff) | This Repository contain the PyTorch implementation of the multi-class unsupervised anomaly detection method, accepted in CVPR2025: "Correcting Deviations from Normality: A Reformulated Diffusion Model for Unsupervised Anomaly Detection." | Python | 54 | 5 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Beizaee_Correcting_Deviations_from_Normality_A_Reformulated_Diffusion_Model_for_Multi-Class_CVPR_2025_paper.pdf) | |
| LP-Diff: Towards Improved Restoration of Real-World Degraded License Plate | [code](https://github.com/haoyGONG/LP-Diff) | Code of paper "LP-Diff: Towards Improved Restoration of Real-World Degraded License Plate" | Python | 14 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Gong_LP-Diff_Towards_Improved_Restoration_of_Real-World_Degraded_License_Plate_CVPR_2025_paper.pdf) | |
| Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation | [code](https://github.com/liyih/CSCL) | [CVPR 2025] Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation | Python | 25 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Unleashing_the_Potential_of_Consistency_Learning_for_Detecting_and_Grounding_CVPR_2025_paper.pdf) | |
| Structure-from-Motion with a Non-Parametric Camera Model | [code](https://github.com/Ivonne320/GenSfM.git) |  | C | 70 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Structure-from-Motion_with_a_Non-Parametric_Camera_Model_CVPR_2025_paper.pdf) | |
| TreeMeshGPT: Artistic Mesh Generation with Autoregressive Tree Sequencing | [code](https://github.com/sail-sg/TreeMeshGPT) | [CVPR 2025] TreeMeshGPT: Artistic Mesh Generation with Autoregressive Tree Sequencing | Python | 177 | 12 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lionar_TreeMeshGPT_Artistic_Mesh_Generation_with_Autoregressive_Tree_Sequencing_CVPR_2025_paper.pdf) | |
| Relation3D : Enhancing Relation Modeling for Point Cloud Instance Segmentation | [code](https://github.com/Howard-coder191/Relation3D) | [CVPR 2025] Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation | Python | 36 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Relation3D__Enhancing_Relation_Modeling_for_Point_Cloud_Instance_Segmentation_CVPR_2025_paper.pdf) | |
| Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging | [code](https://github.com/ZhangLab-DeepNeuroCogLab/visual-forager) | Official code for "Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging" (CVPR2025) | Python | 9 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Gazing_at_Rewards_Eye_Movements_as_a_Lens_into_Human_CVPR_2025_paper.pdf) | |
| FOCUS: Knowledge-enhanced Adaptive Visual Compression for Few-shot Whole Slide Image Classification | [code](https://github.com/dddavid4real/FOCUS) | [CVPR 2025] Official Repo of Paper "FOCUS: Knowledge-enhanced Adaptive Visual Compression for Few-shot Whole Slide Image Classification" | Python | 33 | 5 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_FOCUS_Knowledge-enhanced_Adaptive_Visual_Compression_for_Few-shot_Whole_Slide_Image_CVPR_2025_paper.pdf) | |
| Beyond Human Perception: Understanding Multi-Object World from Monocular View | [code](https://github.com/JasonHuang516/MonoMulti-3DVG) | [CVPR 2025] The offical implementation of 'Beyond Human Perception: Understanding Multi-Object World from Monocular View' | Python | 3 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Beyond_Human_Perception_Understanding_Multi-Object_World_from_Monocular_View_CVPR_2025_paper.pdf) | |
| Automatic Joint Structured Pruning and Quantization for Efficient Neural Network Training and Compression | [code](https://github.com/microsoft/GETA) | [CVPR 2025] Official repository for GETA | Python | 39 | 6 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_Automatic_Joint_Structured_Pruning_and_Quantization_for_Efficient_Neural_Network_CVPR_2025_paper.pdf) | |
| Latent Space Super-Resolution for Higher-Resolution Image Generation with Diffusion Models | [code](https://github.com/3587jjh/LSRNA) | Latent Space Super-Resolution for Higher-Resolution Image Generation with Diffusion Models (CVPR 2025) | Python | 42 | 0 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_Latent_Space_Super-Resolution_for_Higher-Resolution_Image_Generation_with_Diffusion_Models_CVPR_2025_paper.pdf) | |
| DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation | [code](https://github.com/VCIP-RGBD/DFormer) | [CVPR 2025] DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation & [ICLR 2024] DFormer & [NeuriPS 2025] OmniSegmentor | Python | 429 | 50 | 11 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_DFormerv2_Geometry_Self-Attention_for_RGBD_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| Sea-ing in Low-light | [code](https://github.com/nishavarghese15/ULVStereo) | Dataset proposed in "Sea-ing in Low-light", CVPR 2025 |  | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Varghese_Sea-ing_in_Low-light_CVPR_2025_paper.pdf) | |
| VidTwin: Video VAE with Decoupled Structure and Dynamics | [code](https://github.com/microsoft/VidTok/tree/main/vidtwin) | a family of versatile and state-of-the-art video tokenizers. | Python | 429 | 20 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VidTwin_Video_VAE_with_Decoupled_Structure_and_Dynamics_CVPR_2025_paper.pdf) | |
| VisionZip: Longer is Better but Not Necessary in Vision Language Models | [code](https://github.com/dvlab-research/VisionZip) | Official repository for VisionZip (CVPR 2025) | Python | 396 | 17 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_VisionZip_Longer_is_Better_but_Not_Necessary_in_Vision_Language_CVPR_2025_paper.pdf) | |
| VoteFlow: Enforcing Local Rigidity in Self-Supervised Scene Flow | [code](https://github.com/tudelft-iv/VoteFlow) | [CVPR'25] VoteFlow: Enforcing Local Rigidity in Self-Supervised Scene Flow | Jupyter Notebook | 15 | 4 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_VoteFlow_Enforcing_Local_Rigidity_in_Self-Supervised_Scene_Flow_CVPR_2025_paper.pdf) | |
| Balancing Two Classifiers via A Simplex ETF Structure for Model Calibration | [code](https://github.com/JianiNi/BalCAL) |  | Python | 1 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ni_Balancing_Two_Classifiers_via_A_Simplex_ETF_Structure_for_Model_CVPR_2025_paper.pdf) | |
| Unveiling Differences in Generative Models: A Scalable Differential Clustering Approach | [code](https://github.com/buyeah1109/FINC) | Official code repository of paper: "Identification of Novel Modes in Generative Models via Fourier-based Differential Clustering" | Python | 1 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Unveiling_Differences_in_Generative_Models_A_Scalable_Differential_Clustering_Approach_CVPR_2025_paper.pdf) | |
| Semantic Library Adaptation: LoRA Retrieval and Fusion for Open-Vocabulary Semantic Segmentation | [code](https://github.com/rezaqorbani/SemLA) | [CVPR'25] Official implementation of "Semantic Library Adaptation: LoRA Retrieval and Fusion for Open-Vocabulary Semantic Segmentation" | Python | 42 | 8 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qorbani_Semantic_Library_Adaptation_LoRA_Retrieval_and_Fusion_for_Open-Vocabulary_Semantic_CVPR_2025_paper.pdf) | |
| Point Cloud Upsampling Using Conditional Diffusion Module with Adaptive Noise Suppression | [code](https://github.com/Baty2023/PDANS) |  | Python | 11 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Point_Cloud_Upsampling_Using_Conditional_Diffusion_Module_with_Adaptive_Noise_CVPR_2025_paper.pdf) | |
| Recover and Match: Open-Vocabulary Multi-Label Recognition through Knowledge-Constrained Optimal Transport | [code](https://github.com/EricTan7/RAM) | [CVPR2025] Official implementation of RAM | Python | 25 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_Recover_and_Match_Open-Vocabulary_Multi-Label_Recognition_through_Knowledge-Constrained_Optimal_Transport_CVPR_2025_paper.pdf) | |
| DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in Fine-Grained Visual Understanding | [code](https://github.com/PKU-ICST-MIPL/DyFo_CVPR2025) |  | Python | 101 | 3 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DyFo_A_Training-Free_Dynamic_Focus_Visual_Search_for_Enhancing_LMMs_CVPR_2025_paper.pdf) | |
| DEIM: DETR with Improved Matching for Fast Convergence | [code](https://github.com/ShihuaHuang95/DEIM) | [CVPR 2025] DEIM: DETR with Improved Matching for Fast Convergence | Python | 1395 | 177 | 18 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_DEIM_DETR_with_Improved_Matching_for_Fast_Convergence_CVPR_2025_paper.pdf) | |
| BF-STVSR: B-Splines and Fourier---Best Friends for High Fidelity Spatial-Temporal Video Super-Resolution | [code](https://github.com/Eunjnnn/bfstvsr) | [CVPR 2025] BF-STVSR: B-Splines and Fourier-Best Friends for High Fidelity Spatial-Temporal Video Super-Resolution | Python | 46 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_BF-STVSR_B-Splines_and_Fourier---Best_Friends_for_High_Fidelity_Spatial-Temporal_Video_CVPR_2025_paper.pdf) | |
| Human Motion Instruction Tuning | [code](https://github.com/ILGLJ/LLaMo) |  |  | 5 | 0 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Human_Motion_Instruction_Tuning_CVPR_2025_paper.pdf) | |
| RCP-Bench: Benchmarking Robustness for Collaborative Perception Under Diverse Corruptions | [code](https://github.com/LuckyDush/RCP-Bench) | [CVPR-2025]RCP-Bench: Benchmarking Robustness for Collaborative Perception  Under Diverse Corruptions | Python | 7 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Du_RCP-Bench_Benchmarking_Robustness_for_Collaborative_Perception_Under_Diverse_Corruptions_CVPR_2025_paper.pdf) | |
| Image Over Text: Transforming Formula Recognition Evaluation with Character Detection Matching | [code](https://github.com/opendatalab/UniMERNet/tree/main/cdm) | UniMERNet: A Universal Network for Real-World Mathematical Expression Recognition | Python | 447 | 38 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Image_Over_Text_Transforming_Formula_Recognition_Evaluation_with_Character_Detection_CVPR_2025_paper.pdf) | |
| FreePCA: Integrating Consistency Information across Long-short Frames in Training-free Long Video Generation via Principal Component Analysis | [code](https://github.com/JosephTiTan/FreePCA) | Code of the paper "FreePCAï¼šIntegrating Consistency Information across Long-short Frames in Training-free Long Video Generation via Principal Component Analysis", accepted by CVPR 2025 (highlight). | Python | 28 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_FreePCA_Integrating_Consistency_Information_across_Long-short_Frames_in_Training-free_Long_CVPR_2025_paper.pdf) | |
| Automatic Spectral Calibration of Hyperspectral Images: Method; Dataset and Benchmark | [code](https://github.com/duranze/Automatic-spectral-calibration-of-HSI) |  | Python | 18 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Du_Automatic_Spectral_Calibration_of_Hyperspectral_Images_Method_Dataset_and_Benchmark_CVPR_2025_paper.pdf) | |
| Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting | [code](https://github.com/Elin24/P2RLoss) | CVPR-2025 paper "Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting" | Python | 8 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Point-to-Region_Loss_for_Semi-Supervised_Point-Based_Crowd_Counting_CVPR_2025_paper.pdf) | |
| PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation | [code](https://github.com/uyoung-jeong/PoseBH) | PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation | Python | 20 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_PoseBH_Prototypical_Multi-Dataset_Training_Beyond_Human_Pose_Estimation_CVPR_2025_paper.pdf) | |
| MATCHA: Towards Matching Anything | [code](https://github.com/feixue94/matcha) | [CVPR 2025 Highlight] MATCHA: Towards Matching Anything.  |  | 79 | 1 | 12 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_MATCHA_Towards_Matching_Anything_CVPR_2025_paper.pdf) | |
| Fitted Neural Lossless Image Compression | [code](https://github.com/ZZ022/FNLIC) | PyTorch Implementation of the CVPR'25 Paper "Fitted Neural Lossless Image Compression" | C | 14 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Fitted_Neural_Lossless_Image_Compression_CVPR_2025_paper.pdf) | |
| UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting | [code](https://github.com/wangzy22/UniPre3D) | [CVPR 2025] UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting | Python | 49 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_UniPre3D_Unified_Pre-training_of_3D_Point_Cloud_Models_with_Cross-Modal_CVPR_2025_paper.pdf) | |
| Charm: The Missing Piece in ViT Fine-Tuning for Image Aesthetic Assessment | [code](https://github.com/FBehrad/Charm) | The official PyTorch Implementation of Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment | Python | 41 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Behrad_Charm_The_Missing_Piece_in_ViT_Fine-Tuning_for_Image_Aesthetic_CVPR_2025_paper.pdf) | |
| F-LMM: Grounding Frozen Large Multimodal Models | [code](https://github.com/wusize/F-LMM) | [CVPR2025] Code Release of F-LMM: Grounding Frozen Large Multimodal Models | Python | 109 | 1 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_F-LMM_Grounding_Frozen_Large_Multimodal_Models_CVPR_2025_paper.pdf) | |
| Finding Local Diffusion Schrodinger Bridge using Kolmogorov-Arnold Network | [code](https://github.com/PerceptionComputingLab/LDSB) | [CVPR 2025] Pytorch Implementation of the Paper "Finding Local Diffusion Schr\"odinger Bridge using Kolmogorov-Arnold Network" | Python | 2 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_Finding_Local_Diffusion_Schrodinger_Bridge_using_Kolmogorov-Arnold_Network_CVPR_2025_paper.pdf) | |
| Linear Attention Modeling for Learned Image Compression | [code](https://github.com/sjtu-medialab/RwkvCompress) |  | Python | 55 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Linear_Attention_Modeling_for_Learned_Image_Compression_CVPR_2025_paper.pdf) | |
| Asynchronous Collaborative Graph Representation for Frames and Events | [code](https://github.com/dianzl/ACGR) | Official implementation of paper: Asynchronous Collaborative Graph Representation for Frames and Events |  | 2 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Asynchronous_Collaborative_Graph_Representation_for_Frames_and_Events_CVPR_2025_paper.pdf) | |
| Real-time High-fidelity Gaussian Human Avatars with Position-based Interpolation of Spatially Distributed MLPs | [code](https://github.com/1231234zhan/mmlphuman) | [CVPR 2025 Highlight] Real-time High-fidelity Gaussian Human Avatars with Position-based Interpolation of Spatially Distributed MLPs | Python | 64 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhan_Real-time_High-fidelity_Gaussian_Human_Avatars_with_Position-based_Interpolation_of_Spatially_CVPR_2025_paper.pdf) | |
| DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception | [code](https://github.com/xiaomoguhz/DeCLIP) | [CVPR 2025] DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception | Python | 148 | 5 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DeCLIP_Decoupled_Learning_for_Open-Vocabulary_Dense_Perception_CVPR_2025_paper.pdf) | |
| SocialGesture: Delving into Multi-person Gesture Understanding | [code](http://huggingface.co/datasets/IrohXu/SocialGesture) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_SocialGesture_Delving_into_Multi-person_Gesture_Understanding_CVPR_2025_paper.pdf) | |
| Question-Aware Gaussian Experts for Audio-Visual Question Answering | [code](https://github.com/AIM-SKKU/QA-TIGER) | Question-Aware Gaussian Experts for Audio-Visual Question Answering -- Official Pytorch Implementation (CVPR'25, Highlight) | Python | 25 | 6 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Question-Aware_Gaussian_Experts_for_Audio-Visual_Question_Answering_CVPR_2025_paper.pdf) | |
| Adaptive Rectangular Convolution for Remote Sensing Pansharpening | [code](https://github.com/WangXueyang-uestc/ARConv) | Official repo for Adaptive Rectangular Convolution | Jupyter Notebook | 162 | 7 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Adaptive_Rectangular_Convolution_for_Remote_Sensing_Pansharpening_CVPR_2025_paper.pdf) | |
| PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning | [code](https://github.com/songw-zju/PointLoRA) | The official implementation of "PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning" (CVPR 2025) | Python | 28 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_PointLoRA_Low-Rank_Adaptation_with_Token_Selection_for_Point_Cloud_Learning_CVPR_2025_paper.pdf) | |
| HumanRig: Learning Automatic Rigging for Humanoid Character in a Large Scale Dataset | [code](https://github.com/c8241998/HumanRig) | Official implementation of "HumanRig: Learning Automatic Rigging for Humanoid Character in a Large Scale Dataset" |  | 91 | 1 | 21 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chu_HumanRig_Learning_Automatic_Rigging_for_Humanoid_Character_in_a_Large_CVPR_2025_paper.pdf) | |
| Harnessing Frozen Unimodal Encoders for Flexible Multimodal Alignment | [code](http://github.com/mayug/freeze-align) | Code and datasets for CVPR 2025 accepted paper Harnessing Frozen Unimodal Encoders for Flexible Multimodal Alignment | Python | 9 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Maniparambil_Harnessing_Frozen_Unimodal_Encoders_for_Flexible_Multimodal_Alignment_CVPR_2025_paper.pdf) | |
| Revisiting Generative Replay for Class Incremental Object Detection | [code](https://github.com/qiangzai-lv/RGR-IOD) | Official PyTorch implementation of our CVPR 2025 paper, "Revisiting Generative Replay for Class Incremental Object Detection." | Python | 22 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Revisiting_Generative_Replay_for_Class_Incremental_Object_Detection_CVPR_2025_paper.pdf) | |
| From Alexnet to Transformers: Measuring the Non-linearity of Deep Neural Networks with Affine Optimal Transport | [code](https://github.com/qbouniot/AffScoreDeep) | [CVPR 2025] From Alexnet to Transformers: Measuring the Non-linearity of Deep Neural Networks with Affine Optimal Transport | Jupyter Notebook | 10 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Bouniot_From_Alexnet_to_Transformers_Measuring_the_Non-linearity_of_Deep_Neural_CVPR_2025_paper.pdf) | |
| Prompt2Perturb (P2P): Text-Guided Diffusion-Based Adversarial Attack on Breast Ultrasound Images | [code](https://github.com/yasamin-med/P2P) |  | Python | 22 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Medghalchi_Prompt2Perturb_P2P_Text-Guided_Diffusion-Based_Adversarial_Attack_on_Breast_Ultrasound_Images_CVPR_2025_paper.pdf) | |
| Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need | [code](https://github.com/qwangcv/SOYO) | [CVPR 2025] Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need | Python | 7 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Boosting_Domain_Incremental_Learning_Selecting_the_Optimal_Parameters_is_All_CVPR_2025_paper.pdf) | |
| FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs | [code](https://github.com/CVI-SZU/FaceBench) | [CVPR 2025] FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs | Python | 42 | 0 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_FaceBench_A_Multi-View_Multi-Level_Facial_Attribute_VQA_Dataset_for_Benchmarking_CVPR_2025_paper.pdf) | |
| EffiDec3D: An Optimized Decoder for High-Performance and Efficient 3D Medical Image Segmentation | [code](https://github.com/SLDGroup/EffiDec3D) | Official Repository of EffiDec3D-CVPR2025 paper | Python | 33 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Rahman_EffiDec3D_An_Optimized_Decoder_for_High-Performance_and_Efficient_3D_Medical_CVPR_2025_paper.pdf) | |
| VerbDiff: Text-Only Diffusion Models with Enhanced Interaction Awareness | [code](https://github.com/SeungJuCha/VerbDiff.git) |  | Python | 3 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cha_VerbDiff_Text-Only_Diffusion_Models_with_Enhanced_Interaction_Awareness_CVPR_2025_paper.pdf) | |
| Towards In-the-wild 3D Plane Reconstruction from a Single Image | [code](https://github.com/jcliu0428/ZeroPlane) | [CVPR 2025] Towards In-the-wild 3D Plane Reconstruction from a Single Image | Python | 67 | 0 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Towards_In-the-wild_3D_Plane_Reconstruction_from_a_Single_Image_CVPR_2025_paper.pdf) | |
| PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance Prediction | [code](https://github.com/Eduard6421/PQPP) |  | Python | 4 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Poesina_PQPP_A_Joint_Benchmark_for_Text-to-Image_Prompt_and_Query_Performance_CVPR_2025_paper.pdf) | |
| PSBD: Prediction Shift Uncertainty Unlocks Backdoor Detection | [code](https://github.com/WL-619/PSBD) | Official PyTorch Implementation of PSBD: Prediction Shift Uncertainty Unlocks Backdoor Detection (CVPR 2025). | Python | 31 | 6 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_PSBD_Prediction_Shift_Uncertainty_Unlocks_Backdoor_Detection_CVPR_2025_paper.pdf) | |
| Degradation-Aware Feature Perturbation for All-in-One Image Restoration | [code](https://github.com/TxpHome/DFPIR) | all-in-one image restoration | Python | 45 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Degradation-Aware_Feature_Perturbation_for_All-in-One_Image_Restoration_CVPR_2025_paper.pdf) | |
| Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction | [code](https://github.com/GeWu-Lab/Motion-based-Self-Reflection-Framework) |  | Python | 13 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Phoenix_A_Motion-based_Self-Reflection_Framework_for_Fine-grained_Robotic_Action_Correction_CVPR_2025_paper.pdf) | |
| Detect Any Mirrors: Boosting Learning Reliability on Large-Scale Unlabeled Data with an Iterative Data Engine | [code](https://github.com/ge-xing/DAM) |  | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_Detect_Any_Mirrors_Boosting_Learning_Reliability_on_Large-Scale_Unlabeled_Data_CVPR_2025_paper.pdf) | |
| Efficient Visual State Space Model for Image Deblurring | [code](https://github.com/kkkls/EVSSM) | [CVPR 2025] Efficient Visual State Space Model for Image Deblurring;  1st place on AIM 2025 challenge on High FPS Motion Deblurring: | Python | 117 | 12 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kong_Efficient_Visual_State_Space_Model_for_Image_Deblurring_CVPR_2025_paper.pdf) | |
| Detecting Out-of-Distribution Through the Lens of Neural Collapse | [code](https://github.com/litianliu/NCI-OOD) | Detecting Out-of-Distribution through the Lens of Neural Collapse (CVPR 2025) | Python | 6 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Detecting_Out-of-Distribution_Through_the_Lens_of_Neural_Collapse_CVPR_2025_paper.pdf) | |
| Sparse2DGS: Geometry-Prioritized Gaussian Splatting for Surface Reconstruction from Sparse Views | [code](https://github.com/Wuuu3511/Sparse2DGS) | [CVPR2025] | Python | 58 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Sparse2DGS_Geometry-Prioritized_Gaussian_Splatting_for_Surface_Reconstruction_from_Sparse_Views_CVPR_2025_paper.pdf) | |
| PSA-SSL: Pose and Size-aware Self-Supervised Learning on LiDAR Point Clouds | [code](https://github.com/TRAILab/PSA-SSL) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Nisar_PSA-SSL_Pose_and_Size-aware_Self-Supervised_Learning_on_LiDAR_Point_Clouds_CVPR_2025_paper.pdf) | |
| Towards Practical Real-Time Neural Video Compression | [code](https://github.com/microsoft/DCVC) | Deep Contextual Video Compression | Python | 672 | 104 | 16 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_Towards_Practical_Real-Time_Neural_Video_Compression_CVPR_2025_paper.pdf) | |
| DepthSplat: Connecting Gaussian Splatting and Depth | [code](https://github.com/cvg/depthsplat) | [CVPR'25] DepthSplat: Connecting Gaussian Splatting and Depth | Python | 1119 | 59 | 31 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_DepthSplat_Connecting_Gaussian_Splatting_and_Depth_CVPR_2025_paper.pdf) | |
| FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models | [code](https://github.com/HaokunChen245/FedBiP) | [CVPR 2025] FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models | Python | 10 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_FedBiP_Heterogeneous_One-Shot_Federated_Learning_with_Personalized_Latent_Diffusion_Models_CVPR_2025_paper.pdf) | |
| DiC: Rethinking Conv3x3 Designs in Diffusion Models | [code](https://github.com/YuchuanTian/DiC) | [CVPR 2025] "DiC: Rethinking Conv3x3 Designs in Diffusion Models", a performant & speedy Conv3x3 diffusion model. | Python | 240 | 20 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_DiC_Rethinking_Conv3x3_Designs_in_Diffusion_Models_CVPR_2025_paper.pdf) | |
| MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds | [code](https://github.com/JiahuiLei/MoSca) |  | Python | 334 | 15 | 30 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lei_MoSca_Dynamic_Gaussian_Fusion_from_Casual_Videos_via_4D_Motion_CVPR_2025_paper.pdf) | |
| OmniGen: Unified Image Generation | [code](https://github.com/VectorSpaceLab/OmniGen) | OmniGen: Unified Image Generation. https://arxiv.org/pdf/2409.11340 | Jupyter Notebook | 4299 | 369 | 86 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_OmniGen_Unified_Image_Generation_CVPR_2025_paper.pdf) | |
| Continuous Locomotive Crowd Behavior Generation | [code](https://github.com/InhwanBae/CrowdES) | Official Code for "Continuous Locomotive Crowd Behavior Generation (CVPR 2025)" | Python | 38 | 8 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Bae_Continuous_Locomotive_Crowd_Behavior_Generation_CVPR_2025_paper.pdf) | |
| Implicit Bias Injection Attacks against Text-to-Image Diffusion Models | [code](https://github.com/Hannah1102/IBI-attacks) | Code for CVPR 2025 "Implicit Bias Injection Attacks against Text-to-Image Diffusion Models" | Python | 6 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Implicit_Bias_Injection_Attacks_against_Text-to-Image_Diffusion_Models_CVPR_2025_paper.pdf) | |
| FRESA: Feedforward Reconstruction of Personalized Skinned Avatars from Few Images | [code](https://github.com/rongakowang/FRESA) | [CVPR 2025 Highlight] FRESA: Feedforward Reconstruction of Personalized Skinned Avatars from Few Images |  | 35 | 1 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_FRESA_Feedforward_Reconstruction_of_Personalized_Skinned_Avatars_from_Few_Images_CVPR_2025_paper.pdf) | |
| Advancing Adversarial Robustness in GNeRFs: The IL2-NeRF Attack | [code](https://github.com/The-NRC-SCAR-Group/IL2-NeRF) | The Official Repo for IL2-NeRF \| CVPR 2025 | Python | 4 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_Advancing_Adversarial_Robustness_in_GNeRFs_The_IL2-NeRF_Attack_CVPR_2025_paper.pdf) | |
| DarkIR: Robust Low-Light Image Restoration | [code](https://github.com/cidautai/DarkIR) | CVPR 2025 DarkIR: Robust Low-Light Image Restoration - State of the art low light deblurring. NTIRE 2025 Best Method. [Official PyTorch Implementation] | Python | 276 | 28 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Feijoo_DarkIR_Robust_Low-Light_Image_Restoration_CVPR_2025_paper.pdf) | |
| ASIGN: An Anatomy-aware Spatial Imputation Graphic Network for 3D Spatial Transcriptomics | [code](https://github.com/hrlblab/ASIGN) | Anatomy-aware Spatial Imputation Graphic Network for 3D Spatial Transcriptomics | Python | 18 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_ASIGN_An_Anatomy-aware_Spatial_Imputation_Graphic_Network_for_3D_Spatial_CVPR_2025_paper.pdf) | |
| Rethinking Epistemic and Aleatoric Uncertainty for Active Open-Set Annotation: An Energy-Based Approach | [code](https://github.com/chenchenzong/EAOA) | Official Implementation of CVPR'25 paper "Rethinking Epistemic and Aleatoric Uncertainty for Active Open-Set Annotation: An Energy-Based Approach" | Python | 8 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zong_Rethinking_Epistemic_and_Aleatoric_Uncertainty_for_Active_Open-Set_Annotation_An_CVPR_2025_paper.pdf) | |
| ROS-SAM: High-Quality Interactive Segmentation for Remote Sensing Moving Object | [code](https://github.com/ShanZard/ROS-SAM) | This is a official  code repository of ROS-SAM | Python | 65 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shan_ROS-SAM_High-Quality_Interactive_Segmentation_for_Remote_Sensing_Moving_Object_CVPR_2025_paper.pdf) | |
| Octopus: Alleviating Hallucination via Dynamic Contrastive Decoding | [code](https://github.com/LijunZhang01/Octopus) |  | Python | 27 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Suo_Octopus_Alleviating_Hallucination_via_Dynamic_Contrastive_Decoding_CVPR_2025_paper.pdf) | |
| Protecting Your Video Content: Disrupting Automated Video-based LLM Annotations | [code](https://github.com/ttthhl/Protecting_Your_Video_Content) |  | Python | 5 | 0 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Protecting_Your_Video_Content_Disrupting_Automated_Video-based_LLM_Annotations_CVPR_2025_paper.pdf) | |
| Image is All You Need to Empower Large-scale Diffusion Models for In-Domain Generation | [code](https://github.com/PRIV-Creation/In-domain-Generation-Diffusion) | The official code of "Image is All You Need to Empower Large-scale Diffusion Models for In-Domain Generation". [CVPR2025] | Python | 20 | 0 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_Image_is_All_You_Need_to_Empower_Large-scale_Diffusion_Models_CVPR_2025_paper.pdf) | |
| DORNet: A Degradation Oriented and Regularized Network for Blind Depth Super-Resolution | [code](https://github.com/yanzq95/DORNet) | Degradation Oriented and Regularized Network for Real-World Depth Super-Resolution (CVPR 2025 Oral) | Python | 27 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DORNet_A_Degradation_Oriented_and_Regularized_Network_for_Blind_Depth_CVPR_2025_paper.pdf) | |
| Fractal Calibration for Long-tailed Object Detection | [code](https://github.com/kostas1515/FRACAL) | [CVPR2025] Fractal calibration for long-tailed object detection  | Python | 6 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Alexandridis_Fractal_Calibration_for_Long-tailed_Object_Detection_CVPR_2025_paper.pdf) | |
| Noise Calibration and Spatial-Frequency Interactive Network for STEM Image Enhancement | [code](https://github.com/HeasonLee/SFIN) | Code and data of CVPR 2025 paper "Noise Calibration and Spatial-Frequency Interactive Network for STEM Image Enhancement" | Python | 9 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Noise_Calibration_and_Spatial-Frequency_Interactive_Network_for_STEM_Image_Enhancement_CVPR_2025_paper.pdf) | |
| FedSPA: Generalizable Federated Graph Learning under Homophily Heterogeneity | [code](https://github.com/OakleyTan/FedSPA) | Code of FedSPA: Generalizable Federated Graph Learning under Homophily Heterogeneity (CVPR 25) | Python | 4 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_FedSPA_Generalizable_Federated_Graph_Learning_under_Homophily_Heterogeneity_CVPR_2025_paper.pdf) | |
| GaussTR: Foundation Model-Aligned Gaussian Transformer for Self-Supervised 3D Spatial Understanding | [code](https://github.com/hustvl/GaussTR) | [CVPR 2025] GaussTR: Foundation Model-Aligned Gaussian Transformer for Self-Supervised 3D Spatial Understanding | Python | 196 | 11 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_GaussTR_Foundation_Model-Aligned_Gaussian_Transformer_for_Self-Supervised_3D_Spatial_Understanding_CVPR_2025_paper.pdf) | |
| Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning | [code](https://github.com/Kexueyi/discover_infant_vis) | Official implementation of `Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning`, CVPR 2025 | Jupyter Notebook | 14 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ke_Discovering_Hidden_Visual_Concepts_Beyond_Linguistic_Input_in_Infant_Learning_CVPR_2025_paper.pdf) | |
| A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening | [code](https://github.com/Jie-1203/ADWM) | [CVPR 2025] A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening | Python | 33 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_A_General_Adaptive_Dual-level_Weighting_Mechanism_for_Remote_Sensing_Pansharpening_CVPR_2025_paper.pdf) | |
| Continuous; Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions | [code](https://github.com/CompVis/attribute-control) | Fine-Grained Subject-Specific Attribute Expression Control in T2I Models | Jupyter Notebook | 134 | 13 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Baumann_Continuous_Subject-Specific_Attribute_Control_in_T2I_Models_by_Identifying_Semantic_CVPR_2025_paper.pdf) | |
| Diffusion Bridge: Leveraging Diffusion Model to Reduce the Modality Gap Between Text and Vision for Zero-Shot Image Captioning | [code](https://github.com/mongeoroo/diffusion-bridge) | Official code of Diffusion -bridge | Python | 11 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Diffusion_Bridge_Leveraging_Diffusion_Model_to_Reduce_the_Modality_Gap_CVPR_2025_paper.pdf) | |
| LeanGaussian: Breaking Pixel or Point Cloud Correspondence in Modeling 3D Gaussians | [code](https://github.com/jwubz123/LeanGaussian) |  |  | 3 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_LeanGaussian_Breaking_Pixel_or_Point_Cloud_Correspondence_in_Modeling_3D_CVPR_2025_paper.pdf) | |
| Modeling Multiple Normal Action Representations for Error Detection in Procedural Tasks | [code](https://github.com/iSEE-Laboratory/AMNAR) | (CVPR 2025) Official implementation of Paper ''Modeling Multiple Normal Action Representations for Error Detection in Procedural Tasks'' | Python | 10 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Modeling_Multiple_Normal_Action_Representations_for_Error_Detection_in_Procedural_CVPR_2025_paper.pdf) | |
| Alias-Free Latent Diffusion Models: Improving Fractional Shift Equivariance of Diffusion Latent Space | [code](https://github.com/SingleZombie/AFLDM) | [CVPR 2025 Oral] Alias-free Latent Diffusion Models (official implementation) | Python | 105 | 4 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Alias-Free_Latent_Diffusion_Models_Improving_Fractional_Shift_Equivariance_of_Diffusion_CVPR_2025_paper.pdf) | |
| KVQ: Boosting Video Quality Assessment via Saliency-guided Local Perception | [code](https://github.com/qyp2000/KVQ) | [CVPR2025] KVQ: Boosting Video Quality Assessment via Saliency-guided Local Perception |  | 23 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_KVQ_Boosting_Video_Quality_Assessment_via_Saliency-guided_Local_Perception_CVPR_2025_paper.pdf) | |
| MambaVision: A Hybrid Mamba-Transformer Vision Backbone | [code](https://github.com/NVlabs/MambaVision) | [CVPR 2025] Official PyTorch Implementation of MambaVision: A Hybrid Mamba-Transformer Vision Backbone | Python | 1980 | 118 | 18 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hatamizadeh_MambaVision_A_Hybrid_Mamba-Transformer_Vision_Backbone_CVPR_2025_paper.pdf) | |
| Learning Flow Fields in Attention for Controllable Person Image Generation | [code](https://github.com/franciszzj/Leffa) | [CVPR 2025] Learning Flow Fields in Attention for Controllable Person Image Generation | Python | 1640 | 183 | 16 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Learning_Flow_Fields_in_Attention_for_Controllable_Person_Image_Generation_CVPR_2025_paper.pdf) | |
| Early-Bird Diffusion: Investigating and Leveraging Timestep-Aware Early-Bird Tickets in Diffusion Models for Efficient Training | [code](https://github.com/GATECH-EIC/Early-Bird-Diffusion) | [CVPR 2025] "Early-Bird Diffusion: Investigating and Leveraging Timestep-Aware Early-Bird Tickets in Diffusion Models for Efficient Training" by Lexington Whalen, Zhenbang Du, Haoran You, Chaojian Li, Sixu Li, and Yingyan (Celine) Lin. | Python | 3 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Whalen_Early-Bird_Diffusion_Investigating_and_Leveraging_Timestep-Aware_Early-Bird_Tickets_in_Diffusion_CVPR_2025_paper.pdf) | |
| MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting | [code](https://github.com/kaka0910/MFogHub) | Data and code release for "MFogHub" (CVPR 2025). | Python | 17 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_MFogHub_Bridging_Multi-Regional_and_Multi-Satellite_Data_for_Global_Marine_Fog_CVPR_2025_paper.pdf) | |
| Making Old Film Great Again: Degradation-aware State Space Model for Old Film Restoration | [code](https://github.com/MaoAYD/MambaOFR) |  | Python | 10 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_Making_Old_Film_Great_Again_Degradation-aware_State_Space_Model_for_CVPR_2025_paper.pdf) | |
| AlphaPre: Amplitude-Phase Disentanglement Model for Precipitation Nowcasting | [code](https://github.com/linkenghong/AlphaPre) | [CVPR 2025] Official implementation of "AlphaPre: Amplitude-Phase Disentanglement Model for Precipitation Nowcasting" | Python | 31 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_AlphaPre_Amplitude-Phase_Disentanglement_Model_for_Precipitation_Nowcasting_CVPR_2025_paper.pdf) | |
| Detection-Friendly Nonuniformity Correction: A Union Framework for Infrared UAV Target Detection | [code](https://github.com/IVPLaboratory/UniCD) | Official repository for the CVPR 2025 paper â€Detection-Friendly Nonuniformity Correction: A Union Framework for Infrared UAV Target Detectionâ€œ |  | 17 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Detection-Friendly_Nonuniformity_Correction_A_Union_Framework_for_Infrared_UAV_Target_CVPR_2025_paper.pdf) | |
| MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion | [code](https://github.com/cvg/mpsfm) | MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion (CVPR 2025) | Python | 470 | 33 | 17 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Pataki_MP-SfM_Monocular_Surface_Priors_for_Robust_Structure-from-Motion_CVPR_2025_paper.pdf) | |
| Volumetrically Consistent 3D Gaussian Rasterization | [code](https://github.com/chinmay0301ucsd/Vol3DGS) | [CVPR 2025 Highlight] Official Code Release Volumetrically Consistent 3D Gaussian Rasterization  | Python | 83 | 7 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Talegaonkar_Volumetrically_Consistent_3D_Gaussian_Rasterization_CVPR_2025_paper.pdf) | |
| CacheQuant: Comprehensively Accelerated Diffusion Models | [code](https://github.com/BienLuky/CacheQuant) | [CVPR 2025] The official implementation of "CacheQuant: Comprehensively Accelerated Diffusion Models" | Python | 41 | 5 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_CacheQuant_Comprehensively_Accelerated_Diffusion_Models_CVPR_2025_paper.pdf) | |
| DiffVsgg: Diffusion-Driven Online Video Scene Graph Generation | [code](https://github.com/kagawa588/DiffVsgg) | This is the official implementation of "DiffVsgg: Diffusion-Driven Online Video Scene Graph Generation" (Accepted at CVPR 2025). |  | 10 | 0 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_DiffVsgg_Diffusion-Driven_Online_Video_Scene_Graph_Generation_CVPR_2025_paper.pdf) | |
| Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection | [code](https://github.com/heboyong/Generalized-Diffusion-Detector) | [CVPR2025] Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection | Python | 26 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/He_Generalized_Diffusion_Detector_Mining_Robust_Features_from_Diffusion_Models_for_CVPR_2025_paper.pdf) | |
| Forming Auxiliary High-confident Instance-level Loss to Promote Learning from Label Proportions | [code](https://github.com/TianhaoMa5/LLP-AHIL) |  | Python | 4 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Forming_Auxiliary_High-confident_Instance-level_Loss_to_Promote_Learning_from_Label_CVPR_2025_paper.pdf) | |
| SMTPD: A New Benchmark for Temporal Prediction of Social Media Popularity | [code](https://github.com/zhuwei321/SMTPD) | We construct a new social media temporal popularity prediction benchmark, namely SMTPD, and suggest a baseline framework for temporal popularity prediction. | Python | 20 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_SMTPD_A_New_Benchmark_for_Temporal_Prediction_of_Social_Media_CVPR_2025_paper.pdf) | |
| Spherical Manifold Guided Diffusion Model for Panoramic Image Generation | [code](https://github.com/chronos123/SMGD) |  | Jupyter Notebook | 8 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Spherical_Manifold_Guided_Diffusion_Model_for_Panoramic_Image_Generation_CVPR_2025_paper.pdf) | |
| Rethinking Query-based Transformer for Continual Image Segmentation | [code](https://github.com/SooLab/SimCIS) | [CVPR2025] Rethinking Query-based Transformer for Continual Image Segmentation | Python | 41 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Rethinking_Query-based_Transformer_for_Continual_Image_Segmentation_CVPR_2025_paper.pdf) | |
| On the Consistency of Video Large Language Models in Temporal Comprehension | [code](https://github.com/minjoong507/Consistency-of-Video-LLM) | [CVPR 2025] Official Repository of the paper "On the Consistency of Video Large Language Models in Temporal Comprehension" | Python | 15 | 0 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_On_the_Consistency_of_Video_Large_Language_Models_in_Temporal_CVPR_2025_paper.pdf) | |
| Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding | [code](https://github.com/GWxuan/TSP3D) | [CVPR 2025, All Strong Accept] TSP3D: Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding | Python | 248 | 15 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Text-guided_Sparse_Voxel_Pruning_for_Efficient_3D_Visual_Grounding_CVPR_2025_paper.pdf) | |
| ECVC: Exploiting Non-Local Correlations in Multiple Frames for Contextual Video Compression | [code](https://github.com/JiangWeibeta/ECVC) | [CVPR 2025] ECVC: Exploiting Non-Local Correlations in Multiple Frames for Contextual Video Compression |  | 43 | 0 | 8 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_ECVC_Exploiting_Non-Local_Correlations_in_Multiple_Frames_for_Contextual_Video_CVPR_2025_paper.pdf) | |
| Towards Open-Vocabulary Audio-Visual Event Localization | [code](https://github.com/jasongief/OV-AVEL) | [2025 CVPR] Towards Open-Vocabulary Audio-Visual Event Localization | Python | 38 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Towards_Open-Vocabulary_Audio-Visual_Event_Localization_CVPR_2025_paper.pdf) | |
| Inst3D-LMM: Instance-Aware 3D Scene Understanding with Multi-modal Instruction Tuning | [code](https://github.com/hanxunyu/Inst3D-LMM) | [CVPR 2025 HighlightðŸ”¥] Official code repository for "Inst3D-LMM: Instance-Aware 3D Scene Understanding with Multi-modal Instruction Tuning" | Python | 125 | 5 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Inst3D-LMM_Instance-Aware_3D_Scene_Understanding_with_Multi-modal_Instruction_Tuning_CVPR_2025_paper.pdf) | |
| ProHOC: Probabilistic Hierarchical Out-of-Distribution Classification via Multi-Depth Networks | [code](https://github.com/walline/prohoc) | Official repository for CVPR 2025 paper "ProHOC: Probabilistic Hierarchical Out-of-Distribution Classification via Multi-Depth Networks" | Python | 7 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wallin_ProHOC_Probabilistic_Hierarchical_Out-of-Distribution_Classification_via_Multi-Depth_Networks_CVPR_2025_paper.pdf) | |
| CCIN: Compositional Conflict Identification and Neutralization for Composed Image Retrieval | [code](https://github.com/LikaiTian/CCIN) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_CCIN_Compositional_Conflict_Identification_and_Neutralization_for_Composed_Image_Retrieval_CVPR_2025_paper.pdf) | |
| CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards Zero-shot Adversarial Robustness of CLIP | [code](https://github.com/Sxing2/CLIP-Test-time-Counterattacks) | [CVPR-25ðŸ”¥] Test-time Counterattacks (TTC) towards adversarial robustness of CLIP | Python | 38 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_CLIP_is_Strong_Enough_to_Fight_Back_Test-time_Counterattacks_towards_CVPR_2025_paper.pdf) | |
| OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels | [code](https://github.com/LMMMEng/OverLoCK) | [CVPR 2025 Oral] OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels | Python | 481 | 48 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lou_OverLoCK_An_Overview-first-Look-Closely-next_ConvNet_with_Context-Mixing_Dynamic_Kernels_CVPR_2025_paper.pdf) | |
| O-TPT: Orthogonality Constraints for Calibrating Test-time Prompt Tuning in Vision-Language Models | [code](https://github.com/ashshaksharifdeen/O-TPT) | CVPR'25 official code for O-TPT: Orthogonality Constraints for Calibrating Test-time Prompt Tuning in Vision-Language Models  | Python | 14 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Sharifdeen_O-TPT_Orthogonality_Constraints_for_Calibrating_Test-time_Prompt_Tuning_in_Vision-Language_CVPR_2025_paper.pdf) | |
| Analyzing the Synthetic-to-Real Domain Gap in 3D Hand Pose Estimation | [code](https://github.com/delaprada/HandSynthesis.git) | [CVPR 2025] Analyzing the Synthetic-to-Real Domain Gap in 3D Hand Pose Estimation | Jupyter Notebook | 24 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Analyzing_the_Synthetic-to-Real_Domain_Gap_in_3D_Hand_Pose_Estimation_CVPR_2025_paper.pdf) | |
| Hyperspectral Pansharpening via Diffusion Models with Iteratively Zero-Shot Guidance | [code](https://github.com/Jin-liangXiao/DM-zs) | [CVPR2025] Hyperspectral Pansharpening via Diffusion Models with Iteratively Zero-Shot Guidance | Python | 10 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Hyperspectral_Pansharpening_via_Diffusion_Models_with_Iteratively_Zero-Shot_Guidance_CVPR_2025_paper.pdf) | |
| DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering | [code](https://github.com/LZ-CH/DSPNet) | The official repository of  [CVPR2025] DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering | Python | 24 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_DSPNet_Dual-vision_Scene_Perception_for_Robust_3D_Question_Answering_CVPR_2025_paper.pdf) | |
| DTOS: Dynamic Time Object Sensing with Large Multimodal Model | [code](https://github.com/Maulog/OPEN-DTOS-LMM) |  | Python | 9 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_DTOS_Dynamic_Time_Object_Sensing_with_Large_Multimodal_Model_CVPR_2025_paper.pdf) | |
| How to Merge Your Multimodal Models Over Time? | [code](https://github.com/ExplainableML/fomo_in_flux) | Code and benchmark for the paper: "A Practitioner's Guide to Continual Multimodal Pretraining" [NeurIPS'24] | Python | 61 | 4 | 10 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dziadzio_How_to_Merge_Your_Multimodal_Models_Over_Time_CVPR_2025_paper.pdf) | |
| Unsupervised Foundation Model-Agnostic Slide-Level Representation Learning | [code](https://github.com/KatherLab/COBRA) | COntrastive Biomarker Representation Alignment (COBRA) [CVPR25] | Python | 22 | 3 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lenz_Unsupervised_Foundation_Model-Agnostic_Slide-Level_Representation_Learning_CVPR_2025_paper.pdf) | |
| Exploring CLIP's Dense Knowledge for Weakly Supervised Semantic Segmentation | [code](https://github.com/zwyang6/ExCEL) | [CVPR2025] Exploring CLIPâ€™s Dense Knowledge for Weakly Supervised Semantic Segmentation | Python | 64 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Exploring_CLIPs_Dense_Knowledge_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.pdf) | |
| Exploration-Driven Generative Interactive Environments | [code](https://github.com/insait-institute/GenieRedux) | A framework for training world models with virtual environments, complete with annotated environment dataset (RetroAct), exploration agent (AutoExplore Agent), and GenieRedux-G - an implementation of Genie with enhancements | Python | 68 | 10 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Savov_Exploration-Driven_Generative_Interactive_Environments_CVPR_2025_paper.pdf) | |
| Task-Agnostic Guided Feature Expansion for Class-Incremental Learning | [code](https://github.com/bwnzheng/TagFex_CVPR2025) | The code repository for "Task-Agnostic Guided Feature Expansion for Class-Incremental Learning" (CVPR25) | Python | 23 | 5 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Task-Agnostic_Guided_Feature_Expansion_for_Class-Incremental_Learning_CVPR_2025_paper.pdf) | |
| ShowUI: One Vision-Language-Action Model for GUI Visual Agent | [code](https://github.com/showlab/ShowUI) | [CVPR 2025] Open-source, End-to-end, Vision-Language-Action model for GUI Agent & Computer Use. | Python | 1635 | 120 | 19 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_ShowUI_One_Vision-Language-Action_Model_for_GUI_Visual_Agent_CVPR_2025_paper.pdf) | |
| DreamText: High Fidelity Scene Text Synthesis | [code](https://github.com/CodeGoat24/DreamText) | [CVPR2025] Official implementation of High Fidelity Scene Text Synthesis. | Python | 78 | 3 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DreamText_High_Fidelity_Scene_Text_Synthesis_CVPR_2025_paper.pdf) | |
| ReVisionLLM: Recursive Vision-Language Model for Temporal Grounding in Hour-Long Videos | [code](https://github.com/Tanveer81/ReVisionLLM) | This is the official implementation of ReVisionLLM: Recursive Vision-Language Model for Temporal Grounding in Hour-Long Videos | Python | 40 | 2 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hannan_ReVisionLLM_Recursive_Vision-Language_Model_for_Temporal_Grounding_in_Hour-Long_Videos_CVPR_2025_paper.pdf) | |
| Advancing Semantic Future Prediction through Multimodal Visual Sequence Transformers | [code](https://github.com/Sta8is/FUTURIST) | [CVPR 2025]  Advancing Semantic Future Prediction through Multimodal Visual Sequence Transformers | Jupyter Notebook | 41 | 5 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Karypidis_Advancing_Semantic_Future_Prediction_through_Multimodal_Visual_Sequence_Transformers_CVPR_2025_paper.pdf) | |
| GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery | [code](https://github.com/enguangW/GET) | GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery ï¼ˆCVPR2025ï¼‰ | Python | 32 | 2 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_GET_Unlocking_the_Multi-modal_Potential_of_CLIP_for_Generalized_Category_CVPR_2025_paper.pdf) | |
| MonoTAKD: Teaching Assistant Knowledge Distillation for Monocular 3D Object Detection | [code](https://github.com/hoiliu-0801/MonoTAKD) | MonoTAKD: Teaching assistant knowledge distillation for monocular 3D object detection. | Python | 39 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MonoTAKD_Teaching_Assistant_Knowledge_Distillation_for_Monocular_3D_Object_Detection_CVPR_2025_paper.pdf) | |
| Test-Time Domain Generalization via Universe Learning: A Multi-Graph Matching Approach for Medical Image Segmentation | [code](https://github.com/Yore0/TTDG-MGM) | [CVPR 2025] Test-Time Domain Generalization via Universe Learning: A Multi-Graph Matching Approach for Medical Image Segmentation | Python | 94 | 15 | 9 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lv_Test-Time_Domain_Generalization_via_Universe_Learning_A_Multi-Graph_Matching_Approach_CVPR_2025_paper.pdf) | |
| Devils in Middle Layers of Large Vision-Language Models: Interpreting; Detecting and Mitigating Object Hallucinations via Attention Lens | [code](https://github.com/ZhangqiJiang07/middle_layers_indicating_hallucinations) | [CVPR 2025] Devils in Middle Layers of Large Vision-Language Models: Interpreting, Detecting and Mitigating Object Hallucinations via Attention Lens | Python | 60 | 6 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Devils_in_Middle_Layers_of_Large_Vision-Language_Models_Interpreting_Detecting_CVPR_2025_paper.pdf) | |
| AVF-MAE++: Scaling Affective Video Facial Masked Autoencoders via Efficient Audio-Visual Self-Supervised Learning | [code](https://github.com/XuecWu/AVF-MAE) | [CVPR'25] AVF-MAE++ : Scaling Affective Video Facial Masked Autoencoders via Efficient Audio-Visual Self-Supervised Learning | Python | 15 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_AVF-MAE_Scaling_Affective_Video_Facial_Masked_Autoencoders_via_Efficient_Audio-Visual_CVPR_2025_paper.pdf) | |
| CryptoFace: End-to-End Encrypted Face Recognition | [code](https://github.com/human-analysis/CryptoFace) | Official implementation for CryptoFace: End-to-End Encrypted Face Recognition. The paper is presented at CVPR 2025. | C++ | 12 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ao_CryptoFace_End-to-End_Encrypted_Face_Recognition_CVPR_2025_paper.pdf) | |
| Relation-Rich Visual Document Generator for Visual Information Extraction | [code](https://github.com/AI-Application-and-Integration-Lab/RIDGE) | [CVPR 2025] RIDGE: Relation-Rich Visual Document Generator for Visual Information Extraction | Python | 8 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Relation-Rich_Visual_Document_Generator_for_Visual_Information_Extraction_CVPR_2025_paper.pdf) | |
| Mimic In-Context Learning for Multimodal Tasks | [code](https://github.com/Kamichanw/MimIC) | [CVPR'25] Official code of paper "Mimic In-Context Learning for Multimodal Tasks" | Python | 24 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Mimic_In-Context_Learning_for_Multimodal_Tasks_CVPR_2025_paper.pdf) | |
| PromptHash:Affinity-Prompted Collaborative Cross-Modal Learning for Adaptive Hashing Retrieval | [code](https://github.com/ShiShuMo/PromptHash) | Source code for CVPR'25 paper "PromptHash: Affinity-Prompted Collaborative Cross-Modal Learning for Adaptive Hashing Retrieval" | Python | 12 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zou_PromptHashAffinity-Prompted_Collaborative_Cross-Modal_Learning_for_Adaptive_Hashing_Retrieval_CVPR_2025_paper.pdf) | |
| RICCARDO: Radar Hit Prediction and Convolution for Camera-Radar 3D Object Detection | [code](https://github.com/longyunf/riccardo) |  | Python | 11 | 1 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Long_RICCARDO_Radar_Hit_Prediction_and_Convolution_for_Camera-Radar_3D_Object_CVPR_2025_paper.pdf) | |
| Split Adaptation for Pre-trained Vision Transformers | [code](https://github.com/conditionWang/Split_Adaptation) | This is the code implementation of CVPR-2025 paper: Split Adaptation for Pre-trained Vision Transformers. |  | 5 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Split_Adaptation_for_Pre-trained_Vision_Transformers_CVPR_2025_paper.pdf) | |
| SLVR: Super-Light Visual Reconstruction via Blueprint Controllable Convolutions and Exploring Feature Diversity Representation | [code](https://github.com/chongningni/SLVR) | ã€CVPR 2025ã€‘ SLVR: Super-Light Visual Reconstruction via Blueprint Controllable Convolutions and Exploring Feature Diversity Representation | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ni_SLVR_Super-Light_Visual_Reconstruction_via_Blueprint_Controllable_Convolutions_and_Exploring_CVPR_2025_paper.pdf) | |
| Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking | [code](https://github.com/wuyou3474/ORTrack) | [CVPR 2025] Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking | Python | 76 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Learning_Occlusion-Robust_Vision_Transformers_for_Real-Time_UAV_Tracking_CVPR_2025_paper.pdf) | |
| Frequency Dynamic Convolution for Dense Image Prediction | [code](https://github.com/Linwei-Chen/FDConv) | CVPR 2025: Frequency Dynamic Convolution for Dense Image Prediction | Python | 318 | 9 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Frequency_Dynamic_Convolution_for_Dense_Image_Prediction_CVPR_2025_paper.pdf) | |
| SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost | [code](https://github.com/showlab/SAM-I2V) | [CVPR 2025] SAM-I2V | Jupyter Notebook | 33 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Mei_SAM-I2V_Upgrading_SAM_to_Support_Promptable_Video_Segmentation_with_Less_CVPR_2025_paper.pdf) | |
| GroupMamba: Efficient Group-Based Visual State Space Model | [code](https://github.com/Amshaker/GroupMamba) | GroupMamba: Parameter-Efficient and Accurate Group Visual State Space Model [CVPR -2025] | Python | 129 | 7 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shaker_GroupMamba_Efficient_Group-Based_Visual_State_Space_Model_CVPR_2025_paper.pdf) | |
| ActiveGAMER: Active GAussian Mapping through Efficient Rendering | [code](https://github.com/oppo-us-research/ActiveGAMER) | [CVPR2025] ActiveGAMER: Active GAussian Mapping | Python | 24 | 2 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_ActiveGAMER_Active_GAussian_Mapping_through_Efficient_Rendering_CVPR_2025_paper.pdf) | |
| DeepCompress-ViT: Rethinking Model Compression to Enhance Efficiency of Vision Transformers at the Edge | [code](https://github.com/ML-Security-Research-LAB/DeepCompress-ViT) |  | Python | 4 | 3 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ahmed_DeepCompress-ViT_Rethinking_Model_Compression_to_Enhance_Efficiency_of_Vision_Transformers_CVPR_2025_paper.pdf) | |
| Positive2Negative: Breaking the Information-Lossy Barrier in Self-Supervised Single Image Denoising | [code](https://github.com/Li-Tong-621/P2N) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Positive2Negative_Breaking_the_Information-Lossy_Barrier_in_Self-Supervised_Single_Image_Denoising_CVPR_2025_paper.pdf) | |
| DEAL: Data-Efficient Adversarial Learning for High-Quality Infrared Imaging | [code](https://github.com/LiuZhu-CV/DEAL) | DEAL: Data-Efficient Adversarial Learning for High-Quality Infrared Imaging ï¼ˆCVPR 25ï¼‰ | Python | 18 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_DEAL_Data-Efficient_Adversarial_Learning_for_High-Quality_Infrared_Imaging_CVPR_2025_paper.pdf) | |
| CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning | [code](https://github.com/LeapLabTHU/CheXWorld) | [CVPR 2025] CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning | Python | 34 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yue_CheXWorld_Exploring_Image_World_Modeling_for_Radiograph_Representation_Learning_CVPR_2025_paper.pdf) | |
| Learning Class Prototypes for Unified Sparse-Supervised 3D Object Detection | [code](https://github.com/zyrant/CPDet3D) | [CVPR 2025] Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection | Python | 24 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Learning_Class_Prototypes_for_Unified_Sparse-Supervised_3D_Object_Detection_CVPR_2025_paper.pdf) | |
| Open-World Amodal Appearance Completion | [code](https://github.com/saraao/amodal) | [CVPR 2025] Open-World Amodal Appearance Completion | Python | 48 | 3 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ao_Open-World_Amodal_Appearance_Completion_CVPR_2025_paper.pdf) | |
| AIGV-Assessor: Benchmarking and Evaluating the Perceptual Quality of Text-to-Video Generation with LMM | [code](https://github.com/IntMeGroup/AIGV-Assessor) | [CVPR2025] AIGV-Assessor: Benchmarking and Evaluating the Perceptual Quality of Text-to-Video Generation with LMM | Python | 9 | 0 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_AIGV-Assessor_Benchmarking_and_Evaluating_the_Perceptual_Quality_of_Text-to-Video_Generation_CVPR_2025_paper.pdf) | |
| Autoregressive Distillation of Diffusion Transformers | [code](https://github.com/alsdudrla10/ARD) | [CVPR 2025 Oral] PyTorch re-implementation for Autoregressive Distillation of Diffusion Transformers (ARD). | Python | 139 | 6 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Autoregressive_Distillation_of_Diffusion_Transformers_CVPR_2025_paper.pdf) | |
| DiscoVLA: Discrepancy Reduction in Vision; Language; and Alignment for Parameter-Efficient Video-Text Retrieval | [code](https://github.com/LunarShen/DsicoVLA) | [CVPR 2025] DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval | Python | 22 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_DiscoVLA_Discrepancy_Reduction_in_Vision_Language_and_Alignment_for_Parameter-Efficient_CVPR_2025_paper.pdf) | |
| EmoDubber: Towards High Quality and Emotion Controllable Movie Dubbing | [code](https://github.com/GalaxyCong/DubFlow) | Official source codes for the paper: EmoDubber: Towards High Quality and Emotion Controllable Movie Dubbing.  | Python | 33 | 2 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Cong_EmoDubber_Towards_High_Quality_and_Emotion_Controllable_Movie_Dubbing__CVPR_2025_paper.pdf) | |
| A Hubness Perspective on Representation Learning for Graph-Based Multi-View Clustering | [code](https://github.com/zmxu196/hubREP) |  | Python | 4 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_A_Hubness_Perspective_on_Representation_Learning_for_Graph-Based_Multi-View_Clustering_CVPR_2025_paper.pdf) | |
| Image Referenced Sketch Colorization Based on Animation Creation Workflow | [code](https://github.com/tellurion-kanata/colorizeDiffusion) | Implementation of ColorizeDiffusion | Python | 86 | 6 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Image_Referenced_Sketch_Colorization_Based_on_Animation_Creation_Workflow_CVPR_2025_paper.pdf) | |
| HoVLE: Unleashing the Power of Monolithic Vision-Language Models with Holistic Vision-Language Embedding | [code](https://huggingface.co/OpenGVLab/HoVLE) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tao_HoVLE_Unleashing_the_Power_of_Monolithic_Vision-Language_Models_with_Holistic_CVPR_2025_paper.pdf) | |
| Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map | [code](https://github.com/MIV-XJTU/MapDR) | [CVPR 2025 Highlight] Official repository of MapDR dataset proposed in paper "Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map"  | Python | 33 | 4 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_Driving_by_the_Rules_A_Benchmark_for_Integrating_Traffic_Sign_CVPR_2025_paper.pdf) | |
| LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis | [code](https://github.com/ant-research/LeviTor) | [CVPR'25 Highlight] Official implementation for paper - LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis | Python | 157 | 9 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LeviTor_3D_Trajectory_Oriented_Image-to-Video_Synthesis_CVPR_2025_paper.pdf) | |
| ABC-Former: Auxiliary Bimodal Cross-domain Transformer with Interactive Channel Attention for White Balance | [code](https://github.com/ytpeng-aimlab/ABC-Former) |  | Python | 8 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Chiu_ABC-Former_Auxiliary_Bimodal_Cross-domain_Transformer_with_Interactive_Channel_Attention_for_CVPR_2025_paper.pdf) | |
| MoST: Efficient Monarch Sparse Tuning for 3D Representation Learning | [code](https://github.com/xhanxu/MoST) | [CVPR 2025] MoST: Efficient Monarch Sparse Tuning for 3D Representation Learning | Python | 15 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Han_MoST_Efficient_Monarch_Sparse_Tuning_for_3D_Representation_Learning_CVPR_2025_paper.pdf) | |
| CSC-PA: Cross-image Semantic Correlation via Prototype Attentions for Single-network Semi-supervised Breast Tumor Segmentation | [code](https://github.com/shdkdh/CSC-PA) | CSC-PA: Cross-image Semantic Correlation via Prototype Attentions for Single-network Semi-supervised Breast Tumor Segmentation (CVPR 2025) | Python | 17 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ding_CSC-PA_Cross-image_Semantic_Correlation_via_Prototype_Attentions_for_Single-network_Semi-supervised_CVPR_2025_paper.pdf) | |
| BIP3D: Bridging 2D Images and 3D Perception for Embodied Intelligence | [code](https://github.com/HorizonRobotics/BIP3D) | BIP3D: Bridging 2D Images and 3D Perception for Embodied Intelligence | Python | 239 | 4 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_BIP3D_Bridging_2D_Images_and_3D_Perception_for_Embodied_Intelligence_CVPR_2025_paper.pdf) | |
| CoA: Towards Real Image Dehazing via Compression-and-Adaptation | [code](https://github.com/fyxnl/COA) | This a code for CVPR 2025: CoA: Towards Real Image Dehazing via Compression-and-Adaptation |  | 13 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_CoA_Towards_Real_Image_Dehazing_via_Compression-and-Adaptation_CVPR_2025_paper.pdf) | |
| Improving Autoregressive Visual Generation with Cluster-Oriented Token Prediction | [code](https://github.com/sjtuplayer/IAR) | [CVPR25] IAR | Python | 15 | 3 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_Improving_Autoregressive_Visual_Generation_with_Cluster-Oriented_Token_Prediction_CVPR_2025_paper.pdf) | |
| D^3: Scaling Up Deepfake Detection by Learning from Discrepancy | [code](https://github.com/BigAandSmallq/D3) |  | Python | 39 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_D3_Scaling_Up_Deepfake_Detection_by_Learning_from_Discrepancy_CVPR_2025_paper.pdf) | |
| Jailbreaking the Non-Transferable Barrier via Test-Time Data Disguising | [code](https://github.com/tmllab/2025_CVPR_JailNTL) |  | Python | 4 | 0 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xiang_Jailbreaking_the_Non-Transferable_Barrier_via_Test-Time_Data_Disguising_CVPR_2025_paper.pdf) | |
| Percept; Memory; and Imagine: World Feature Simulating for Open-Domain Unknown Object Detection | [code](https://github.com/AmingWu/WFS) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Percept_Memory_and_Imagine_World_Feature_Simulating_for_Open-Domain_Unknown_CVPR_2025_paper.pdf) | |
| Efficient Depth Estimation for Unstable Stereo Camera Systems on AR Glasses | [code](https://github.com/UCI-ISA-Lab/MultiHeadDepth-HomoDepth) | [CVPR 2025] Official implementation of  paper on depth estimation for AR stereo cameras. | Python | 20 | 3 | 0 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Efficient_Depth_Estimation_for_Unstable_Stereo_Camera_Systems_on_AR_CVPR_2025_paper.pdf) | |
| Cross-modal Information Flow in Multimodal Large Language Models | [code](https://github.com/FightingFighting/cross-modal-information-flow-in-MLLM.git) | This is the official repository for paper: cross-modal information flow in multimodal large language models | Python | 37 | 2 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Cross-modal_Information_Flow_in_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf) | |
| Omnidirectional Multi-Object Tracking | [code](https://github.com/xifen523/OmniTrack) | The official implementation of OmniTrack: Omnidirectional Multi-Object Tracking (CVPR 2025) | HTML | 96 | 4 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Omnidirectional_Multi-Object_Tracking_CVPR_2025_paper.pdf) | |
| Directional Label Diffusion Model for Learning from Noisy Labels | [code](https://github.com/SenyuHou/DLD) |  | Python | 7 | 1 | 1 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hou_Directional_Label_Diffusion_Model_for_Learning_from_Noisy_Labels_CVPR_2025_paper.pdf) | |
| AA-CLIP: Enhancing Zero-Shot Anomaly Detection via Anomaly-Aware CLIP | [code](https://github.com/Mwxinnn/AA-CLIP) | The official implementation of AA-CLIP: Enhancing Zero-shot Anomaly Detection via Anomaly-Aware CLIP | Python | 213 | 15 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_AA-CLIP_Enhancing_Zero-Shot_Anomaly_Detection_via_Anomaly-Aware_CLIP_CVPR_2025_paper.pdf) | |
| HybridGS: Decoupling Transients and Statics with 2D and 3D Gaussian Splatting | [code](https://github.com/Yeyuqqwx/HybridGS) | This repository contains the code for the paper [HybridGS: Decoupling Transients and Statics with 2D and 3D Gaussian Splatting](https://gujiaqivadin.github.io/hybridgs/). | Python | 63 | 1 | 6 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_HybridGS_Decoupling_Transients_and_Statics_with_2D_and_3D_Gaussian_CVPR_2025_paper.pdf) | |
| Channel Consistency Prior and Self-Reconstruction Strategy Based Unsupervised Image Deraining | [code](https://github.com/GuangluDong0728/CSUD) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Channel_Consistency_Prior_and_Self-Reconstruction_Strategy_Based_Unsupervised_Image_Deraining_CVPR_2025_paper.pdf) | |
| EdgeTAM: On-Device Track Anything Model | [code](https://github.com/facebookresearch/EdgeTAM) | [CVPR 2025] Official PyTorch implementation of "EdgeTAM: On-Device Track Anything Model" | Jupyter Notebook | 852 | 66 | 7 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_EdgeTAM_On-Device_Track_Anything_Model_CVPR_2025_paper.pdf) | |
| SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection | [code](https://github.com/lexisnexis-risk-open-source/simltd) | [CVPR 2025] Simple Supervised and Semi-Supervised Long-Tailed Object Detection | Python | 12 | 1 | 3 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Tran_SimLTD_Simple_Supervised_and_Semi-Supervised_Long-Tailed_Object_Detection_CVPR_2025_paper.pdf) | |
| EarthDial: Turning Multi-sensory Earth Observations to Interactive Dialogues | [code](https://github.com/hiyamdebary/EarthDial) | [CVPR 2025 ðŸ”¥] EarthDial: Turning Multi-Sensory Earth Observations to Interactive Dialogues. | Python | 105 | 8 | 4 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Soni_EarthDial_Turning_Multi-sensory_Earth_Observations_to_Interactive_Dialogues_CVPR_2025_paper.pdf) | |
| HyperSeg: Hybrid Segmentation Assistant with Fine-grained Visual Perceiver | [code](https://github.com/congvvc/HyperSeg) | [CVPR2025] Project for "HyperSeg: Towards Universal Visual Segmentation with Large Language Model". | Python | 178 | 5 | 10 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_HyperSeg_Hybrid_Segmentation_Assistant_with_Fine-grained_Visual_Perceiver_CVPR_2025_paper.pdf) | |
| Diffusion-based Event Generation for High-Quality Image Deblurring | [code](https://github.com/XinanXie/EGDeblurring) |  | Python | 23 | 1 | 2 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Diffusion-based_Event_Generation_for_High-Quality_Image_Deblurring_CVPR_2025_paper.pdf) | |
| Balanced Rate-Distortion Optimization in Learned Image Compression | [code](https://gitlab.com/viper-purdue/Balanced-RD) |  |  |  |  |  | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Balanced_Rate-Distortion_Optimization_in_Learned_Image_Compression_CVPR_2025_paper.pdf) | |
| Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model | [code](https://github.com/ZhaochongAn/GFS-VL) | [CVPR 2025] Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model | Python | 53 | 3 | 5 | [pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/An_Generalized_Few-shot_3D_Point_Cloud_Segmentation_with_Vision-Language_Model_CVPR_2025_paper.pdf) | |
